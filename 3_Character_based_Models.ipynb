{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6W1O4UJcuAE"
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dropout,Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping,TensorBoard,LearningRateScheduler\n",
    "from nltk.translate import bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>Encoder Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "zp7DConlnKPW",
    "outputId": "9afa9237-c077-4016-c789-73803ea580ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-08 04:28:05--  https://doc-14-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/0d1l8r7lvb03s30i0dca615to39oqlp5/1591590450000/02963250765125473783/02963250765125473783/1jW765FL46OCyM0yBYXzhLrcUpSbZEZUz?e=download&authuser=1\n",
      "Resolving doc-14-ak-docs.googleusercontent.com (doc-14-ak-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
      "Connecting to doc-14-ak-docs.googleusercontent.com (doc-14-ak-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘char_encoded_data’\n",
      "\n",
      "\r",
      "char_encoded_data       [<=>                 ]       0  --.-KB/s               \r",
      "char_encoded_data       [ <=>                ]   4.01M  14.4MB/s               \r",
      "char_encoded_data       [  <=>               ]   8.12M  27.7MB/s    in 0.3s    \n",
      "\n",
      "2020-06-08 04:28:06 (27.7 MB/s) - ‘char_encoded_data’ saved [8514266]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-14-ak-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://drive.google.com/drive/u/1/folders/1kcnuBLEiI2SFWWZhGFK3ba-Vwbbt0LmE\" --header=\"Cookie: AUTH_hsr61oqao0sqa2rdskku1n6gcr67pomr=02963250765125473783|1591590300000|u7dhk7aivpt8lc34m2ada26ut0lhkduc; _ga=GA1.2.1509677474.1591248567\" --header=\"Connection: keep-alive\" \"https://doc-14-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/0d1l8r7lvb03s30i0dca615to39oqlp5/1591590450000/02963250765125473783/02963250765125473783/1jW765FL46OCyM0yBYXzhLrcUpSbZEZUz?e=download&authuser=1\" -c -O 'char_encoded_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5JLhjfZ0XEz"
   },
   "source": [
    "<h1>1. Read Featurized data</h1> \n",
    "<h2>(Refer Character Featurization Section 3 of 2_Data_Preparation.ipynb)</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnTFvgjaWx8o"
   },
   "outputs": [],
   "source": [
    "[X_train_padded_docs,y_train_padded_docs,X_val_padded_docs,y_val_padded_docs,\n",
    "                                             embedding_matrix,tokenizer] = joblib.load('char_encoded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjB44o3q0XHp"
   },
   "source": [
    "<h1>2. Encoder Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icMEwKexcuC2"
   },
   "source": [
    "<h2>2.1. Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgtZmDqYcuC6"
   },
   "outputs": [],
   "source": [
    "#Encoder class\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,enc_units,**kwargs):\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, weights=[embedding_matrix],\n",
    "                                   mask_zero=True,name='Encoder_Embedding')\n",
    "        self.lstm = LSTM(self.enc_units,return_sequences=True,return_state=True,name='Encoder_LSTM',dropout=0.33)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        #state_c = Cell state output of last time step\n",
    "        encoder_outputs, _, state_c = self.lstm(x)\n",
    "        \n",
    "        #Take average of encoder_outputs\n",
    "        hidden = tf.reduce_mean(encoder_outputs,1)\n",
    "        \n",
    "        return hidden, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uc064MCCcuC_",
    "outputId": "2ec31460-85e5-4573-c3ea-e93d4bc325a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocab size:',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "P_xpJvvccuDE",
    "outputId": "b09a9dd1-8da4-45b1-8a55-ef03d9a326a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch input data (batch_size,sequence length): (32, 132)\n",
      "Shape of batch output data (batch_size,sequence length): (32, 132)\n",
      "Shape of average hidden state output (batch_size,units): (32, 256)\n",
      "Shape of average memory state output (batch_size,units): (32, 256)\n"
     ]
    }
   ],
   "source": [
    "#Create encoder object\n",
    "BATCH_SIZE = 32\n",
    "encoder = Encoder(vocab_size=vocab_size,embedding_dim=300,embedding_matrix=embedding_matrix,\n",
    "                  enc_units=256,name='Encoder')\n",
    "\n",
    "#Sample input to encoder\n",
    "example_input_batch, example_target_batch = X_train_padded_docs[:BATCH_SIZE], y_train_padded_docs[:BATCH_SIZE]\n",
    "print('Shape of batch input data (batch_size,sequence length):',example_input_batch.shape)\n",
    "print('Shape of batch output data (batch_size,sequence length):',example_target_batch.shape)\n",
    "\n",
    "#Genearte sample hidden state from encoder object\n",
    "sample_hidden_output, sample_cell_output = encoder(example_input_batch)\n",
    "print('Shape of average hidden state output (batch_size,units):',sample_hidden_output.shape)\n",
    "print('Shape of average memory state output (batch_size,units):',sample_cell_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWTi0DbhcuDf"
   },
   "source": [
    "<h2>2.2. Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxVxxpnbcuDg"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,dec_units,**kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim,\n",
    "                                            weights=[embedding_matrix],mask_zero=True,name='Decoder_Embedding')\n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units,return_sequences=True,return_state=True,name='Decoder_LSTM',dropout=0.33)\n",
    "        self.batch_norm = BatchNormalization()\n",
    "        \n",
    "    def call(self, x, hidden, cell):\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # passing the concatenated vector to the LSTM\n",
    "        lstm_output, state_h, state_c = self.lstm(x,initial_state=[hidden,cell])\n",
    "        \n",
    "        #Normalise output\n",
    "        lstm_output = self.batch_norm(lstm_output)\n",
    "        \n",
    "        return lstm_output,state_h,state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "b9pinu5acuDv",
    "outputId": "72e523a9-0980-4de8-956e-081183b2e18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder:\n",
      "Shape of decoder input (batch_size,sequence_length): (32, 132)\n",
      "Shape of decoder output (batch_size,sequence_length,units): (32, 132, 256)\n",
      "Shape of decoder hidden state output (batch_size,units): (32, 256)\n",
      "Shape of decoder memory state output (batch_size,units): (32, 256)\n"
     ]
    }
   ],
   "source": [
    "#Initialise one step decoder\n",
    "BATCH_SIZE = 32\n",
    "dec = Decoder(vocab_size=vocab_size,embedding_dim=300,embedding_matrix=embedding_matrix,dec_units=256)\n",
    "\n",
    "#Geneate sample output and hidden states from decoder object\n",
    "sample_output_dec,sample_hidden_output_dec,sample_cell_output_dec = dec(example_target_batch,sample_hidden_output,\n",
    "                                                                        sample_cell_output)\n",
    "print('Decoder:')\n",
    "print('Shape of decoder input (batch_size,sequence_length):',example_target_batch.shape)\n",
    "print('Shape of decoder output (batch_size,sequence_length,units):',sample_output_dec.shape)\n",
    "print('Shape of decoder hidden state output (batch_size,units):',sample_hidden_output_dec.shape)\n",
    "print('Shape of decoder memory state output (batch_size,units):',sample_cell_output_dec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3JlgiLdcuEM"
   },
   "source": [
    "<h2>2.3. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DTKipswcuEN"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHe4U-qBcuER"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    \n",
    "    #Identify zeros in real tensor/Creating masking tensor\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    #Calculate log loss for each class\n",
    "    loss_ = loss_object(real, pred)\n",
    "    #Change data type of mask\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #Calculate loss considering masking\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qlauC-cuET"
   },
   "source": [
    "<h2>2.4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDQubxhQcuEU"
   },
   "outputs": [],
   "source": [
    "class Encoder_Decoder_Model(tf.keras.models.Model):\n",
    "    def __init__(self, vocab_size,embedding_dim,embedding_matrix,units,**kwargs):\n",
    "        super(Encoder_Decoder_Model,self).__init__(**kwargs)\n",
    "        self.encoder = Encoder(vocab_size=vocab_size, embedding_dim=embedding_dim,embedding_matrix=embedding_matrix,\n",
    "                               enc_units=units,name='Encoder_layer')\n",
    "        self.decoder = Decoder(vocab_size=vocab_size, embedding_dim=embedding_dim,embedding_matrix=embedding_matrix,\n",
    "                               dec_units=units,name='Decoder_layer')\n",
    "        self.drop = Dropout(0.2,name='Dropout')\n",
    "        self.dense = Dense(vocab_size,name='Output_layer')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #Inputs will contain encoder input and decoder input\n",
    "        #Separate encoder and decoder inputs\n",
    "        encoder_inputs, decoder_inputs = inputs[0], inputs[1]\n",
    "        \n",
    "        #Genearte output and hidden states from encoder object\n",
    "        enc_hidden_output, enc_cell_output = self.encoder(encoder_inputs)\n",
    "\n",
    "        #Generate output from decoder\n",
    "        #Initialise hidden states of decoder with hidden states of encoder\n",
    "        decoder_outputs,_,_ = self.decoder(decoder_inputs,enc_hidden_output,enc_cell_output)\n",
    "        \n",
    "        #Dropout\n",
    "        decoder_outputs = self.drop(decoder_outputs)\n",
    "        \n",
    "        #Shape of outputs = (batch_size,timesteps,vocab_size)\n",
    "        outputs = self.dense(decoder_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcrEYcmlL7H6"
   },
   "source": [
    "<h2>2.5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBKLoKUbL7H7"
   },
   "outputs": [],
   "source": [
    "#Function returns texts from a sequence\n",
    "def get_text_from_seq(sequence,tokenizer):\n",
    "    sent =''\n",
    "    for i in sequence:\n",
    "        if i!=0:\n",
    "            sent+=tokenizer.index_word[i]\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ_KwVRdL7H_"
   },
   "outputs": [],
   "source": [
    "#Function to get bleu score for a sentence\n",
    "def get_bleu_score(enc_dec_model,input_seq,expected_output_seq):\n",
    "    \n",
    "    input_max_length = X_train_padded_docs.shape[1]\n",
    "    output_max_length = y_train_padded_docs.shape[1]\n",
    "    \n",
    "    #Get output from encoder\n",
    "    enc_hidden,enc_cell = enc_dec_model.layers[0](input_seq.reshape(1,input_max_length))\n",
    "    \n",
    "    #Boundary case for decoder\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['#']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    \n",
    "    #Predicted output sequence\n",
    "    #Add '#' (start) token to output sequence\n",
    "    output_seq = [tokenizer.word_index['#']]\n",
    "    \n",
    "    #The model will start predicting after start token, hence max_length is subtracted by 1\n",
    "    for i in range(output_max_length-1):\n",
    "        #Get prediction from decoder\n",
    "        dec_output,dec_hidden,dec_cell = enc_dec_model.layers[1](dec_input,dec_hidden,dec_cell)\n",
    "        \n",
    "        #Get prediction from dense layer\n",
    "        #Shape == (batch_size,timestep,vocab_size) == (1,1,30)\n",
    "        outputs = enc_dec_model.layers[3](dec_output)\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = np.argmax(outputs.numpy().reshape(-1))\n",
    "        \n",
    "        output_seq.append(key)\n",
    "        \n",
    "        if tokenizer.index_word[key] == '*':\n",
    "            #Get texts from input sentence\n",
    "            input_sent = get_text_from_seq(input_seq,tokenizer)\n",
    "            #Get texts from sequence for actual sentence\n",
    "            actual = get_text_from_seq(expected_output_seq,tokenizer)\n",
    "            #Get texts from sequence for predicted sentence\n",
    "            prediction = get_text_from_seq(output_seq,tokenizer)\n",
    "            return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    input_sent = get_text_from_seq(input_seq,tokenizer)\n",
    "    actual = get_text_from_seq(expected_output_seq,tokenizer)\n",
    "    prediction = get_text_from_seq(output_seq,tokenizer)\n",
    "    return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6naCdjvcuEa"
   },
   "source": [
    "<h1>3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TTqWUC8cuEa"
   },
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "#Encoding and decoding Embedding layer dimension\n",
    "embedding_dim = 300\n",
    "#Encoding and decoding LSTM layer units\n",
    "units = 256\n",
    "\n",
    "#Initialise object for Model class\n",
    "model = Encoder_Decoder_Model(vocab_size,embedding_dim,embedding_matrix,units,name='Encoder_Decoder_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "PKDJZOJDcuEc",
    "outputId": "dab4afa5-b3fc-495e-c122-3df4ae3561d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder_Decoder_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_layer (Encoder)      multiple                  579368    \n",
      "_________________________________________________________________\n",
      "Decoder_layer (Decoder)      multiple                  580392    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "Output_layer (Dense)         multiple                  7710      \n",
      "=================================================================\n",
      "Total params: 1,167,470\n",
      "Trainable params: 1,166,958\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Max sequence length = 166 for input sentence\n",
    "#Max sequence length = (166-1) for output sentence, 1 is subtracted because '*' (end) token should not be give input to decoder\n",
    "model.build(input_shape=[(None,X_train_padded_docs.shape[0]),(None,y_train_padded_docs.shape[0])])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20CwK6Chcj1d"
   },
   "outputs": [],
   "source": [
    "def data_generator(X,y,BATCH_SIZE,shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(X)).batch(BATCH_SIZE,drop_remainder=True)\n",
    "    else:\n",
    "        dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEn_0bp2cuEf"
   },
   "outputs": [],
   "source": [
    "#Create folder to save model weights\n",
    "if not os.path.isdir('model_save'):\n",
    "    os.makedirs('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsXuVDsV0XIU"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tyKYm6yocuEm",
    "outputId": "de615eed-cf1a-494d-860e-bee2e4a7e162",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.4803\n",
      "Epoch 00001: loss improved from inf to 0.48030, saving model to model_save/weights-01-0.4803.hdf5\n",
      "424/424 [==============================] - 72s 170ms/step - loss: 0.4803 - val_loss: 0.3392\n",
      "Epoch 2/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.3773\n",
      "Epoch 00002: loss improved from 0.48030 to 0.37729, saving model to model_save/weights-02-0.3773.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.3773 - val_loss: 0.2849\n",
      "Epoch 3/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.3418\n",
      "Epoch 00003: loss improved from 0.37729 to 0.34185, saving model to model_save/weights-03-0.3418.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.3418 - val_loss: 0.2627\n",
      "Epoch 4/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.3199\n",
      "Epoch 00004: loss improved from 0.34185 to 0.31985, saving model to model_save/weights-04-0.3199.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.3199 - val_loss: 0.2469\n",
      "Epoch 5/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.3027\n",
      "Epoch 00005: loss improved from 0.31985 to 0.30271, saving model to model_save/weights-05-0.3027.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.3027 - val_loss: 0.2335\n",
      "Epoch 6/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2888\n",
      "Epoch 00006: loss improved from 0.30271 to 0.28881, saving model to model_save/weights-06-0.2888.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2888 - val_loss: 0.2235\n",
      "Epoch 7/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2776\n",
      "Epoch 00007: loss improved from 0.28881 to 0.27757, saving model to model_save/weights-07-0.2776.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2776 - val_loss: 0.2153\n",
      "Epoch 8/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2690\n",
      "Epoch 00008: loss improved from 0.27757 to 0.26895, saving model to model_save/weights-08-0.2690.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2690 - val_loss: 0.2098\n",
      "Epoch 9/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2623\n",
      "Epoch 00009: loss improved from 0.26895 to 0.26226, saving model to model_save/weights-09-0.2623.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2623 - val_loss: 0.2068\n",
      "Epoch 10/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2569\n",
      "Epoch 00010: loss improved from 0.26226 to 0.25685, saving model to model_save/weights-10-0.2569.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2569 - val_loss: 0.2040\n",
      "Epoch 11/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2524\n",
      "Epoch 00011: loss improved from 0.25685 to 0.25244, saving model to model_save/weights-11-0.2524.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2524 - val_loss: 0.2020\n",
      "Epoch 12/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2488\n",
      "Epoch 00012: loss improved from 0.25244 to 0.24876, saving model to model_save/weights-12-0.2488.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2488 - val_loss: 0.1998\n",
      "Epoch 13/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2454\n",
      "Epoch 00013: loss improved from 0.24876 to 0.24541, saving model to model_save/weights-13-0.2454.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2454 - val_loss: 0.1989\n",
      "Epoch 14/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2429\n",
      "Epoch 00014: loss improved from 0.24541 to 0.24286, saving model to model_save/weights-14-0.2429.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2429 - val_loss: 0.1968\n",
      "Epoch 15/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2407\n",
      "Epoch 00015: loss improved from 0.24286 to 0.24072, saving model to model_save/weights-15-0.2407.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2407 - val_loss: 0.1962\n",
      "Epoch 16/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2388\n",
      "Epoch 00016: loss improved from 0.24072 to 0.23882, saving model to model_save/weights-16-0.2388.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2388 - val_loss: 0.1958\n",
      "Epoch 17/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2372\n",
      "Epoch 00017: loss improved from 0.23882 to 0.23723, saving model to model_save/weights-17-0.2372.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2372 - val_loss: 0.1949\n",
      "Epoch 18/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2360\n",
      "Epoch 00018: loss improved from 0.23723 to 0.23595, saving model to model_save/weights-18-0.2360.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2360 - val_loss: 0.1946\n",
      "Epoch 19/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2353\n",
      "Epoch 00019: loss improved from 0.23595 to 0.23529, saving model to model_save/weights-19-0.2353.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2353 - val_loss: 0.1941\n",
      "Epoch 20/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2342\n",
      "Epoch 00020: loss improved from 0.23529 to 0.23420, saving model to model_save/weights-20-0.2342.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2342 - val_loss: 0.1942\n",
      "Epoch 21/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2329\n",
      "Epoch 00021: loss improved from 0.23420 to 0.23288, saving model to model_save/weights-21-0.2329.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2329 - val_loss: 0.1928\n",
      "Epoch 22/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2320\n",
      "Epoch 00022: loss improved from 0.23288 to 0.23200, saving model to model_save/weights-22-0.2320.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2320 - val_loss: 0.1943\n",
      "Epoch 23/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2331\n",
      "Epoch 00023: loss did not improve from 0.23200\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2331 - val_loss: 0.1948\n",
      "Epoch 24/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2332\n",
      "Epoch 00024: loss did not improve from 0.23200\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2332 - val_loss: 0.1947\n",
      "Epoch 25/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2323\n",
      "Epoch 00025: loss did not improve from 0.23200\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2323 - val_loss: 0.1942\n",
      "Epoch 26/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2321\n",
      "Epoch 00026: loss did not improve from 0.23200\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2321 - val_loss: 0.1980\n",
      "Epoch 27/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2330\n",
      "Epoch 00027: loss did not improve from 0.23200\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2330 - val_loss: 0.1959\n",
      "Epoch 28/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2301\n",
      "Epoch 00028: loss improved from 0.23200 to 0.23006, saving model to model_save/weights-28-0.2301.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2301 - val_loss: 0.1929\n",
      "Epoch 29/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2285\n",
      "Epoch 00029: loss improved from 0.23006 to 0.22847, saving model to model_save/weights-29-0.2285.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2285 - val_loss: 0.1931\n",
      "Epoch 30/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2277\n",
      "Epoch 00030: loss improved from 0.22847 to 0.22770, saving model to model_save/weights-30-0.2277.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2277 - val_loss: 0.1930\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 30\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 8 epochs\n",
    "terminate_loss = EarlyStopping(monitor='loss',patience=8,verbose=1,mode='min',restore_best_weights=False)\n",
    "\n",
    "#Callback list\n",
    "callback_list=[checkpoint,tensorboard_callback,terminate_loss]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history1 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ekrJhdiEjOG5",
    "outputId": "b6edb364-d90f-419c-ebce-c01a34938b4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history1']"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history1.history,'history1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mrd7PRmjcuEp"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7ObOhaJazQcU",
    "outputId": "866a4b50-f921-4f6d-db91-ff7668c73f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 [==============================] - 24s 56ms/step - loss: 0.2084\n"
     ]
    }
   ],
   "source": [
    "train_parameters = model.evaluate([X_train_padded_docs,y_train_padded_docs[:,:-1]],y_train_padded_docs[:,1:],\n",
    "                                  verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dOq7_Vm-zjIM",
    "outputId": "ccc743c8-9418-4433-c3fa-076f499b9a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 55ms/step - loss: 0.1928\n"
     ]
    }
   ],
   "source": [
    "val_parameters = model.evaluate([X_val_padded_docs,y_val_padded_docs[:,:-1]],y_val_padded_docs[:,1:],\n",
    "                                 verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt-hIXlo7fBQ"
   },
   "outputs": [],
   "source": [
    "#Load weights\n",
    "model.load_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PuzDUjQbjOHK",
    "outputId": "054a4026-1086-455d-9fa9-28cbbf25cbc5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2159\n",
      "Epoch 00001: loss improved from inf to 0.21585, saving model to model_save/weights-01-0.2159.hdf5\n",
      "424/424 [==============================] - 73s 171ms/step - loss: 0.2159 - val_loss: 0.1818\n",
      "Epoch 2/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2116\n",
      "Epoch 00002: loss improved from 0.21585 to 0.21163, saving model to model_save/weights-02-0.2116.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.2116 - val_loss: 0.1806\n",
      "Epoch 3/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2099\n",
      "Epoch 00003: loss improved from 0.21163 to 0.20990, saving model to model_save/weights-03-0.2099.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2099 - val_loss: 0.1799\n",
      "Epoch 4/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2087\n",
      "Epoch 00004: loss improved from 0.20990 to 0.20869, saving model to model_save/weights-04-0.2087.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2087 - val_loss: 0.1793\n",
      "Epoch 5/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2075\n",
      "Epoch 00005: loss improved from 0.20869 to 0.20753, saving model to model_save/weights-05-0.2075.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2075 - val_loss: 0.1790\n",
      "Epoch 6/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2067\n",
      "Epoch 00006: loss improved from 0.20753 to 0.20673, saving model to model_save/weights-06-0.2067.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2067 - val_loss: 0.1785\n",
      "Epoch 7/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2059\n",
      "Epoch 00007: loss improved from 0.20673 to 0.20590, saving model to model_save/weights-07-0.2059.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2059 - val_loss: 0.1783\n",
      "Epoch 8/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2052\n",
      "Epoch 00008: loss improved from 0.20590 to 0.20521, saving model to model_save/weights-08-0.2052.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2052 - val_loss: 0.1780\n",
      "Epoch 9/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2045\n",
      "Epoch 00009: loss improved from 0.20521 to 0.20451, saving model to model_save/weights-09-0.2045.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2045 - val_loss: 0.1779\n",
      "Epoch 10/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2039\n",
      "Epoch 00010: loss improved from 0.20451 to 0.20391, saving model to model_save/weights-10-0.2039.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.2039 - val_loss: 0.1776\n",
      "Epoch 11/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 00011: loss improved from 0.20391 to 0.20327, saving model to model_save/weights-11-0.2033.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2033 - val_loss: 0.1775\n",
      "Epoch 12/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2027\n",
      "Epoch 00012: loss improved from 0.20327 to 0.20274, saving model to model_save/weights-12-0.2027.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.2027 - val_loss: 0.1773\n",
      "Epoch 13/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2022\n",
      "Epoch 00013: loss improved from 0.20274 to 0.20223, saving model to model_save/weights-13-0.2022.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.2022 - val_loss: 0.1772\n",
      "Epoch 14/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2016\n",
      "Epoch 00014: loss improved from 0.20223 to 0.20164, saving model to model_save/weights-14-0.2016.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.2016 - val_loss: 0.1770\n",
      "Epoch 15/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2011\n",
      "Epoch 00015: loss improved from 0.20164 to 0.20112, saving model to model_save/weights-15-0.2011.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.2011 - val_loss: 0.1769\n",
      "Epoch 16/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2007\n",
      "Epoch 00016: loss improved from 0.20112 to 0.20065, saving model to model_save/weights-16-0.2007.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.2007 - val_loss: 0.1767\n",
      "Epoch 17/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.2002\n",
      "Epoch 00017: loss improved from 0.20065 to 0.20020, saving model to model_save/weights-17-0.2002.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.2002 - val_loss: 0.1766\n",
      "Epoch 18/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1997\n",
      "Epoch 00018: loss improved from 0.20020 to 0.19972, saving model to model_save/weights-18-0.1997.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1997 - val_loss: 0.1765\n",
      "Epoch 19/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 00019: loss improved from 0.19972 to 0.19920, saving model to model_save/weights-19-0.1992.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.1992 - val_loss: 0.1762\n",
      "Epoch 20/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1988\n",
      "Epoch 00020: loss improved from 0.19920 to 0.19882, saving model to model_save/weights-20-0.1988.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1988 - val_loss: 0.1762\n",
      "Epoch 21/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1984\n",
      "Epoch 00021: loss improved from 0.19882 to 0.19840, saving model to model_save/weights-21-0.1984.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1984 - val_loss: 0.1761\n",
      "Epoch 22/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1979\n",
      "Epoch 00022: loss improved from 0.19840 to 0.19792, saving model to model_save/weights-22-0.1979.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1979 - val_loss: 0.1760\n",
      "Epoch 23/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1976\n",
      "Epoch 00023: loss improved from 0.19792 to 0.19756, saving model to model_save/weights-23-0.1976.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1976 - val_loss: 0.1760\n",
      "Epoch 24/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1972\n",
      "Epoch 00024: loss improved from 0.19756 to 0.19717, saving model to model_save/weights-24-0.1972.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.1972 - val_loss: 0.1759\n",
      "Epoch 25/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1967\n",
      "Epoch 00025: loss improved from 0.19717 to 0.19672, saving model to model_save/weights-25-0.1967.hdf5\n",
      "424/424 [==============================] - 71s 166ms/step - loss: 0.1967 - val_loss: 0.1757\n",
      "Epoch 26/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1963\n",
      "Epoch 00026: loss improved from 0.19672 to 0.19634, saving model to model_save/weights-26-0.1963.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1963 - val_loss: 0.1758\n",
      "Epoch 27/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1959\n",
      "Epoch 00027: loss improved from 0.19634 to 0.19591, saving model to model_save/weights-27-0.1959.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1959 - val_loss: 0.1757\n",
      "Epoch 28/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1956\n",
      "Epoch 00028: loss improved from 0.19591 to 0.19561, saving model to model_save/weights-28-0.1956.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1956 - val_loss: 0.1758\n",
      "Epoch 29/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1952\n",
      "Epoch 00029: loss improved from 0.19561 to 0.19521, saving model to model_save/weights-29-0.1952.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1952 - val_loss: 0.1756\n",
      "Epoch 30/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1948\n",
      "Epoch 00030: loss improved from 0.19521 to 0.19483, saving model to model_save/weights-30-0.1948.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1948 - val_loss: 0.1756\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 30\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list=[checkpoint,tensorboard_callback]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history2 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BxxR261FjOHM",
    "outputId": "e48ea5e4-1705-4b56-9362-1812cab4d446"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history2']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history2.history,'history2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUmGIJwFIdCL"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx1rwYWBIh6M"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.load_weights('best_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "feLMRaTXjOHS",
    "outputId": "838fa20c-f155-4e3b-e71a-02ba9a6f8a1c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 00001: loss improved from inf to 0.19454, saving model to model_save/weights-01-0.1945.hdf5\n",
      "424/424 [==============================] - 72s 171ms/step - loss: 0.1945 - val_loss: 0.1755\n",
      "Epoch 2/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1941\n",
      "Epoch 00002: loss improved from 0.19454 to 0.19413, saving model to model_save/weights-02-0.1941.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1941 - val_loss: 0.1754\n",
      "Epoch 3/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1938\n",
      "Epoch 00003: loss improved from 0.19413 to 0.19377, saving model to model_save/weights-03-0.1938.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1938 - val_loss: 0.1755\n",
      "Epoch 4/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1934\n",
      "Epoch 00004: loss improved from 0.19377 to 0.19339, saving model to model_save/weights-04-0.1934.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1934 - val_loss: 0.1755\n",
      "Epoch 5/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00005: loss improved from 0.19339 to 0.19306, saving model to model_save/weights-05-0.1931.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1931 - val_loss: 0.1754\n",
      "Epoch 6/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1927\n",
      "Epoch 00006: loss improved from 0.19306 to 0.19269, saving model to model_save/weights-06-0.1927.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1927 - val_loss: 0.1753\n",
      "Epoch 7/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1925\n",
      "Epoch 00007: loss improved from 0.19269 to 0.19248, saving model to model_save/weights-07-0.1925.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1925 - val_loss: 0.1754\n",
      "Epoch 8/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1920\n",
      "Epoch 00008: loss improved from 0.19248 to 0.19204, saving model to model_save/weights-08-0.1920.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1920 - val_loss: 0.1753\n",
      "Epoch 9/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00009: loss improved from 0.19204 to 0.19177, saving model to model_save/weights-09-0.1918.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1918 - val_loss: 0.1754\n",
      "Epoch 10/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00010: loss improved from 0.19177 to 0.19141, saving model to model_save/weights-10-0.1914.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1914 - val_loss: 0.1753\n",
      "Epoch 11/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00011: loss improved from 0.19141 to 0.19109, saving model to model_save/weights-11-0.1911.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1911 - val_loss: 0.1753\n",
      "Epoch 12/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00012: loss improved from 0.19109 to 0.19078, saving model to model_save/weights-12-0.1908.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1908 - val_loss: 0.1752\n",
      "Epoch 13/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1904\n",
      "Epoch 00013: loss improved from 0.19078 to 0.19044, saving model to model_save/weights-13-0.1904.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1904 - val_loss: 0.1753\n",
      "Epoch 14/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1901\n",
      "Epoch 00014: loss improved from 0.19044 to 0.19012, saving model to model_save/weights-14-0.1901.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1901 - val_loss: 0.1754\n",
      "Epoch 15/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1898\n",
      "Epoch 00015: loss improved from 0.19012 to 0.18982, saving model to model_save/weights-15-0.1898.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1898 - val_loss: 0.1753\n",
      "Epoch 16/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1894\n",
      "Epoch 00016: loss improved from 0.18982 to 0.18945, saving model to model_save/weights-16-0.1894.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1894 - val_loss: 0.1753\n",
      "Epoch 17/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1892\n",
      "Epoch 00017: loss improved from 0.18945 to 0.18921, saving model to model_save/weights-17-0.1892.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1892 - val_loss: 0.1753\n",
      "Epoch 18/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1888\n",
      "Epoch 00018: loss improved from 0.18921 to 0.18883, saving model to model_save/weights-18-0.1888.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1888 - val_loss: 0.1755\n",
      "Epoch 19/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1886\n",
      "Epoch 00019: loss improved from 0.18883 to 0.18860, saving model to model_save/weights-19-0.1886.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1886 - val_loss: 0.1752\n",
      "Epoch 20/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 00020: loss improved from 0.18860 to 0.18821, saving model to model_save/weights-20-0.1882.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1882 - val_loss: 0.1756\n",
      "Epoch 21/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1879\n",
      "Epoch 00021: loss improved from 0.18821 to 0.18790, saving model to model_save/weights-21-0.1879.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1879 - val_loss: 0.1753\n",
      "Epoch 22/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1876\n",
      "Epoch 00022: loss improved from 0.18790 to 0.18761, saving model to model_save/weights-22-0.1876.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1876 - val_loss: 0.1753\n",
      "Epoch 23/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1873\n",
      "Epoch 00023: loss improved from 0.18761 to 0.18733, saving model to model_save/weights-23-0.1873.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1873 - val_loss: 0.1752\n",
      "Epoch 24/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1870\n",
      "Epoch 00024: loss improved from 0.18733 to 0.18701, saving model to model_save/weights-24-0.1870.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1870 - val_loss: 0.1754\n",
      "Epoch 25/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 00025: loss improved from 0.18701 to 0.18677, saving model to model_save/weights-25-0.1868.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1868 - val_loss: 0.1755\n",
      "Epoch 26/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1864\n",
      "Epoch 00026: loss improved from 0.18677 to 0.18640, saving model to model_save/weights-26-0.1864.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1864 - val_loss: 0.1756\n",
      "Epoch 27/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1862\n",
      "Epoch 00027: loss improved from 0.18640 to 0.18619, saving model to model_save/weights-27-0.1862.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1862 - val_loss: 0.1754\n",
      "Epoch 28/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1858\n",
      "Epoch 00028: loss improved from 0.18619 to 0.18585, saving model to model_save/weights-28-0.1858.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1858 - val_loss: 0.1756\n",
      "Epoch 29/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1856\n",
      "Epoch 00029: loss improved from 0.18585 to 0.18560, saving model to model_save/weights-29-0.1856.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1856 - val_loss: 0.1755\n",
      "Epoch 30/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1853\n",
      "Epoch 00030: loss improved from 0.18560 to 0.18527, saving model to model_save/weights-30-0.1853.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1853 - val_loss: 0.1755\n",
      "Epoch 31/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1851\n",
      "Epoch 00031: loss improved from 0.18527 to 0.18505, saving model to model_save/weights-31-0.1851.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1851 - val_loss: 0.1755\n",
      "Epoch 32/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1846\n",
      "Epoch 00032: loss improved from 0.18505 to 0.18462, saving model to model_save/weights-32-0.1846.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1846 - val_loss: 0.1755\n",
      "Epoch 33/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1844\n",
      "Epoch 00033: loss improved from 0.18462 to 0.18438, saving model to model_save/weights-33-0.1844.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1844 - val_loss: 0.1755\n",
      "Epoch 34/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1841\n",
      "Epoch 00034: loss improved from 0.18438 to 0.18410, saving model to model_save/weights-34-0.1841.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1841 - val_loss: 0.1756\n",
      "Epoch 35/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1838\n",
      "Epoch 00035: loss improved from 0.18410 to 0.18377, saving model to model_save/weights-35-0.1838.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1838 - val_loss: 0.1759\n",
      "Epoch 36/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 00036: loss improved from 0.18377 to 0.18349, saving model to model_save/weights-36-0.1835.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1835 - val_loss: 0.1757\n",
      "Epoch 37/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1832\n",
      "Epoch 00037: loss improved from 0.18349 to 0.18320, saving model to model_save/weights-37-0.1832.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1832 - val_loss: 0.1758\n",
      "Epoch 38/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1829\n",
      "Epoch 00038: loss improved from 0.18320 to 0.18291, saving model to model_save/weights-38-0.1829.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1829 - val_loss: 0.1757\n",
      "Epoch 39/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 00039: loss improved from 0.18291 to 0.18267, saving model to model_save/weights-39-0.1827.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1827 - val_loss: 0.1758\n",
      "Epoch 40/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1824\n",
      "Epoch 00040: loss improved from 0.18267 to 0.18244, saving model to model_save/weights-40-0.1824.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1824 - val_loss: 0.1756\n",
      "Epoch 41/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1822\n",
      "Epoch 00041: loss improved from 0.18244 to 0.18217, saving model to model_save/weights-41-0.1822.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1822 - val_loss: 0.1760\n",
      "Epoch 42/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1818\n",
      "Epoch 00042: loss improved from 0.18217 to 0.18185, saving model to model_save/weights-42-0.1818.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1818 - val_loss: 0.1758\n",
      "Epoch 43/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 00043: loss improved from 0.18185 to 0.18154, saving model to model_save/weights-43-0.1815.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1815 - val_loss: 0.1758\n",
      "Epoch 44/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1812\n",
      "Epoch 00044: loss improved from 0.18154 to 0.18123, saving model to model_save/weights-44-0.1812.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1812 - val_loss: 0.1759\n",
      "Epoch 45/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1810\n",
      "Epoch 00045: loss improved from 0.18123 to 0.18100, saving model to model_save/weights-45-0.1810.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1810 - val_loss: 0.1759\n",
      "Epoch 46/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1808\n",
      "Epoch 00046: loss improved from 0.18100 to 0.18078, saving model to model_save/weights-46-0.1808.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1808 - val_loss: 0.1761\n",
      "Epoch 47/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 00047: loss improved from 0.18078 to 0.18042, saving model to model_save/weights-47-0.1804.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1804 - val_loss: 0.1760\n",
      "Epoch 48/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1802\n",
      "Epoch 00048: loss improved from 0.18042 to 0.18023, saving model to model_save/weights-48-0.1802.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1802 - val_loss: 0.1758\n",
      "Epoch 49/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1799\n",
      "Epoch 00049: loss improved from 0.18023 to 0.17991, saving model to model_save/weights-49-0.1799.hdf5\n",
      "424/424 [==============================] - 71s 168ms/step - loss: 0.1799 - val_loss: 0.1763\n",
      "Epoch 50/50\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1797\n",
      "Epoch 00050: loss improved from 0.17991 to 0.17967, saving model to model_save/weights-50-0.1797.hdf5\n",
      "424/424 [==============================] - 71s 167ms/step - loss: 0.1797 - val_loss: 0.1763\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 50\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list=[checkpoint,tensorboard_callback]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history3 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1Z98ZWfFIQy5",
    "outputId": "daa45fe4-3581-4c7d-8c35-e523c7dff747"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history3']"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history3.history,'history3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAht63JTbf4M"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPsKE7Yvbf4X"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.load_weights('best_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-lkupW8Ebf4a",
    "outputId": "8b54516e-bca8-4c13-cbfc-8ea89f9cc101",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 00001: loss improved from inf to 0.17945, saving model to model_save/weights-01-0.1795.hdf5\n",
      "424/424 [==============================] - 72s 169ms/step - loss: 0.1795 - val_loss: 0.1761\n",
      "Epoch 2/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1791\n",
      "Epoch 00002: loss improved from 0.17945 to 0.17907, saving model to model_save/weights-02-0.1791.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1791 - val_loss: 0.1764\n",
      "Epoch 3/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1788\n",
      "Epoch 00003: loss improved from 0.17907 to 0.17883, saving model to model_save/weights-03-0.1788.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1788 - val_loss: 0.1764\n",
      "Epoch 4/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 00004: loss improved from 0.17883 to 0.17858, saving model to model_save/weights-04-0.1786.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1786 - val_loss: 0.1765\n",
      "Epoch 5/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 00005: loss improved from 0.17858 to 0.17832, saving model to model_save/weights-05-0.1783.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1783 - val_loss: 0.1767\n",
      "Epoch 6/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 00006: loss improved from 0.17832 to 0.17812, saving model to model_save/weights-06-0.1781.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1781 - val_loss: 0.1766\n",
      "Epoch 7/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 00007: loss improved from 0.17812 to 0.17788, saving model to model_save/weights-07-0.1779.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1779 - val_loss: 0.1765\n",
      "Epoch 8/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 00008: loss improved from 0.17788 to 0.17762, saving model to model_save/weights-08-0.1776.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1776 - val_loss: 0.1766\n",
      "Epoch 9/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1772\n",
      "Epoch 00009: loss improved from 0.17762 to 0.17724, saving model to model_save/weights-09-0.1772.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1772 - val_loss: 0.1770\n",
      "Epoch 10/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1771\n",
      "Epoch 00010: loss improved from 0.17724 to 0.17712, saving model to model_save/weights-10-0.1771.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1771 - val_loss: 0.1768\n",
      "Epoch 11/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 00011: loss improved from 0.17712 to 0.17687, saving model to model_save/weights-11-0.1769.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1769 - val_loss: 0.1769\n",
      "Epoch 12/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1766\n",
      "Epoch 00012: loss improved from 0.17687 to 0.17659, saving model to model_save/weights-12-0.1766.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1766 - val_loss: 0.1772\n",
      "Epoch 13/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1763\n",
      "Epoch 00013: loss improved from 0.17659 to 0.17634, saving model to model_save/weights-13-0.1763.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1763 - val_loss: 0.1772\n",
      "Epoch 14/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1760\n",
      "Epoch 00014: loss improved from 0.17634 to 0.17602, saving model to model_save/weights-14-0.1760.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1760 - val_loss: 0.1773\n",
      "Epoch 15/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1758\n",
      "Epoch 00015: loss improved from 0.17602 to 0.17580, saving model to model_save/weights-15-0.1758.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1758 - val_loss: 0.1772\n",
      "Epoch 16/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1756\n",
      "Epoch 00016: loss improved from 0.17580 to 0.17560, saving model to model_save/weights-16-0.1756.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1756 - val_loss: 0.1775\n",
      "Epoch 17/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1753\n",
      "Epoch 00017: loss improved from 0.17560 to 0.17528, saving model to model_save/weights-17-0.1753.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1753 - val_loss: 0.1775\n",
      "Epoch 18/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 00018: loss improved from 0.17528 to 0.17508, saving model to model_save/weights-18-0.1751.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1751 - val_loss: 0.1774\n",
      "Epoch 19/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1749\n",
      "Epoch 00019: loss improved from 0.17508 to 0.17487, saving model to model_save/weights-19-0.1749.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1749 - val_loss: 0.1774\n",
      "Epoch 20/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1746\n",
      "Epoch 00020: loss improved from 0.17487 to 0.17455, saving model to model_save/weights-20-0.1746.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1746 - val_loss: 0.1776\n",
      "Epoch 21/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 00021: loss improved from 0.17455 to 0.17438, saving model to model_save/weights-21-0.1744.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1744 - val_loss: 0.1778\n",
      "Epoch 22/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1741\n",
      "Epoch 00022: loss improved from 0.17438 to 0.17410, saving model to model_save/weights-22-0.1741.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1741 - val_loss: 0.1779\n",
      "Epoch 23/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1739\n",
      "Epoch 00023: loss improved from 0.17410 to 0.17390, saving model to model_save/weights-23-0.1739.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1739 - val_loss: 0.1780\n",
      "Epoch 24/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 00024: loss improved from 0.17390 to 0.17360, saving model to model_save/weights-24-0.1736.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1736 - val_loss: 0.1777\n",
      "Epoch 25/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1734\n",
      "Epoch 00025: loss improved from 0.17360 to 0.17338, saving model to model_save/weights-25-0.1734.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1734 - val_loss: 0.1781\n",
      "Epoch 26/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1732\n",
      "Epoch 00026: loss improved from 0.17338 to 0.17317, saving model to model_save/weights-26-0.1732.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1732 - val_loss: 0.1782\n",
      "Epoch 27/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1729\n",
      "Epoch 00027: loss improved from 0.17317 to 0.17287, saving model to model_save/weights-27-0.1729.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1729 - val_loss: 0.1782\n",
      "Epoch 28/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 00028: loss improved from 0.17287 to 0.17270, saving model to model_save/weights-28-0.1727.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1727 - val_loss: 0.1783\n",
      "Epoch 29/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 00029: loss improved from 0.17270 to 0.17239, saving model to model_save/weights-29-0.1724.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1724 - val_loss: 0.1783\n",
      "Epoch 30/30\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1722\n",
      "Epoch 00030: loss improved from 0.17239 to 0.17221, saving model to model_save/weights-30-0.1722.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1722 - val_loss: 0.1785\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 30\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callback_list=[checkpoint]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],\n",
    "                       BATCH_SIZE=BATCH_SIZE,shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history4 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gx1s-6jqIRDi",
    "outputId": "ddd11c46-7015-4009-c63b-ee3cace35b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history4']"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history4.history,'history4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuCZDcc2IQ9_"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "id": "WZn7ndQga-dx",
    "outputId": "92a849ae-7550-4717-9dbd-b3fec96044f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1713\n",
      "Epoch 00001: loss improved from inf to 0.17130, saving model to model_save/weights-01-0.1713.hdf5\n",
      "424/424 [==============================] - 72s 171ms/step - loss: 0.1713 - val_loss: 0.1770 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 00002: loss improved from 0.17130 to 0.17041, saving model to model_save/weights-02-0.1704.hdf5\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1704 - val_loss: 0.1769 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 00003: loss improved from 0.17041 to 0.17021, saving model to model_save/weights-03-0.1702.hdf5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1702 - val_loss: 0.1769 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1701\n",
      "Epoch 00004: loss improved from 0.17021 to 0.17006, saving model to model_save/weights-04-0.1701.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1701 - val_loss: 0.1770 - lr: 9.0000e-05\n",
      "Epoch 5/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 00005: loss improved from 0.17006 to 0.17005, saving model to model_save/weights-05-0.1700.hdf5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1700 - val_loss: 0.1771 - lr: 9.0000e-05\n",
      "Epoch 6/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 00006: loss improved from 0.17005 to 0.16994, saving model to model_save/weights-06-0.1699.hdf5\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1699 - val_loss: 0.1771 - lr: 8.1000e-05\n",
      "Epoch 7/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 00007: loss improved from 0.16994 to 0.16994, saving model to model_save/weights-07-0.1699.hdf5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1699 - val_loss: 0.1771 - lr: 8.1000e-05\n",
      "Epoch 8/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 00008: loss did not improve from 0.16994\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1700 - val_loss: 0.1772 - lr: 7.2900e-05\n",
      "Epoch 9/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 00009: loss improved from 0.16994 to 0.16987, saving model to model_save/weights-09-0.1699.hdf5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
      "424/424 [==============================] - 70s 165ms/step - loss: 0.1699 - val_loss: 0.1771 - lr: 7.2900e-05\n",
      "Epoch 10/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 00010: loss did not improve from 0.16987\n",
      "Restoring model weights from the end of the best epoch.\n",
      "424/424 [==============================] - 70s 166ms/step - loss: 0.1699 - val_loss: 0.1771 - lr: 6.5610e-05\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 15\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.0001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Reduce learning rate by 10% if validation loss does not decrease from last 2 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, verbose=1, patience=2,min_lr=0.00001)\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 8 epochs\n",
    "terminate = EarlyStopping(monitor='val_loss',patience=8,verbose=1,mode='min',restore_best_weights=True)\n",
    "\n",
    "callback_list=[checkpoint,reduce_lr,terminate]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],\n",
    "                       BATCH_SIZE=BATCH_SIZE,shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history5 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-5xuuYlea-cD",
    "outputId": "74adbcc6-dea6-4c20-bd69-24a1a14d8e83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history5']"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history5.history,'history5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AeUY01ya-ZN"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ArybbQ8hT20t",
    "outputId": "bcb7a919-e2ce-4c44-f2d8-1a60529cb0f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 [==============================] - 24s 56ms/step - loss: 0.1489\n"
     ]
    }
   ],
   "source": [
    "train_parameters = model.evaluate([X_train_padded_docs,y_train_padded_docs[:,:-1]],y_train_padded_docs[:,1:],\n",
    "                                  verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a3nA1ZjeT20x",
    "outputId": "7eebad5a-2c01-4a1a-976b-b78a8cb38d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 55ms/step - loss: 0.1768\n"
     ]
    }
   ],
   "source": [
    "val_parameters = model.evaluate([X_val_padded_docs,y_val_padded_docs[:,:-1]],y_val_padded_docs[:,1:],\n",
    "                                 verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqNXppQdRtZI"
   },
   "outputs": [],
   "source": [
    "h1 = joblib.load('history1')\n",
    "h2 = joblib.load('history2')\n",
    "h3 = joblib.load('history3')\n",
    "h4 = joblib.load('history4')\n",
    "h5 = joblib.load('history5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRv5nhtcRyaz"
   },
   "outputs": [],
   "source": [
    "loss = h1['loss']+h2['loss']+h3['loss']+h4['loss']+h5['loss']\n",
    "val_loss = h1['val_loss']+h2['val_loss']+h3['val_loss']+h4['val_loss']+h5['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "-3JnSRmPRyZL",
    "outputId": "1f575173-5300-4f9a-8e31-379e32e21825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Vs No of epochs')"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss,label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('No of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Vs No of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvvc3q93L7In"
   },
   "outputs": [],
   "source": [
    "#Generate 1000 random samples from train and val data\n",
    "#Train data\n",
    "train_index = []\n",
    "for i in range(X_train_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_train_padded_docs[i]!=0)>70:\n",
    "        train_index.append(i)\n",
    "train_index = random.sample(train_index,1000)\n",
    "\n",
    "#Validation data\n",
    "#Train data\n",
    "val_index = []\n",
    "for i in range(X_val_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_val_padded_docs[i]!=0)>70:\n",
    "        val_index.append(i)\n",
    "val_index = random.sample(val_index,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "3cf2f8e430254d94be82b2be91b5a371",
      "d442c81f5a164f3f88b14979fdcf0667",
      "12101f81f0534cf3a5a7fa56b928ec35",
      "fe13d92887dc4fe9b3c66874ccfb1524",
      "13d19626343b4384babd116f222a603f",
      "1b95b38bf4584deb8b4798a0e6d3fe33",
      "3ded593da51549b59af267610944fa43",
      "ee66e4045deb4451a5254ecf9d48f6c5"
     ]
    },
    "colab_type": "code",
    "id": "muqMywldL7Iq",
    "outputId": "c02c5939-0899-4cac-b1ce-29398cac4f53",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf2f8e430254d94be82b2be91b5a371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # this website will reduce training costs and increase availability of training t *\n",
      "Actual words: # o all employees *\n",
      "Predicted words: # o the company *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # i will not assume that you want to play unless you send me a confirmation ema *\n",
      "Actual words: # il *\n",
      "Predicted words: # il *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # i have attached the bill for your review but a more detailed analysis wi *\n",
      "Actual words: # ll follow *\n",
      "Predicted words: # th the conference *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # first thank you all for your hard work this last week and in advance for the next we *\n",
      "Actual words: # eks to come *\n",
      "Predicted words: # ek *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # i would like to have several participants from our team in this first *\n",
      "Actual words: #  session *\n",
      "Predicted words: #  things *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # please do not hesitate to contact me directly if you need any further infor *\n",
      "Actual words: # mation from me *\n",
      "Predicted words: # mation *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # he is ready and willing to be here any day we have something to discuss with h *\n",
      "Actual words: # im *\n",
      "Predicted words: # ave the conference *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # if we decide so to use the floor we could get this done within a coupl *\n",
      "Actual words: # e of weeks at most *\n",
      "Predicted words: # e of days *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # were very busy at work and will continue to be so through the rest  *\n",
      "Actual words: # of the year *\n",
      "Predicted words: # of the day *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # please feel free to contact me if you have any questions or need any assistance prior  *\n",
      "Actual words: # to your trip *\n",
      "Predicted words: # the attached *\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For train data, actual and predicted words\n",
    "train_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_train_padded_docs[train_index,:],y_train_padded_docs[train_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    train_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "9fd5aa186a974f40a00840972e67520d",
      "59542b89f1174c56a093027d76e8e8d5",
      "51c7998555644ecaa1e853dbd1d58f54",
      "14c69cf8a247444e9d6268179d523402",
      "89648b655e3c4fa6ac72e2b1ca2e74cb",
      "55f5855c3de446cfa5096f59fdbb6d17",
      "656e9181e931444299b9878e4a779047",
      "5cb2539fb5bf4236a74b0672ae5aa886"
     ]
    },
    "colab_type": "code",
    "id": "o2B9_PCSL7Is",
    "outputId": "7e5c62ae-719a-438c-801c-85e7ce4750b6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd5aa186a974f40a00840972e67520d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # also prepare to have your markets covered when you leave the office ear *\n",
      "Actual words: # ly *\n",
      "Predicted words: # liest convenience *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # they want to answer the customer within a week so they will need this informat *\n",
      "Actual words: # ion at least by early next week *\n",
      "Predicted words: # ion *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # a hard copy would be much appreciated but if need be please send vi *\n",
      "Actual words: # a email *\n",
      "Predicted words: # ew *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # i understand that you are busy so please take your time in getting back with the requested inform *\n",
      "Actual words: # ation *\n",
      "Predicted words: # ation *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # for full program details and to register please visit our website ww *\n",
      "Actual words: # w *\n",
      "Predicted words: # w *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # we then began to discuss what we needed to have and what was already present in the cu *\n",
      "Actual words: # rrent system *\n",
      "Predicted words: # rrent *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # if you have any questions or comments about this new report do not hesitate to bring *\n",
      "Actual words: #  them to my attention *\n",
      "Predicted words: #  the attached *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # they want to answer the customer within a week so they will need this information at least  *\n",
      "Actual words: # by early next week *\n",
      "Predicted words: # the company *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # please use both files when considering my performance for the whole yea *\n",
      "Actual words: # r *\n",
      "Predicted words: # r *\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: # we will continue to bring you valuable offers on the products and services tha *\n",
      "Actual words: # t interest you most *\n",
      "Predicted words: # t we can *\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For validation data actual and predicted words\n",
    "val_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_val_padded_docs[val_index,:],y_val_padded_docs[val_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    val_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "EvU7rH7IL7Iy",
    "outputId": "348f79be-d524-41df-a9df-227d9da2dca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for train data of 1000 samples: 0.698\n",
      "BLEU Score for validation data of 1000 samples: 0.689\n"
     ]
    }
   ],
   "source": [
    "#Average BLEU Score for sentences\n",
    "print('BLEU Score for train data of 1000 samples:',np.round(sum(train_bleu_list)/len(train_bleu_list),3))\n",
    "print('BLEU Score for validation data of 1000 samples:',np.round(sum(val_bleu_list)/len(val_bleu_list),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xqdMoy5cuFl"
   },
   "source": [
    "<h1>4. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgjJobuUcuFl"
   },
   "outputs": [],
   "source": [
    "def predict_sentence(enc_dec_model,input_sentence):\n",
    "    \n",
    "    #Maximum sequence length for input and target sentence\n",
    "    input_max_length = X_train_padded_docs.shape[1]\n",
    "    output_max_length = y_train_padded_docs.shape[1]\n",
    "\n",
    "    input_sentence = '# ' + input_sentence + ' *'\n",
    "    \n",
    "    #Convert texts to sequences\n",
    "    sent = tokenizer.texts_to_sequences([input_sentence])\n",
    "    #Pad data\n",
    "    sent = tf.keras.preprocessing.sequence.pad_sequences(sent,maxlen=input_max_length,padding='post')\n",
    "    \n",
    "    #print('Encoder input shape (batch_size,sequence length):',sent.shape)\n",
    "    enc_hidden,enc_cell = enc_dec_model.layers[0](sent)\n",
    "    #print('Encoder hidden state shape (batch_size,units):',enc_hidden.shape)\n",
    "    #print('Encoder cell state shape (batch_size,units):',enc_cell.shape)\n",
    "    #print(90*'-')\n",
    "    \n",
    "    #Boundary case\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['#']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    #print('Decoder input shape (batch_size,1):',dec_input.shape)\n",
    "    #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "    #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    output_sent = ''\n",
    "    \n",
    "    for i in range(output_max_length-1):\n",
    "        #Get prediction from onestep_decoder\n",
    "        dec_output,dec_hidden,dec_cell = enc_dec_model.layers[1](dec_input,dec_hidden,dec_cell)\n",
    "        #print('Decoder output shape (batch_size,vocab_size):',dec_output.shape)\n",
    "        #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "        #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    \n",
    "        #Get prediction from dense layer\n",
    "        #Shape == (batch_size,timestep,vocab_size) == (1,1,30)\n",
    "        outputs = enc_dec_model.layers[3](dec_output)\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = np.argmax(outputs.numpy().reshape(-1))\n",
    "        \n",
    "        #Get word corresponding to index\n",
    "        output_sent+=tokenizer.index_word[key]\n",
    "        \n",
    "        if tokenizer.index_word[key] == '*':\n",
    "            return output_sent\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    return output_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tbVttk15Wx-m",
    "outputId": "1a032a0d-cf06-47af-d15a-a960d8be0dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  the conference call *'"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'thank you for')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fi7OT3XCWx-t",
    "outputId": "a406fd76-c430-4a46-d8f4-5402863b1e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  will be a good time *'"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'hope it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dysFablEWx-w",
    "outputId": "7e9a2d37-de02-476f-b258-d95f1c41bfd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  me a call *'"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'can you give')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DIgD44y6Wx-0",
    "outputId": "bedd011b-b713-46fe-86cc-ded13fe43f6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  a call if you have any questions or comments *'"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'give me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jbug0uI7Wx-3",
    "outputId": "44073241-b41b-420c-cf00-a60820a0e82d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' able to discuss this *'"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'are you avail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>Encoder Decoder Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "Mth7qnVvxDaZ",
    "outputId": "26590d14-eca1-4226-9c4d-073355d30cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-05 04:43:21--  https://doc-08-44-docs.googleusercontent.com/docs/securesc/oik9lo733t355n1nglla0cdlqj79umtt/tv4k6lhqh609hsumjakcisnk9ol47fpj/1591332150000/02963250765125473783/00136369994752382157/1AdAgXbmDo9eDellva8bClMYUsiH5LNo4?e=download&authuser=0\n",
      "Resolving doc-08-44-docs.googleusercontent.com (doc-08-44-docs.googleusercontent.com)... 64.233.184.132, 2a00:1450:400c:c0b::84\n",
      "Connecting to doc-08-44-docs.googleusercontent.com (doc-08-44-docs.googleusercontent.com)|64.233.184.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘char_encoded_data’\n",
      "\n",
      "char_encoded_data       [   <=>              ]  44.83M  52.1MB/s    in 0.9s    \n",
      "\n",
      "2020-06-05 04:43:23 (52.1 MB/s) - ‘char_encoded_data’ saved [47013427]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-08-44-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://drive.google.com/drive/u/0/folders/1Lze5wKSp2c3rurUo8iet5RgNygcOyW1Z\" --header=\"Cookie: AUTH_bfhjrtscq695ib7edi83p6bfm42sd929=00136369994752382157|1591332075000|khsiv584fse14fsp6qp1a1iov04jc9gc; _ga=GA1.2.1509677474.1591248567; _gid=GA1.2.195823905.1591248567\" --header=\"Connection: keep-alive\" \"https://doc-08-44-docs.googleusercontent.com/docs/securesc/oik9lo733t355n1nglla0cdlqj79umtt/tv4k6lhqh609hsumjakcisnk9ol47fpj/1591332150000/02963250765125473783/00136369994752382157/1AdAgXbmDo9eDellva8bClMYUsiH5LNo4?e=download&authuser=0\" -c -O 'char_encoded_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPcS3aGjw8KV"
   },
   "source": [
    "<h1>1. Read Featurized data</h1> \n",
    "<h2>(Refer Character Featurization Section 3 of 2_Data_Preparation.ipynb)</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDfzcCAIcuCy"
   },
   "outputs": [],
   "source": [
    "[X_train_padded_docs,y_train_padded_docs,X_val_padded_docs,y_val_padded_docs,\n",
    "                                             embedding_matrix,tokenizer] = joblib.load('char_encoded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gi9gVXkcuCy"
   },
   "source": [
    "<h1>2. Define Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icMEwKexcuC2"
   },
   "source": [
    "<h2>2.1. Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgtZmDqYcuC6"
   },
   "outputs": [],
   "source": [
    "#Encoder class\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,enc_units,**kwargs):\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim,weights=[embedding_matrix],\n",
    "                                   mask_zero=True,name='Encoder_Embedding_layer')\n",
    "        self.lstm = LSTM(self.enc_units,return_sequences=True,return_state=True,name='Encoder_LSTM',dropout=0.33)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        #state_h = Hidden state output of last time step (Output of last time step)\n",
    "        #state_c = Cell state output of last time step\n",
    "        lstm_out, state_h, state_c = self.lstm(x)\n",
    "        return lstm_out, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uc064MCCcuC_",
    "outputId": "eac03827-57d5-4e59-e511-59e01cfea2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocab size:',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "P_xpJvvccuDE",
    "outputId": "9112eee7-8115-4c6f-a592-2e385780b4a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch input data (batch_size,sequence length): (32, 53)\n",
      "Shape of batch output data (batch_size,sequence length): (32, 53)\n",
      "Shape of encoder output (batch_size,sequence length,units): (32, 53, 128)\n",
      "Shape of hidden state output of last time step (batch_size,units): (32, 128)\n",
      "Shape of memory state output of last time step (batch_size,units): (32, 128)\n"
     ]
    }
   ],
   "source": [
    "#Create encoder object\n",
    "BATCH_SIZE = 32\n",
    "encoder = Encoder(vocab_size=vocab_size,embedding_dim=300,embedding_matrix=embedding_matrix,\n",
    "                  enc_units=128,name='Encoder')\n",
    "\n",
    "#Get data from data generator\n",
    "example_input_batch, example_target_batch = X_train_padded_docs[:BATCH_SIZE], y_train_padded_docs[:BATCH_SIZE]\n",
    "print('Shape of batch input data (batch_size,sequence length):',example_input_batch.shape)\n",
    "print('Shape of batch output data (batch_size,sequence length):',example_target_batch.shape)\n",
    "\n",
    "#Genearte sample ouptput and hidden state from encoder object\n",
    "sample_output, sample_hidden_output, sample_cell_output = encoder(example_input_batch)\n",
    "print('Shape of encoder output (batch_size,sequence length,units):',sample_output.shape)\n",
    "print('Shape of hidden state output of last time step (batch_size,units):',sample_hidden_output.shape)\n",
    "print('Shape of memory state output of last time step (batch_size,units):',sample_cell_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGFLsbQOcuDJ"
   },
   "source": [
    "<h2>2.2. Attention layer</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rp9SoJz2cuDK"
   },
   "source": [
    "For a particular time step of Decoder, the attention layer takes the output from the encoder (output at all time steps) and decoder output (hidden state output of decoder) at previous time step and computes the context vector. The context vector concatenated with the decoder output of previous time step is given as an input to the decoder for the current time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMN95hW8w8Kv"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.units = units\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "        \n",
    "    def call(self, hs, ht):\n",
    "        #hs = Encoder output at all time steps\n",
    "        #ht = Decoder output at last time step (Hidden state output of decoder at last time step)\n",
    "        #Add time axis to ht, this is done to perform broadcast addition along time axis to calculate score\n",
    "        #hs shape == (batch size,max_length,hidden size)\n",
    "        #ht shape == (batch size,hidden size)\n",
    "        #ht_with_time_axis shape == (batch size,1,hidden size)\n",
    "        ht_with_time_axis = tf.expand_dims(ht, axis=1)\n",
    "        \n",
    "        #score shape == (batch size, max_length, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(ht_with_time_axis) + self.W2(hs)))\n",
    "        \n",
    "        #Softmaxing the scores to get attention weights (alpha's)\n",
    "        #attention_weights shape == (batch size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        #Get context vector\n",
    "        #context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * hs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "uw8EUNgXw8Kz",
    "outputId": "133614ae-920b-4a6b-e382-e89f0f431210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of context vector (batch_size,units): (32, 128)\n",
      "Shape of attention weights (batch_size,sequence length,1): (32, 53, 1)\n"
     ]
    }
   ],
   "source": [
    "#Initalise Attention\n",
    "attention_layer = BahdanauAttention(units=128)\n",
    "sample_context_vector, sample_attention_weights = attention_layer(sample_output,sample_hidden_output)\n",
    "print('Shape of context vector (batch_size,units):',sample_context_vector.shape)\n",
    "print('Shape of attention weights (batch_size,sequence length,1):',sample_attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWTi0DbhcuDf"
   },
   "source": [
    "<h2>2.3. Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOymahJ7cuDg"
   },
   "source": [
    "<h3>2.3.1. One Step Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxVxxpnbcuDg"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,dec_units,att_units):\n",
    "        super(OneStepDecoder, self).__init__()\n",
    "        self.attention = BahdanauAttention(units=att_units)\n",
    "        self.embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim,weights=[embedding_matrix],mask_zero=True,\n",
    "                                   name='Decoder_Embedding_layer')\n",
    "        self.lstm = LSTM(dec_units,return_sequences=False,return_state=True,name='Decoder_LSTM',dropout=0.33)\n",
    "        self.drop = Dropout(0.2)\n",
    "        self.fc = Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x, hidden, cell, enc_output):\n",
    "        #enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(enc_output,hidden)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the LSTM\n",
    "        output, state_h, state_c = self.lstm(x,initial_state=[hidden,cell])\n",
    "        \n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state_h, state_c, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "b9pinu5acuDv",
    "outputId": "9f23779a-5b4e-459e-a8bd-8b96498444db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Step Decoder with Attention:\n",
      "Shape of decoder output (batch_size,vocab_size): (32, 30)\n",
      "Shape of decoder hidden state output (batch_size,units): (32, 128)\n",
      "Shape of decoder memory state output (batch_size,units): (32, 128)\n",
      "Shape of attention weights (batch_size,sequence length,1): (32, 53, 1)\n"
     ]
    }
   ],
   "source": [
    "#Initialise one step decoder with attention\n",
    "BATCH_SIZE = 32\n",
    "osd = OneStepDecoder(vocab_size=vocab_size,embedding_dim=300,embedding_matrix=embedding_matrix,dec_units=128,att_units=128)\n",
    "\n",
    "#Input to decoder for first time step\n",
    "dec_input = tf.expand_dims([tokenizer.word_index['#']] * BATCH_SIZE, 1)\n",
    "\n",
    "#Geneate sample output, hidden states and attention weights from decoder object\n",
    "sample_output_dec,sample_hidden_output_dec,sample_cell_output_dec,sample_attention_weights = osd(dec_input,\n",
    "                                                                                                 sample_hidden_output, \n",
    "                                                                                                 sample_cell_output,\n",
    "                                                                                                 sample_output)\n",
    "print('One Step Decoder with Attention:')\n",
    "print('Shape of decoder output (batch_size,vocab_size):',sample_output_dec.shape)\n",
    "print('Shape of decoder hidden state output (batch_size,units):',sample_hidden_output_dec.shape)\n",
    "print('Shape of decoder memory state output (batch_size,units):',sample_cell_output_dec.shape)\n",
    "print('Shape of attention weights (batch_size,sequence length,1):',sample_attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZxADS2EcuD8"
   },
   "source": [
    "<h3>2.3.2. Decoder for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiG649pXcuD9"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,dec_units,att_units,**kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.att_units = att_units\n",
    "        self.onestep_decoder = OneStepDecoder(vocab_size=self.vocab_size,embedding_dim=self.embedding_dim,\n",
    "                                              embedding_matrix=embedding_matrix,\n",
    "                                              dec_units=self.dec_units,\n",
    "                                              att_units=self.att_units)\n",
    "        \n",
    "    #@tf.function\n",
    "    def call(self,decoder_input,decoder_hidden_state,decoder_cell_state,encoder_outputs):\n",
    "        \n",
    "        #Decoder must output words after <start> token hence sequence length is reduced by 1\n",
    "        all_outputs = tf.TensorArray(tf.float32,size=decoder_input.shape[1]-1,name='Output_arrays')\n",
    "        \n",
    "        #Initialise the hidden and cell states of decoder\n",
    "        hidden_output_dec = decoder_hidden_state\n",
    "        cell_output_dec = decoder_cell_state\n",
    "        \n",
    "        #for each timestep in decoder input (output after <start> token)\n",
    "        for timestep in range(decoder_input.shape[1]-1):\n",
    "            #Get the output, hidden states from one step decoder\n",
    "            output_dec,hidden_output_dec,cell_output_dec,_ = self.onestep_decoder(decoder_input[:,timestep:timestep+1],\n",
    "                                                                                  hidden_output_dec,cell_output_dec,\n",
    "                                                                                  encoder_outputs)\n",
    "            \n",
    "            #output_dec shape == (batch_size,vocab_size)\n",
    "            #Storing all outputs\n",
    "            all_outputs = all_outputs.write(timestep,output_dec)\n",
    "        #all_outputs shape after stacking == (timestep-1,batch_size,vocab_size)\n",
    "        #all_outputs shape after transpose == (batch_size,timestep-1,vocab_size)\n",
    "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        \n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "yBIUAdeTcuEB",
    "outputId": "9fef7b77-67cf-4ba8-8ad1-f8f63ce8d768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder with Attention:\n",
      "Shape of decoder input (batch_size,sequence length): (32, 53)\n",
      "Shape of decoder output (batch_size,sequence length-1,vocab_size): (32, 52, 30)\n"
     ]
    }
   ],
   "source": [
    "#Initialise decoder\n",
    "decoder = Decoder(vocab_size=vocab_size,embedding_dim=300,embedding_matrix=embedding_matrix,dec_units=128,att_units=128)\n",
    "\n",
    "#Generate output from decoder\n",
    "all_outputs = decoder(example_target_batch,sample_hidden_output,sample_cell_output,sample_output)\n",
    "print('Decoder with Attention:')\n",
    "print('Shape of decoder input (batch_size,sequence length):',example_target_batch.shape)\n",
    "print('Shape of decoder output (batch_size,sequence length-1,vocab_size):',all_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3JlgiLdcuEM"
   },
   "source": [
    "<h2>2.4. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DTKipswcuEN"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHe4U-qBcuER"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    \n",
    "    #Identify zeros in real tensor/Creating masking tensor\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    #Calculate log loss for each class\n",
    "    loss_ = loss_object(real, pred)\n",
    "    #Change data type of mask\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #Calculate loss considering masking\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qlauC-cuET"
   },
   "source": [
    "<h2>2.5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDQubxhQcuEU"
   },
   "outputs": [],
   "source": [
    "class Encoder_Decoder_Attention_Model(tf.keras.models.Model):\n",
    "    def __init__(self, vocab_size,embedding_dim,embedding_matrix,units,att_units,**kwargs):\n",
    "        super(Encoder_Decoder_Attention_Model,self).__init__(**kwargs)\n",
    "        self.encoder = Encoder(vocab_size=vocab_size, embedding_dim=embedding_dim,embedding_matrix=embedding_matrix,\n",
    "                               enc_units=units,name='Encoder_layer')\n",
    "        self.decoder = Decoder(vocab_size=vocab_size, embedding_dim=embedding_dim,embedding_matrix=embedding_matrix,\n",
    "                               dec_units=units,att_units=att_units,\n",
    "                               name='Decoder_layer')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #Inputs will contain encoder input and decoder input\n",
    "        #Separate encoder and decoder inputs\n",
    "        encoder_inputs, decoder_inputs = inputs[0], inputs[1]\n",
    "        \n",
    "        #Genearte output and hidden states from encoder object\n",
    "        encoder_outputs, enc_hidden_output, enc_cell_output = self.encoder(encoder_inputs)\n",
    "\n",
    "        #Generate output from decoder\n",
    "        #Initialise hidden states of decoder with hidden states of encoder\n",
    "        all_outputs = self.decoder(decoder_inputs,enc_hidden_output,enc_cell_output,encoder_outputs)\n",
    "        \n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcrEYcmlL7H6"
   },
   "source": [
    "<h2>2.6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBKLoKUbL7H7"
   },
   "outputs": [],
   "source": [
    "#Function returns texts from a sequence\n",
    "def get_text_from_seq(sequence,tokenizer):\n",
    "    sent =''\n",
    "    for i in sequence:\n",
    "        if i!=0:\n",
    "            sent+=tokenizer.index_word[i]\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ_KwVRdL7H_"
   },
   "outputs": [],
   "source": [
    "#Function to get bleu score for a sentence\n",
    "def get_bleu_score(enc_dec_model,input_seq,expected_output_seq):\n",
    "    \n",
    "    inp_max_length = X_train_padded_docs.shape[1]\n",
    "    out_max_length = y_train_padded_docs.shape[1]\n",
    "    \n",
    "    #Get output from encoder\n",
    "    enc_outputs,enc_hidden,enc_cell = enc_dec_model.layers[0](input_seq.reshape(1,inp_max_length))\n",
    "    \n",
    "    #Boundary case for decoder\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['#']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    \n",
    "    #Predicted output sequence\n",
    "    #Add <start> token to output sequence\n",
    "    output_seq = [tokenizer.word_index['#']]\n",
    "    \n",
    "    #The model will start predicting after start token, hence max_length is subtracted by 1\n",
    "    for i in range(out_max_length-1):\n",
    "        #Get prediction from onestep_decoder\n",
    "        dec_output,dec_hidden,dec_cell,_ = enc_dec_model.layers[1].onestep_decoder(dec_input,dec_hidden,\n",
    "                                                                                               dec_cell,enc_outputs)\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = tf.argmax(dec_output[0]).numpy()\n",
    "        \n",
    "        output_seq.append(key)\n",
    "        \n",
    "        if tokenizer.index_word[key] == '*':\n",
    "            #Get texts from input sentence\n",
    "            input_sent = get_text_from_seq(input_seq,tokenizer)\n",
    "            #Get texts from sequence for actual sentence\n",
    "            actual = get_text_from_seq(expected_output_seq,tokenizer)\n",
    "            #Get texts from sequence for predicted sentence\n",
    "            prediction = get_text_from_seq(output_seq,tokenizer)\n",
    "            return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    input_sent = get_text_from_seq(input_seq,tokenizer)\n",
    "    actual = get_text_from_seq(expected_output_seq,tokenizer)\n",
    "    prediction = get_text_from_seq(output_seq,tokenizer)\n",
    "    return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6naCdjvcuEa"
   },
   "source": [
    "<h1>3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TTqWUC8cuEa"
   },
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "\n",
    "#Encoding and decoding Embedding layer dimension\n",
    "embedding_dim = 300\n",
    "\n",
    "#Encoding and decoding LSTM layer units\n",
    "units = 128\n",
    "att_units = 32\n",
    "\n",
    "#Initialise object for Model class\n",
    "model = Encoder_Decoder_Attention_Model(vocab_size,embedding_dim,embedding_matrix,units,att_units,\n",
    "                                        name='Encoder_Decoder_Attention_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "PKDJZOJDcuEc",
    "outputId": "7189f005-5b49-49eb-ed9d-5843ae40634c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder_Decoder_Attention_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_layer (Encoder)      multiple                  228648    \n",
      "_________________________________________________________________\n",
      "Decoder_layer (Decoder)      multiple                  306343    \n",
      "=================================================================\n",
      "Total params: 534,991\n",
      "Trainable params: 534,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Max sequence length for input and output sentence\n",
    "model.build(input_shape=[(None,X_train_padded_docs.shape[1]),(None,y_train_padded_docs.shape[1])])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20CwK6Chcj1d"
   },
   "outputs": [],
   "source": [
    "def data_generator(X,y,BATCH_SIZE,shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(X)).batch(BATCH_SIZE,drop_remainder=True)\n",
    "    else:\n",
    "        dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEn_0bp2cuEf"
   },
   "outputs": [],
   "source": [
    "#Create folder to save model weights\n",
    "if not os.path.isdir('model_save'):\n",
    "    os.makedirs('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsXuVDsV0XIU"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "tyKYm6yocuEm",
    "outputId": "3b36de56-07b4-4658-9cd6-2f0f932e65e1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.7767\n",
      "Epoch 00001: loss improved from inf to 0.77665, saving model to model_save/weights-01-0.7767.hdf5\n",
      "209/209 [==============================] - 148s 706ms/step - loss: 0.7767 - val_loss: 0.4650\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.5602\n",
      "Epoch 00002: loss improved from 0.77665 to 0.56016, saving model to model_save/weights-02-0.5602.hdf5\n",
      "209/209 [==============================] - 124s 593ms/step - loss: 0.5602 - val_loss: 0.3880\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.4899\n",
      "Epoch 00003: loss improved from 0.56016 to 0.48995, saving model to model_save/weights-03-0.4899.hdf5\n",
      "209/209 [==============================] - 124s 592ms/step - loss: 0.4899 - val_loss: 0.3557\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.4537\n",
      "Epoch 00004: loss improved from 0.48995 to 0.45367, saving model to model_save/weights-04-0.4537.hdf5\n",
      "209/209 [==============================] - 124s 594ms/step - loss: 0.4537 - val_loss: 0.3411\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.4311\n",
      "Epoch 00005: loss improved from 0.45367 to 0.43113, saving model to model_save/weights-05-0.4311.hdf5\n",
      "209/209 [==============================] - 124s 593ms/step - loss: 0.4311 - val_loss: 0.3313\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.4152\n",
      "Epoch 00006: loss improved from 0.43113 to 0.41523, saving model to model_save/weights-06-0.4152.hdf5\n",
      "209/209 [==============================] - 123s 590ms/step - loss: 0.4152 - val_loss: 0.3242\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.4025\n",
      "Epoch 00007: loss improved from 0.41523 to 0.40245, saving model to model_save/weights-07-0.4025.hdf5\n",
      "209/209 [==============================] - 123s 591ms/step - loss: 0.4025 - val_loss: 0.3206\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3934\n",
      "Epoch 00008: loss improved from 0.40245 to 0.39337, saving model to model_save/weights-08-0.3934.hdf5\n",
      "209/209 [==============================] - 124s 592ms/step - loss: 0.3934 - val_loss: 0.3190\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3853\n",
      "Epoch 00009: loss improved from 0.39337 to 0.38531, saving model to model_save/weights-09-0.3853.hdf5\n",
      "209/209 [==============================] - 123s 590ms/step - loss: 0.3853 - val_loss: 0.3145\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3787\n",
      "Epoch 00010: loss improved from 0.38531 to 0.37872, saving model to model_save/weights-10-0.3787.hdf5\n",
      "209/209 [==============================] - 123s 590ms/step - loss: 0.3787 - val_loss: 0.3132\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 10\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list = [checkpoint,tensorboard_callback]\n",
    "\n",
    "#Data generator\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs),y_train_padded_docs[:,1:],\n",
    "                       BATCH_SIZE=BATCH_SIZE,shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history1 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yXcw8dC73Pie",
    "outputId": "cb84bbaa-fa61-4383-a600-15540eb1058a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history1']"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history1.history,'history1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mrd7PRmjcuEp"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7ObOhaJazQcU",
    "outputId": "a6dafdc6-bca7-4787-f23c-bb53769821ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 42s 201ms/step - loss: 0.3632\n"
     ]
    }
   ],
   "source": [
    "train_parameters = model.evaluate([X_train_padded_docs,y_train_padded_docs],y_train_padded_docs[:,1:],\n",
    "                                  verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dOq7_Vm-zjIM",
    "outputId": "8481528a-f211-4267-ee6f-dfd6432a8c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3129\n"
     ]
    }
   ],
   "source": [
    "val_parameters = model.evaluate([X_val_padded_docs,y_val_padded_docs],y_val_padded_docs[:,1:],\n",
    "                                 verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt-hIXlo7fBQ"
   },
   "outputs": [],
   "source": [
    "#Load weights\n",
    "model.load_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "colab_type": "code",
    "id": "vUZp41FB3Piv",
    "outputId": "28a37a24-ff65-458c-d5ad-3e1d7c00b9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/209 [..............................] - ETA: 7:30 - loss: 0.3942WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.928715). Check your callbacks.\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3756\n",
      "Epoch 00001: loss improved from 0.37872 to 0.37559, saving model to model_save/weights-01-0.3756.hdf5\n",
      "209/209 [==============================] - 150s 717ms/step - loss: 0.3756 - val_loss: 0.3126\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3670\n",
      "Epoch 00002: loss improved from 0.37559 to 0.36695, saving model to model_save/weights-02-0.3670.hdf5\n",
      "209/209 [==============================] - 123s 589ms/step - loss: 0.3670 - val_loss: 0.3126\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3616\n",
      "Epoch 00003: loss improved from 0.36695 to 0.36157, saving model to model_save/weights-03-0.3616.hdf5\n",
      "209/209 [==============================] - 124s 592ms/step - loss: 0.3616 - val_loss: 0.3134\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3578\n",
      "Epoch 00004: loss improved from 0.36157 to 0.35783, saving model to model_save/weights-04-0.3578.hdf5\n",
      "209/209 [==============================] - 124s 592ms/step - loss: 0.3578 - val_loss: 0.3162\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3542\n",
      "Epoch 00005: loss improved from 0.35783 to 0.35417, saving model to model_save/weights-05-0.3542.hdf5\n",
      "209/209 [==============================] - 124s 593ms/step - loss: 0.3542 - val_loss: 0.3153\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3513\n",
      "Epoch 00006: loss improved from 0.35417 to 0.35133, saving model to model_save/weights-06-0.3513.hdf5\n",
      "209/209 [==============================] - 124s 592ms/step - loss: 0.3513 - val_loss: 0.3152\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3488\n",
      "Epoch 00007: loss improved from 0.35133 to 0.34880, saving model to model_save/weights-07-0.3488.hdf5\n",
      "209/209 [==============================] - 124s 594ms/step - loss: 0.3488 - val_loss: 0.3161\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3464\n",
      "Epoch 00008: loss improved from 0.34880 to 0.34644, saving model to model_save/weights-08-0.3464.hdf5\n",
      "209/209 [==============================] - 124s 595ms/step - loss: 0.3464 - val_loss: 0.3169\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3438\n",
      "Epoch 00009: loss improved from 0.34644 to 0.34378, saving model to model_save/weights-09-0.3438.hdf5\n",
      "209/209 [==============================] - 124s 594ms/step - loss: 0.3438 - val_loss: 0.3188\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3415\n",
      "Epoch 00010: loss improved from 0.34378 to 0.34152, saving model to model_save/weights-10-0.3415.hdf5\n",
      "209/209 [==============================] - 124s 593ms/step - loss: 0.3415 - val_loss: 0.3163\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 10\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Data generator\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history2 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vjXvi7q13Piy",
    "outputId": "30197ae8-95cc-4029-e83c-be3d66097e4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history2']"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history2.history,'history2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGq6nEVf3Pi1"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M3_GIicwlsP"
   },
   "outputs": [],
   "source": [
    "model.load_weights('best_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zhfZx9hrVAvW",
    "outputId": "7510c375-c22b-4af7-dcec-61528b9703c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/209 [..............................] - ETA: 5:51 - loss: 0.3552WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.450427). Check your callbacks.\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3253\n",
      "Epoch 00001: loss improved from inf to 0.32529, saving model to model_save/weights-01-0.3253.hdf5\n",
      "209/209 [==============================] - 151s 721ms/step - loss: 0.3253 - val_loss: 0.2953\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3130\n",
      "Epoch 00002: loss improved from 0.32529 to 0.31297, saving model to model_save/weights-02-0.3130.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.3130 - val_loss: 0.2938\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3086\n",
      "Epoch 00003: loss improved from 0.31297 to 0.30855, saving model to model_save/weights-03-0.3086.hdf5\n",
      "209/209 [==============================] - 124s 596ms/step - loss: 0.3086 - val_loss: 0.2929\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3054\n",
      "Epoch 00004: loss improved from 0.30855 to 0.30543, saving model to model_save/weights-04-0.3054.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.3054 - val_loss: 0.2927\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3029\n",
      "Epoch 00005: loss improved from 0.30543 to 0.30287, saving model to model_save/weights-05-0.3029.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.3029 - val_loss: 0.2926\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.3011\n",
      "Epoch 00006: loss improved from 0.30287 to 0.30107, saving model to model_save/weights-06-0.3011.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.3011 - val_loss: 0.2924\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2991\n",
      "Epoch 00007: loss improved from 0.30107 to 0.29914, saving model to model_save/weights-07-0.2991.hdf5\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2991 - val_loss: 0.2923\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2974\n",
      "Epoch 00008: loss improved from 0.29914 to 0.29740, saving model to model_save/weights-08-0.2974.hdf5\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2974 - val_loss: 0.2923\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2958\n",
      "Epoch 00009: loss improved from 0.29740 to 0.29585, saving model to model_save/weights-09-0.2958.hdf5\n",
      "209/209 [==============================] - 125s 598ms/step - loss: 0.2958 - val_loss: 0.2921\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2944\n",
      "Epoch 00010: loss improved from 0.29585 to 0.29439, saving model to model_save/weights-10-0.2944.hdf5\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2944 - val_loss: 0.2922\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2930\n",
      "Epoch 00011: loss improved from 0.29439 to 0.29305, saving model to model_save/weights-11-0.2930.hdf5\n",
      "209/209 [==============================] - 125s 598ms/step - loss: 0.2930 - val_loss: 0.2920\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2916\n",
      "Epoch 00012: loss improved from 0.29305 to 0.29157, saving model to model_save/weights-12-0.2916.hdf5\n",
      "209/209 [==============================] - 124s 594ms/step - loss: 0.2916 - val_loss: 0.2924\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2905\n",
      "Epoch 00013: loss improved from 0.29157 to 0.29050, saving model to model_save/weights-13-0.2905.hdf5\n",
      "209/209 [==============================] - 124s 595ms/step - loss: 0.2905 - val_loss: 0.2923\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2894\n",
      "Epoch 00014: loss improved from 0.29050 to 0.28939, saving model to model_save/weights-14-0.2894.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.2894 - val_loss: 0.2924\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2882\n",
      "Epoch 00015: loss improved from 0.28939 to 0.28825, saving model to model_save/weights-15-0.2882.hdf5\n",
      "209/209 [==============================] - 125s 599ms/step - loss: 0.2882 - val_loss: 0.2924\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2872\n",
      "Epoch 00016: loss improved from 0.28825 to 0.28722, saving model to model_save/weights-16-0.2872.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.2872 - val_loss: 0.2925\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2860\n",
      "Epoch 00017: loss improved from 0.28722 to 0.28600, saving model to model_save/weights-17-0.2860.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.2860 - val_loss: 0.2927\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2852\n",
      "Epoch 00018: loss improved from 0.28600 to 0.28516, saving model to model_save/weights-18-0.2852.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.2852 - val_loss: 0.2929\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2841\n",
      "Epoch 00019: loss improved from 0.28516 to 0.28406, saving model to model_save/weights-19-0.2841.hdf5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "209/209 [==============================] - 125s 600ms/step - loss: 0.2841 - val_loss: 0.2930\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 30\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 8 epochs\n",
    "terminate = EarlyStopping(monitor='val_loss',patience=8,verbose=1,mode='min',restore_best_weights=True)\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list = [checkpoint,terminate,tensorboard_callback]\n",
    "\n",
    "#Data generator\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history3 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "170_lQosVAtq",
    "outputId": "abd93835-42da-47c8-9c08-60fbf787ba3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history3']"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history3.history,'history3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIQ5qtfgVAsN"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OkAh1RN45D2A",
    "outputId": "f86cc43b-041a-4f6f-8d62-1fe5cfed59b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/209 [..............................] - ETA: 6:00 - loss: 0.3154WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.493787). Check your callbacks.\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2884\n",
      "Epoch 00001: loss improved from inf to 0.28844, saving model to model_save/weights-01-0.2884.hdf5\n",
      "209/209 [==============================] - 151s 722ms/step - loss: 0.2884 - val_loss: 0.2911 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2871\n",
      "Epoch 00002: loss improved from 0.28844 to 0.28713, saving model to model_save/weights-02-0.2871.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.2871 - val_loss: 0.2909 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2867\n",
      "Epoch 00003: loss improved from 0.28713 to 0.28666, saving model to model_save/weights-03-0.2867.hdf5\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2867 - val_loss: 0.2908 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2863\n",
      "Epoch 00004: loss improved from 0.28666 to 0.28630, saving model to model_save/weights-04-0.2863.hdf5\n",
      "209/209 [==============================] - 125s 596ms/step - loss: 0.2863 - val_loss: 0.2908 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2859\n",
      "Epoch 00005: loss improved from 0.28630 to 0.28593, saving model to model_save/weights-05-0.2859.hdf5\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2859 - val_loss: 0.2908 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2856\n",
      "Epoch 00006: loss improved from 0.28593 to 0.28560, saving model to model_save/weights-06-0.2856.hdf5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2856 - val_loss: 0.2908 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2856\n",
      "Epoch 00007: loss improved from 0.28560 to 0.28559, saving model to model_save/weights-07-0.2856.hdf5\n",
      "209/209 [==============================] - 126s 601ms/step - loss: 0.2856 - val_loss: 0.2908 - lr: 9.0000e-05\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2854\n",
      "Epoch 00008: loss improved from 0.28559 to 0.28543, saving model to model_save/weights-08-0.2854.hdf5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "209/209 [==============================] - 125s 598ms/step - loss: 0.2854 - val_loss: 0.2908 - lr: 9.0000e-05\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2852\n",
      "Epoch 00009: loss improved from 0.28543 to 0.28518, saving model to model_save/weights-09-0.2852.hdf5\n",
      "209/209 [==============================] - 126s 603ms/step - loss: 0.2852 - val_loss: 0.2907 - lr: 8.1000e-05\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2852\n",
      "Epoch 00010: loss did not improve from 0.28518\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
      "209/209 [==============================] - 125s 599ms/step - loss: 0.2852 - val_loss: 0.2907 - lr: 8.1000e-05\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2849\n",
      "Epoch 00011: loss improved from 0.28518 to 0.28490, saving model to model_save/weights-11-0.2849.hdf5\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2849 - val_loss: 0.2907 - lr: 7.2900e-05\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2847\n",
      "Epoch 00012: loss improved from 0.28490 to 0.28472, saving model to model_save/weights-12-0.2847.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
      "209/209 [==============================] - 125s 597ms/step - loss: 0.2847 - val_loss: 0.2907 - lr: 7.2900e-05\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2845\n",
      "Epoch 00013: loss improved from 0.28472 to 0.28453, saving model to model_save/weights-13-0.2845.hdf5\n",
      "209/209 [==============================] - 125s 599ms/step - loss: 0.2845 - val_loss: 0.2907 - lr: 6.5610e-05\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2845\n",
      "Epoch 00014: loss improved from 0.28453 to 0.28452, saving model to model_save/weights-14-0.2845.hdf5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 5.904900172026828e-05.\n",
      "209/209 [==============================] - 126s 604ms/step - loss: 0.2845 - val_loss: 0.2907 - lr: 6.5610e-05\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2844\n",
      "Epoch 00015: loss improved from 0.28452 to 0.28438, saving model to model_save/weights-15-0.2844.hdf5\n",
      "209/209 [==============================] - 126s 602ms/step - loss: 0.2844 - val_loss: 0.2907 - lr: 5.9049e-05\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2843\n",
      "Epoch 00016: loss improved from 0.28438 to 0.28429, saving model to model_save/weights-16-0.2843.hdf5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 5.314410154824145e-05.\n",
      "209/209 [==============================] - 126s 602ms/step - loss: 0.2843 - val_loss: 0.2907 - lr: 5.9049e-05\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2842\n",
      "Epoch 00017: loss improved from 0.28429 to 0.28420, saving model to model_save/weights-17-0.2842.hdf5\n",
      "209/209 [==============================] - 126s 602ms/step - loss: 0.2842 - val_loss: 0.2908 - lr: 5.3144e-05\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2842\n",
      "Epoch 00018: loss improved from 0.28420 to 0.28419, saving model to model_save/weights-18-0.2842.hdf5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.7829690083744934e-05.\n",
      "209/209 [==============================] - 126s 602ms/step - loss: 0.2842 - val_loss: 0.2907 - lr: 5.3144e-05\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2841\n",
      "Epoch 00019: loss improved from 0.28419 to 0.28406, saving model to model_save/weights-19-0.2841.hdf5\n",
      "209/209 [==============================] - 125s 598ms/step - loss: 0.2841 - val_loss: 0.2908 - lr: 4.7830e-05\n",
      "Epoch 20/30\n",
      "209/209 [==============================] - ETA: 0s - loss: 0.2839\n",
      "Epoch 00020: loss improved from 0.28406 to 0.28393, saving model to model_save/weights-20-0.2839.hdf5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.304672074795235e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "209/209 [==============================] - 125s 599ms/step - loss: 0.2839 - val_loss: 0.2907 - lr: 4.7830e-05\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 30\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.0001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Reduce learning rate by 10% if validation loss does not decrease from last 2 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, verbose=1, patience=2,min_lr=0.00001)\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 8 epochs\n",
    "terminate = EarlyStopping(monitor='val_loss',patience=8,verbose=1,mode='min',restore_best_weights=True)\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list = [checkpoint,reduce_lr,terminate,tensorboard_callback]\n",
    "\n",
    "#Data generator\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history4 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5bWxWJqb5Dzs",
    "outputId": "52663655-1a06-4d74-aea1-ce45ede1dc8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history4']"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history4.history,'history4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7H1cTYu75Duh"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqNXppQdRtZI"
   },
   "outputs": [],
   "source": [
    "h1 = joblib.load('history1')\n",
    "h2 = joblib.load('history2')\n",
    "h3 = joblib.load('history3')\n",
    "h4 = joblib.load('history4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRv5nhtcRyaz"
   },
   "outputs": [],
   "source": [
    "loss = h1['loss']+h2['loss']+h3['loss']+h4['loss']\n",
    "val_loss = h1['val_loss']+h2['val_loss']+h3['val_loss']+h4['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "-3JnSRmPRyZL",
    "outputId": "b386976c-3706-45e8-ea0a-80b89aea296a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Vs No of epochs')"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss,label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('No of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Vs No of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvvc3q93L7In"
   },
   "outputs": [],
   "source": [
    "#Generate 1000 random samples from train and val data\n",
    "#Train data\n",
    "train_index = []\n",
    "for i in range(X_train_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_train_padded_docs[i]!=0)>10:\n",
    "        train_index.append(i)\n",
    "train_index = random.sample(train_index,1000)\n",
    "\n",
    "#Validation data\n",
    "#Train data\n",
    "val_index = []\n",
    "for i in range(X_val_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_val_padded_docs[i]!=0)>10:\n",
    "        val_index.append(i)\n",
    "val_index = random.sample(val_index,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "muqMywldL7Iq",
    "outputId": "7d9bacf5-9ed7-4c6a-d24d-9ed165af77fa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:17,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # again any questions comm *\n",
      "Actual words: # ents concerns let me know *\n",
      "Predicted words: # ents concerns *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [00:35,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # please contact me with any concern *\n",
      "Actual words: # s or questions *\n",
      "Predicted words: # s *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:55,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # do not worry about having *\n",
      "Actual words: #  to have a gift ready *\n",
      "Predicted words: #  to have a great *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [01:13,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # i have all his  *\n",
      "Actual words: # information if you need it *\n",
      "Predicted words: # sure you are coming *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:30,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # under the ap *\n",
      "Actual words: # propriate desk of course *\n",
      "Predicted words: # preciated to the company *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [01:47,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # we are trying to  *\n",
      "Actual words: # schedule this gas for today *\n",
      "Predicted words: # the morning *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [02:06,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # there never w *\n",
      "Actual words: # as any deregulation *\n",
      "Predicted words: # e have a good time *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [02:25,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # please let me know how this works for y *\n",
      "Actual words: # ou *\n",
      "Predicted words: # ou *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [02:43,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # great that he could come over *\n",
      "Actual words: #  and visit *\n",
      "Predicted words: #  the problems *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [03:04,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # let me know if you ha *\n",
      "Actual words: # ve comments or concerns *\n",
      "Predicted words: # ve any questions *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#For train data, actual and predicted words\n",
    "train_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_train_padded_docs[train_index,:],y_train_padded_docs[train_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    train_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "o2B9_PCSL7Is",
    "outputId": "388790e1-d71e-45ad-8dd0-bdae8e38ab10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:16,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # we apologize for the late distribution th *\n",
      "Actual words: # is month *\n",
      "Predicted words: # e past *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:32,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # i am not asking for approva *\n",
      "Actual words: # l to do this *\n",
      "Predicted words: # ted *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:49,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # i definitely *\n",
      "Actual words: #  need to meet some new people *\n",
      "Predicted words: #  they are the past on the same *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [01:07,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # i will have her cont *\n",
      "Actual words: # act you later today *\n",
      "Predicted words: # inue to you *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [01:24,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # we will not accept such orders or i *\n",
      "Actual words: # nstructions *\n",
      "Predicted words: # n the online *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [01:42,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # let me know the final reso *\n",
      "Actual words: # lution on this one *\n",
      "Predicted words: # lve *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [01:59,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # after that j *\n",
      "Actual words: # ust enjoy the games *\n",
      "Predicted words: # ust story *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [02:16,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # thanks so much for all your help an *\n",
      "Actual words: # d hard work *\n",
      "Predicted words: # d suggestions *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [02:33,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # i received this and thought it w *\n",
      "Actual words: # as great *\n",
      "Predicted words: # ill be a completed *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [02:49,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # that is exactly what we are lookin *\n",
      "Actual words: # g for *\n",
      "Predicted words: # g *\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#For validation data actual and predicted words\n",
    "val_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_val_padded_docs[val_index,:],y_val_padded_docs[val_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    val_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "EvU7rH7IL7Iy",
    "outputId": "845aabb6-e7e4-424d-d86f-02ec012bf77c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for train data of 1000 samples: 0.649\n",
      "BLEU Score for validation data of 1000 samples: 0.653\n"
     ]
    }
   ],
   "source": [
    "#Average BLEU Score for sentences\n",
    "print('BLEU Score for train data of 1000 samples:',np.round(sum(train_bleu_list)/len(train_bleu_list),3))\n",
    "print('BLEU Score for validation data of 1000 samples:',np.round(sum(val_bleu_list)/len(val_bleu_list),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xqdMoy5cuFl"
   },
   "source": [
    "<h1>4. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgjJobuUcuFl"
   },
   "outputs": [],
   "source": [
    "def predict_sentence(enc_dec_model,input_sentence):\n",
    "    \n",
    "    #Maximum sequence length for input and target sentence\n",
    "    inp_max_length = X_train_padded_docs.shape[1]\n",
    "    out_max_length = y_train_padded_docs.shape[1]\n",
    "    \n",
    "    #Attention plot\n",
    "    attention_plot = np.zeros((inp_max_length,out_max_length))\n",
    "    \n",
    "    input_sentence = '# ' + input_sentence + ' *'\n",
    "    \n",
    "    #Convert texts to sequences\n",
    "    sent = tokenizer.texts_to_sequences([input_sentence])\n",
    "    #Pad data\n",
    "    sent = tf.keras.preprocessing.sequence.pad_sequences(sent,maxlen=inp_max_length,padding='post')\n",
    "    \n",
    "    #print('Encoder input shape (batch_size,sequence length):',sent.shape)\n",
    "    enc_outputs,enc_hidden,enc_cell = enc_dec_model.layers[0](sent)\n",
    "    #print('Encoder output shape (batch_size,sequence lengths,units):',enc_outputs.shape)\n",
    "    #print('Encoder hidden state shape (batch_size,units):',enc_hidden.shape)\n",
    "    #print('Encoder cell state shape (batch_size,units):',enc_cell.shape)\n",
    "    #print(90*'-')\n",
    "    \n",
    "    #Boundary case\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['#']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    #print('Decoder input shape (batch_size,1):',dec_input.shape)\n",
    "    #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "    #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    output_sent = ''\n",
    "    \n",
    "    for i in range(out_max_length-1):\n",
    "        #Get prediction from onestep_decoder\n",
    "        dec_output,dec_hidden,dec_cell,attention_weights = enc_dec_model.layers[1].onestep_decoder(dec_input,dec_hidden,\n",
    "                                                                                               dec_cell,enc_outputs)\n",
    "        #print('Decoder output shape (batch_size,vocab_size):',dec_output.shape)\n",
    "        #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "        #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    \n",
    "        #Storing attention weights\n",
    "        attention_weights = tf.reshape(attention_weights,(-1,))\n",
    "        attention_plot[i] = attention_weights.numpy()\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = tf.argmax(dec_output[0]).numpy()\n",
    "        #Get word corresponding to index\n",
    "        output_sent+=tokenizer.index_word[key]+''\n",
    "        \n",
    "        if tokenizer.index_word[key] == '*':\n",
    "            return output_sent,input_sentence,attention_plot\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    return output_sent,input_sentence,attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmtMX13TcuFn"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/nmt_with_attention#write_the_encoder_and_decoder_model\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcbDDFYHcuFp"
   },
   "outputs": [],
   "source": [
    "def generate_sentence(enc_dec_model,input_sentence):\n",
    "    #Get prediction from model\n",
    "    result,sentence,attention_plot = predict_sentence(enc_dec_model,input_sentence)\n",
    "    print('Input sentence:',sentence)\n",
    "    print('Predicted words:',result)\n",
    "    #Plot Attention plots\n",
    "    attention_plot = attention_plot[:len(list(result)),:len(list(sentence))]\n",
    "    plot_attention(attention_plot, list(sentence), list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "GtnPdEIjcuFr",
    "outputId": "30200a09-790f-4d6f-d628-dc798038e32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # thank you *\n",
      "Predicted words:   this weekend *\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'thank you'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "U_HUiAXnL7KI",
    "outputId": "ff0e778b-4d32-43b4-8f0a-6469888cb345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # hope it *\n",
      "Predicted words:   is a while you soon *\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'hope it'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "PrX2R0r1L7KL",
    "outputId": "1f0b891b-2fe2-4a44-b26e-2f18525d343c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # can you *\n",
      "Predicted words:   have any questions or concerns *\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'can you'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "99K45xZzB-OR",
    "outputId": "9705be2a-d6b0-48be-9b0c-3d4dd5c55a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # give me *\n",
      "Predicted words:   a call if you need anything *\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'give me'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "AfloCp7zB-G7",
    "outputId": "14d46af0-bf39-46b8-a591-8cb6f019593e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: # are you avail *\n",
      "Predicted words:  able to assistance in the morning *\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKMAAAE3CAYAAADG7PFhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcSUlEQVR4nO2de5RdVXnAf9+9M3kweUAeJgEkxBQIERWRBhFQxIosXT6L2oq1apeooAWphVVbu2xrRTFaXCoRqJa2AkVL6wNaqAtkJVDAYg02BAKEBEgIISGTx+Q5c+/XP/aJ3lzu/s6Zc87MHHO/31p3zdyzz7fPvne+2fvs73wPUVUcpwrUxnoAjrMfV0anMrgyOpXBldGpDK6MTmVwZXQqgyujg4hcJyK35G0vizFTRhGZKSL7RKRPRHpFZKeIHDVW4+lyLgLePxIdi8hdWc8dy5nxVOBBVd0JnARsUdWnRuJCIjJuJPo9WFDVbaq6taz+ROQMETmr7dhZInKGJTeWyvga4J7k99NbfjcRkXNEZJmI9IvIFhG5XUSObzvnLhFZIiKLRWTT/r4lcKmIrBaR3SLyfyKSOiOIyAdE5HkRGd92/HoR+VHy+3gRuVJENorIHhG5T0RObxnPN9pkMy99sc8sIucn16u3nX9Dy7iyfF9lL8NPAheIyFXA5OTnBcnxOKo6ai/gKGBr8toH7E5+3wvsSX6/KqWP301exwAvB74HPA6MaznnLmAH8BVgAXB8cvxvgVXAOcA84H3ATuAtKdecCPQD72k5NhXYBbw9ef81YAPwFuB44FpgAJiTjOcbbX1eB9yS8XuLfeYXJd/bOS3nTko+03uG8X2ZYxnOWNvkLgcUuDzT+aOsjD3A0cmXsi/5OT9RnNcmbTOG2Wcf0ABOb1PGX3Y4bzdwRtvxK4H/yHCdbwC3tbz/OPBs8pn6ks/zgZb2OrAa+HxRZbQ+M/BvwD+3tL0f2AZMGMb3VaoyAkcCNwFXAT9Pft4EHGnJjeoyrapDqrqWMFv9j6r+EpgNbFTVpaq6VlU3W32IyPxkGVotItuBjYTbjfbNz8/b3i8EJgC3icjA/hdBqeZnGP61wBtF5Mjk/YeBf1TVoUS+l5ZbDVVtAPcm1y1Eymf+LvAOETkkOf084GZV3ZNBdqR4CXC1ql4A7Eh+Xk1YjaL0jOCAXoCIPATMJfzhaoky9AA9ye9PqupLU7q5BVgHfBRYDwwBK4H2TcrOtvf7//HeCrRvlAbTxq6qD4rI/wIfFJEfACeTbQeqQBOQtuO9GWT3Y33mm5P3bxeRO4DfAd6UUXZEUNWlHY7dmSY3qsoIvJnwR7gDuJQwe/0LYRm4jRSlEJHphFn1AlX9aXLsJLJ9jpWEe9O5Wb6YCNcm454B3KOqq5LjqwnL9GnJ7ySbilOBG4BjCfeOrbwCWJt2wbTPrKp7ReT7hBlxBuHW4a4ssqOBqp6Z9dxRVUZVfVJEZgOzgB8SZo2XEpaVDRm66Ac2Ax8RkaeBI4AvE/7b0669Q0QWA4tFRIClhJv9VwNNVb0mw/VvBL5KWNo/1tL3ThFZAnxJRDYDa4BPJZ/zKuBtwJUi8jbCBuqjwIvJoIwZP/N3Cf/g84AbVbU5DNnqUPYmJcPN7e8By5LfzwAeG6b8WcAKwi5yBWFJGgA+2HLOXbRtGJLjAnySX8+Sm4CfAG8cxvW/A2wH+tqOjydshjYmfd9HskkgrAbfJCjGZuCvGN5u2vzMyedaS/jnfnmO78scy3DGWuQlycWcjIjIfwLrVPUjYz2Wg43Rvmf8jUVEDiPM5GcT7vecknFlzM4vgGnAZ1R1xVgP5mDEl2mnMrgLmVMZXBmdyjDmyigi5+dpOxhlqzqukZQ9gNG2M3awYT2Qp+1glK3quEZStvU15jOj4+xn1HfT42S8TqDvV+8H2Usv4zuea7UdjLJVHVeZsnvYyT7d2+40AoyBnXECfZwib4ifUKvH25qN8gfkjCr36x3RNl+mncrgyuhUhlFZppPt/fkAEzgk5WynWxmVmVFVr1HVk1X1ZOtG2OlufJl2KoMro1MZKudCVj9sarStsaXflO2ZPSvaNrTh2ZTrHmYPrBE3KzV27LBlLVuuZcoC25xVRBZAOpr7MlGbNCl+2bTvI9Zn3sE4TtnkVsYsaTMcZzgUmRn7CAFIi4AzCVkMfuxJlpy85L5nVNWbW9+LyIcIUXOLgLvb2tzO6KRSZJnOnDbD7YxOForspkc9bYZzcJNLGUXkbkYobUajf1u0rTZxoinbHGhPr9Mi29cXbQNoHPdis722/FGzPS9St80zaphnahPsVaa5a5d9ccPkJOPtvmX2zHhjTtNOXuUZImQo+M1Im+H8RlBkJruNkF9xBSH55J8QMmI5Ti6KKONGQmq5I5LX7wBT9NdJhxxnWBSxM56XyJ9K2MScD1zc6cQk9/QDIvLAIHsLXNI5mCkyM24A/lhDEM0jInIscAkhZdwBaEg3dw3AFJnmKSycjhSZGe/TA6O57gWOEJEpBcfkdCllOkpcWmJfThdSZJk+RUSkZXacCexR1e2FRmTsf3TQthzteuMJ0bZDbnvQlK0/vt4el2XT27PHljXQodR04nGaKXvFNBcxw85YS7EzNteus/vOQZGZ8XBCauDjRORc4ARC+mDHyUWRmfF6Qq2T+wnpex8lW45qx+lILmXUAzPYfwJCyS9Ctn3HyYWHqjqVwUNVncrgMTBOZahcdKAVdcagbQYZ//y+aFuaWWjgNLt84OTlRs2krXG3tzRknO3+qXuNx6e1sZtLanOPiLY1Hs9nVPGZ0akMroxOZSgSAyPSUtUeeBWhKKXj5KLIPePngXOBCwnFGU8FrhWRflW9tfVEN+04WcgbA9NHcBc7W1WXJYfXiMgignIeoIzuQuZkIe/M2FrVvlW5evFHgk5O8ipjoar2jtOJvMpYRlX7jtSmx7OBNdY9Y8oOTumNtvXNiWcoA9g1ww4ZHX9U/LF77/YBU7bRH8+eVjvEvodu7IvbTmvT7MxpzWfsEI/aRONpWM12P5OmEebaY6iVYe7N6yhRRlV7xzmAIrvpzxIiBD8NLCHk2VkOXFHCuJwupEjiJwW+nrwcpzDuQuZUBnchcyqDP5t2KsPou5CJmBmudOfuaFtt3gtSPx7Ahj+MmzLm/5XhmgbUUlJW9WyPRwDqUbNNWTGyozHHyOYF9BhRif2n25nTDr0jbhYCzEjMoWOOtEV74vNY/WnLBBc3GZUyM4rIXSLyjTL6croXX6adylBYGZOowNcBF4qIJq+ji/brdB9l3DNeBBwLPAJ8Jjm2qfUEN+04WSisjKq6TUT2AbtUtWMZqgNcyGrT3YXM6YjfMzqVwZXRqQxl2Rn3EfLupKNqhl+qkSlfDVcsgFVnPBBte/PzZ5uyM5fa7laPnX94tG3+539pyupg3N7XfPQJW3YobgA99HZ7zI2tW812i/quuL0XoLk73q5W4U4r81nqqLKxFlgkIkeLyAwR8RnXGTa5Z0YRGQ98Cfh94FDC7PgIMB6Yh4cfOMOkyAx2BfBe4MPAiYQw1SHgcFVdW3xoTreRSxmT6MCPA5ep6q2q+jDwMYKz7YUdzvdqB04qeWfG+YRIwHv2H1DVBiHJ/ML2k92FzMnCSGw03Kjt5CLvBmY1YcNyWvI7IlInZJW4IVXaSnxuZNbSRryoI8CbX3ZWtK2xZVO0DaDn8Dlmu2W+MTOFpaBGlB1gfldqRA4WJS1rW31qvMJKY5tRY8D4uHmjA3eKyBLgSyKymZBY/lPALOCqPH06ThGj92XJz38gmHZ+AZyjqkYiQ8eJUyQ6cC+hVmDHeoGOM1w8OtCpDB4d6FQGf4bsVAZXRqcyVK/agWG/0uPnmbIbTp0abZt1f9w1DYCnnzObN94YD92c81G72sHQho4O8ADUp9ghtDo37rqWVqhy17zJZvvk/45XJdCZ00xZ1m+023PgM6NTGYokmD9HRJaJSL+IbBGR20Xk+DIH53QXRWbGPuBKYBFwJrAN+LGI2FV2HCdCEaP3za3vReRDhByNi4C729rczuikUmSZni8iNyR1YLYTfBlrwAsS4rid0clCkd30LcA64KPAeoKX90rAl2knF3nrwEwHFgAXqOpPk2Mn5e3PcSC/8vQDm4GPiMjTwBHAlzFz2bdghCuaPnoPrjK73fnu3443XvuoKdtc8BKzffafxiuKNDZvMWUtGimVEnjw4WhTbbJtRzxkuW1btbxD67vjKQAhfziqRa57RlVtEoKxXg6sAL5JSDjvAS5ObnJvYJL6LxcQKhwcDXyPcM8Yj6R3HIMicdM9wA+BbwPnEQK0TsKe/R0nSpENxxSCh/ePVXV1cuyRTie6ndHJQpFlegtwHXC7iNwqIpeISMek225ndLJQyFFCVT8EnEIo1/Y2YJWIvKmMgTndh5hb9OF2JvKfQL+qvi92zhSZpqfIG+Kd1IxkZk37drT+0uOibY2HbLOQeV1AjMKOVqYw50Du1zvYrls6fplFHgfOE5EvishrRGSuiLyeYOpZmbdPp7spsoHZRcjl/X1gBuHZ9PWEzGSOM2yKbGA2ElzIniYUPJ9KcCWLr5WOYzAqdkY37ThZGBU74wHVDmSaJ4ZyOjIqdkbHyUKZdsZLgTVuZ3TyUkZRogeBB0XkW8C/An8I3J6/w3ilz1TRuh26aSH1bMUanAQrTHY0XcjghXZGwuZlIW5ndHJSpp1xEHgWtzM6OSkSHbgReNf+90l11RmqGneJdhwDT4nnVAZPiedUBs+141SGyoWW1iZOjLbJuF5beChuFqpNmGCLnrzAbO/ZGo+W0zT3NMPUIePtlcKqpNA8/URTtnb3cntcBj2zZ5ntOjUemdhY9Xiua/rM6FQGV0anMhRSRhF5rYjcJyIDwDuBF4nICeUMzek23IXMqQzuQuZUBnchcyqDh6o6laEUFzIR+RohAdRuCrqQWZVTm9t2m7J1if9vNVMqn/Y+a1csYKtVKTT/nUeRyqj1+1bYfaeE31rueo3+raZobbB8F4RSXMiA8YS0eB6q6uSmDBeyn8ABW+S/EZHvquraIgNzuo9Coaqq+i7gcOBeQqnfOcnr6XKG53QTZdwzbhORfcAuVe1YCsrtjE4W3IXMqQz+bNqpDGW5kO0DsofXGZFltUl90TbdZ1f1WP+BeLW4I6633by2n/gis33y43HXttrATlO2uSfuflafdpgp23g+nry+Psse89AzG8x2i9qUeEFRAJ0zPd7Yb5jJjERyZc2Ma4FFInK0iMwQMQx+jhOhLKVZTJgdVwKb6FAly3HSKKWqKnAfoW7gq1RV3Mbo5GFUqqqKyPki8oCIPDDopWKcCKNSVdVdyJwsjEpVVcfJgldVdSrD2FRVzWn5abzMLjY5brsREtpnP4Y8ZIN9LyuDcQOZHDrVlNXN+ash1PridlfG2//39akptsI9xmeecagp25gUf5JWMypDYCSZG5uqqo7Tgbz3jHcC/w28EXgMuAN4Cq+q6hSgiGnnTGAJobrB+4B3AB9R1euKD8vpRooo40pV/UtVfVRVvwf8FOhY+srtjE4WiijjL9vePwN0fHLvLmROFoooY3tEjhbsz+lyxiYLmVGQsrGlP9om98bbAKb/TzxL2ZARdQhQ32JHwzV3xyMTixSytFzE0mg+YbuumUngwc6O9tgau2vj+zSLoxpNPpM5lcGV0akMuZZpVT0TQEQEuAT4GOGZ9CYRuVxV/6y0ETpdQ9F7xi8AHyco5FJgJvDK9pM8OtDJgpg3m5agyCTCI8GLVfVbWeWmyDQ9RTqaI/d3nGs8ANIT38BYaVMAainPrnWENjAjSpENTI89T5nfp9Hv/XoH23VLx4EVuWdcSEhrckeBPhznV/gGxqkMRe4ZHyY4RryB4CxRClZBybTlUI4zXMwesTPwpy7ThrtWY/PzpuyYUSQ7WtOWlXHx78Oq0GBRJOxgR5IK73IR2UvYwEwnBGUtyduv070UyektwBaCu+S3k8P9QObNjOO0UuSe8fPAhwnJ5ecD7wcmEPwcHWfY5A076CPYFs9W1WXJ4TUisgi4ELi17Xy3Mzqp5F2mFxJmwdtEpPVOt5eQ6uQAPFTVyUJeZdy/vL+VEG7QitebdnKRVxlXEsw6c1X1zhLH43QxeR0ldojIYmBxsqteCkwCXg00k2U5F3Wjmmfj2Y2m7Ko/jd+PLvikfa86/d/tSgrr//yYaFvPT1N8Eg17X1r10iHjM9dnGGnpKGb/rB9mh98OHffiaFvtZw8ZgvGmIkbvzxKySHyaEJi1HVgOXFGgT6eLKWL0VuDryctxCuPPpp3KMCoxMG5ndLLg1Q6cylCaMorIdSJyS1n9Od1Hmcv0RUA2N22jwKLlUc2JC8xue9bHZ12ZMtmUffpzc8z2iRviGfx10iRTtjkwEJdNcfOS8cZKMt2ulJBWhcF0yZuWkoVsQlx18s5wpSmjqqaUJXUcG1+mncrgph2nMrhpx6kMbtpxKoMv005lcGV0KkPlUuJhZSp48FGz28U3roi2fevvTksblcnQYfF73Z4t8YqrAOzYEW1qbEpx87K+q42bbNG0kFGj6oQM7DJFe5eti7aZ9ktPief8JpA3IOsugrf3VsIuuQn8EyFa0HFyUWRmPI/gt/sa4BPAxcB7yxiU0514tQOnMni1A6cyeLUDpzKMjWnHQCbHXb10q+0YdPXrXx9ta/bbkYUTn7JdpmjEKzA2Nj5nyxpYWdcA1KoMsW273XlaFjKN921FJQLUDNc2zRk57zOZUxlcGZ3KUKjaQduxDxYdjNPduAuZUxnchcypDH7P6FQGV0anMpRyz5g4TqxQ1U8U7qxuuDVZYZvAo588Ktp2zOXxcNHQuR1lu3tePCx0/BMpBXwMl6r6jGmm7NCGZw3ZGaZsY/Nms92qWFA/zLa76iTj3v+J9pSdrYOKN/nM6FSGwsooItcBrwMuFBFNXkcX7dfpPspYpi8CjgUeAT6THLNdkB2nA4WVUVW3icg+YJeqdrzBcTujkwW3MzqVwTcwTmUoEgPTasrZB9i+UBnRbfFIurQCiRe/NZ7q59bLjSKXAM9vNZs3fC4+o8+9PX+96cYm2/xi0UxxqUtzIbO+z6HnUsxCzxt/biui0aCsmXEtsEhEjhaRGSJGDKTjRChLaRYTZseVhJ103PrsOBGKKGNNRL4gIpuBu4F7gEmqKqq6tpTROV3FqISqenSgk4VRCVV1046ThVEJVXWcLHioqlMZKheq2ujvjzemuHndeka82GRja0qxyZS+5/5e/qKQFmbGrjRZK2NbUTQemgugQ3Z7HnwmcypDIWUUkUtFZLWI7AbeDhxRzrCcbiSXMiahqtuAPwIuBBYmP48VkbeUNjqnq8j7bLoPuAQ4W1WXJYfXiMgiglLe2na+u5A5qeTdwCwEJgC3iUjr0/hewnPqA1DVa4BrAKbItJQEME63klcZ9y/vbwXao29ypv1xup28yrgS2AvMVdU7SxwP9SlTom3NXXbS84HTfyvaNvHHP7evO3O62b7rVXPjfS97xJRtGgnmaxMm2LJ79sRlx/WmyKaYfgxzVt3IBgeAEanZ2JQv6iRvrp0dIrIYWCwiAiwFJgGvBprJsuw4w6KI0fuzwEbg08ASYDuwHLiihHE5XUhuZdRQKPnryctxCuNZyJzK4NGBTmXwZ9NOZXBldCpD9VzIBnbmlt1xRPzj9KXY5KyMXACHPBmvLNAYSMlwZlDEhaw2w7aNNtetT7m48TAsrQrDzvx/pxg+MzqVIVUZReQuEVkiIl8RkS0isklELhKR8SLyTRHZKiJPicgfjMaAnYOXrDPjecAO4BTgi8CVwA+AR4GTgX8E/l5E5ozEIJ3uIKsyPqSqn1PVx4CvApuBQVX9mqo+Dvw1IEDHCuMequpkIasy/ioSMHny8hzwfy3HBoF+vJClU4CsytgpEtCjA51SceVxKkPl7Iw9c2ZF24bWP2PKLvvMV6Nt77nhTbnHBMBgfnugRRE7Y9r3MZLoCHwfPjM6lSF1ZowUrTwhsTNeCfw+MJXgy7i89BE6XUORmfEKQtaxDwOvJOyub+tka3TTjpOFXMqYhKp+HLhMVW9V1YeBjxE8vy9sP99NO04W8s6M8wlhqffsP6CqDeBeQhir4wybkdjAeFy0k4u8pp3VhBzepyW/IyJ14FTghiIDMk0dKZnC3n1cx1ylADR32pUB6ilFMtkWdyFLqypgkVacM63Cw0jR2GpXf7BCWRuD+3JdM2+o6k4RWQJ8KcnpvQb4FDALuDbXSJyup4jR+7Lk5w8INWA2Eh4R3gz8dsFxOV1IkVDVvcDFInIi8CrgRsKsaK+ljhOhrMeBa1T1T2KNHqrqZKGs3bSZyMbtjE4WylLG8qNznK7DHSWcylA5FzLdtTvaVj92vim79j3xMjSz77XtdbXN8esCqJU+bs06U7ZhVD+tTUxJiWc1vvxYU7b2uD2uphUWfEK8cgQAe400nA/HUwBaj0R8ZnQqQ5F60yuBrcAJwEIR2QNcqppSQMRxIoxKIUvHycKoFLJ0f0YnC6NSyNLtjE4WvJClUxnKNO2cDqSkyE9HZs+MN26x3cB6d8RNOxN+scaUHVwYr2YAMG59vMBmkcxpHB6PhgTQhx+LtvU8YxfXTB1XLW6uqj1jVywYPObwuKx91ShlKuP9gJ2jzXEMylxWBwm7a8fJRV7n2jNLHofjeLUDpzp4tQOnMrgpxqkMroxOZaicCxlb4+5Hzf64rQ9g8rp4FVHdHa9OCrBnpl3tYNwT8fDLIpnEmo+ttU8wwmAbm207o+YMGQWQCfbtVO+qeCWFRs7QXZ8ZncpQhgvZ+QQf0OeAtWUNzOk+ynQhWwBcX8agnO7EXcicyuAuZE5lcBcypzJUz7RjmEm0aZsMpvzXw3HZlMtOXmVn3dpx8pHRtolFEr2nhQzV4gUldZ9tupEe+89rmaQa6zfYsil/izz4TOZUBldGpzLkUsbEhewyEfknERkQkY3AKgARua684TndRJGZ8SvA64B3AmcBrwDO6HSim3acLOR9AjOJUHLjA6r6k+TYHwEd82mo6jXANQBTZJrn/HY6UrTawc/2H1DVncCKMgbldCe+gXEqQ5FqB4OE3N1PAIjIIYS8O6uLDMjMjJVikxt62UuibfWfP2LKSkoY7KSlz0Xb4o5r6dQm9ZntDaPKgvT0mrI6ZGQKA7N6RJodUeqG/bOZ7xvJG5A1ICLf4dfVDjYAf0GYaf2e0MlFkScwnwb6gB8BA8DfEUpv2F6sjhMh9z2jqg6o6h+oap+qziIo40uBx0sbndNV5J4ZReSVwPGEHfVkQl2YycBNHc71UFUnlaKOEpcAxxGcbJcDr1XVF9ga3c7oZKFIUaJfACeXOBanyxl1FzKp1ahNjC/VlttTY+ECs+9NJ8b7ndk8zpTVPXaEX3NCfFy9T9u3Hs1+wz1N7Nv2+qGHRtuGFhxlyvY8ZGdes1zQ9GV2gvm6kQGt8dzmuOCgkfnMvGJGkgAtxylEbmUUkTNE5Ky2Y2eJSEdnCcdJo8gy/STwVRE5F5gsIlcRYmAuKWVkTtdRxM74lKqeC2wDTgK2qeq5qvpU+7mtLmT71G3iTmeKLNNHishNwFTgf4GpInKTiLwgWKQ1OnCc2BWhnO6lyAbmJcDVqnoBsCP5eTUwr5SROV1HETvj0g7H7iw2HKebEc2ZMSr3BUU2ETY/+5kBxAxTVtvBKFvVcZUpO1dVO5e0UNUxfQEP5Gk7GGWrOq6RlG19uae3UxlcGZ3KUAVlvCZn28EoO5J9V1X2V4z6BsZxYlRhZnQcwJXRqRCujE5lcGV0KoMro1MZXBmdyvD/OKxL25iugMgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'are you avail'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0cyugfe7UYz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_Encoder_Decoder_Attention_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
