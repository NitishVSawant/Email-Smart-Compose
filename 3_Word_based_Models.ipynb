{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6W1O4UJcuAE"
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,BatchNormalization,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping,TensorBoard,LearningRateScheduler\n",
    "from nltk.translate import bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>Encoder Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "1NO2MKm2vbcb",
    "outputId": "089599d8-58e0-4ce9-dc89-7729ae8f45ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-08 21:57:26--  https://doc-0c-4g-docs.googleusercontent.com/docs/securesc/oik9lo733t355n1nglla0cdlqj79umtt/ehk8e924a2ltko8e12d28qusuc9agoer/1591653375000/00136369994752382157/00136369994752382157/16WsaIFQ3eMopsTJtclGqj4jSlyITPFx5?e=download&authuser=0&nonce=ik8omm9uggl20&user=00136369994752382157&hash=1sg7b7uhncfiv9ctkbq68jk0tcprr0rp\n",
      "Resolving doc-0c-4g-docs.googleusercontent.com (doc-0c-4g-docs.googleusercontent.com)... 74.125.128.132, 2a00:1450:4013:c02::84\n",
      "Connecting to doc-0c-4g-docs.googleusercontent.com (doc-0c-4g-docs.googleusercontent.com)|74.125.128.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘encoded_data’\n",
      "\n",
      "\r",
      "encoded_data            [<=>                 ]       0  --.-KB/s               \r",
      "encoded_data            [ <=>                ]   4.01M  6.38MB/s               \r",
      "encoded_data            [  <=>               ]   7.08M  11.1MB/s    in 0.6s    \n",
      "\n",
      "2020-06-08 21:57:29 (11.1 MB/s) - ‘encoded_data’ saved [7426606]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-0c-4g-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://drive.google.com/drive/u/0/folders/1Nz-Vq0RhziotMAesPgnisN_Ti9HNQ51f\" --header=\"Cookie: AUTH_bfhjrtscq695ib7edi83p6bfm42sd929_nonce=ik8omm9uggl20; _ga=GA1.2.1509677474.1591248567\" --header=\"Connection: keep-alive\" \"https://doc-0c-4g-docs.googleusercontent.com/docs/securesc/oik9lo733t355n1nglla0cdlqj79umtt/ehk8e924a2ltko8e12d28qusuc9agoer/1591653375000/00136369994752382157/00136369994752382157/16WsaIFQ3eMopsTJtclGqj4jSlyITPFx5?e=download&authuser=0&nonce=ik8omm9uggl20&user=00136369994752382157&hash=1sg7b7uhncfiv9ctkbq68jk0tcprr0rp\" -c -O 'encoded_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5JLhjfZ0XEz"
   },
   "source": [
    "<h1>1. Read Featurized data</h1> \n",
    "<h2>(Refer Word Featurization Section 3 of 2_Data_Featurization.ipynb)</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnTFvgjaWx8o"
   },
   "outputs": [],
   "source": [
    "[X_train_padded_docs,y_train_padded_docs,X_val_padded_docs,y_val_padded_docs,inp_embedding_matrix,\n",
    "                             out_embedding_matrix,inp_tokenizer,out_tokenizer] = joblib.load('encoded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjB44o3q0XHp"
   },
   "source": [
    "<h1>2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icMEwKexcuC2"
   },
   "source": [
    "<h2>2.1. Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgtZmDqYcuC6"
   },
   "outputs": [],
   "source": [
    "#Encoder class\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,enc_units,**kwargs):\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, weights=[embedding_matrix],\n",
    "                                   mask_zero=True,name='Encoder_Embedding',trainable=False)\n",
    "        self.lstm = LSTM(self.enc_units,return_sequences=True,return_state=True,name='Encoder_LSTM',dropout=0.33)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        #state_c = Cell state output of last time step\n",
    "        encoder_outputs, _, state_c = self.lstm(x)\n",
    "\n",
    "        #Take average of encoder_outputs\n",
    "        hidden = tf.reduce_mean(encoder_outputs,1)\n",
    "        \n",
    "        return hidden, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uc064MCCcuC_",
    "outputId": "03f356f1-9764-477c-938a-db7d7f797269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Vocab size: 1470\n"
     ]
    }
   ],
   "source": [
    "inp_vocab_size = len(inp_tokenizer.word_index) + 1\n",
    "print('Input Vocab size:',inp_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "P_xpJvvccuDE",
    "outputId": "ad16f054-d816-430e-fea3-4b2db17bf41d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch input data (batch_size,sequence length): (32, 23)\n",
      "Shape of batch output data (batch_size,sequence length): (32, 23)\n",
      "Shape of average hidden state output (batch_size,units): (32, 256)\n",
      "Shape of average memory state output (batch_size,units): (32, 256)\n"
     ]
    }
   ],
   "source": [
    "#Create encoder object\n",
    "BATCH_SIZE = 32\n",
    "encoder = Encoder(vocab_size=inp_vocab_size,embedding_dim=300,embedding_matrix=inp_embedding_matrix,\n",
    "                  enc_units=256,name='Encoder')\n",
    "\n",
    "#Sample input to encoder\n",
    "example_input_batch, example_target_batch = X_train_padded_docs[:BATCH_SIZE], y_train_padded_docs[:BATCH_SIZE]\n",
    "print('Shape of batch input data (batch_size,sequence length):',example_input_batch.shape)\n",
    "print('Shape of batch output data (batch_size,sequence length):',example_target_batch.shape)\n",
    "\n",
    "#Genearte sample hidden state from encoder object\n",
    "sample_hidden_output, sample_cell_output = encoder(example_input_batch)\n",
    "print('Shape of average hidden state output (batch_size,units):',sample_hidden_output.shape)\n",
    "print('Shape of average memory state output (batch_size,units):',sample_cell_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWTi0DbhcuDf"
   },
   "source": [
    "<h2>2.2. Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxVxxpnbcuDg"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,dec_units,**kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim,\n",
    "                                            weights=[embedding_matrix],mask_zero=True,name='Decoder_Embedding',trainable=False)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units,return_sequences=True,return_state=True,name='Decoder_LSTM',\n",
    "                                         dropout=0.33)\n",
    "        self.batch_norm = BatchNormalization()\n",
    "        \n",
    "    def call(self, x, hidden, cell):\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # passing the concatenated vector to the LSTM\n",
    "        lstm_output, state_h, state_c = self.lstm(x,initial_state=[hidden,cell])\n",
    "        \n",
    "        #Normalise output\n",
    "        lstm_output = self.batch_norm(lstm_output)\n",
    "        \n",
    "        return lstm_output,state_h,state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MwzqwDHZWx9H",
    "outputId": "621107c6-c964-48d9-e319-9cd66041db9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Vocab size: 1469\n"
     ]
    }
   ],
   "source": [
    "out_vocab_size = len(out_tokenizer.word_index) + 1\n",
    "print('Output Vocab size:',out_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "b9pinu5acuDv",
    "outputId": "03165dea-09b1-4e3e-d38a-85cd797552a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder:\n",
      "Shape of decoder input (batch_size,sequence_length): (32, 23)\n",
      "Shape of decoder output (batch_size,sequence_length,units): (32, 23, 256)\n",
      "Shape of decoder hidden state output (batch_size,units): (32, 256)\n",
      "Shape of decoder memory state output (batch_size,units): (32, 256)\n"
     ]
    }
   ],
   "source": [
    "#Initialise one step decoder\n",
    "BATCH_SIZE = 32\n",
    "dec = Decoder(vocab_size=out_vocab_size,embedding_dim=300,embedding_matrix=out_embedding_matrix,dec_units=256)\n",
    "\n",
    "#Geneate sample output and hidden states from decoder object\n",
    "sample_output_dec,sample_hidden_output_dec,sample_cell_output_dec = dec(example_target_batch,sample_hidden_output,\n",
    "                                                                        sample_cell_output)\n",
    "print('Decoder:')\n",
    "print('Shape of decoder input (batch_size,sequence_length):',example_target_batch.shape)\n",
    "print('Shape of decoder output (batch_size,sequence_length,units):',sample_output_dec.shape)\n",
    "print('Shape of decoder hidden state output (batch_size,units):',sample_hidden_output_dec.shape)\n",
    "print('Shape of decoder memory state output (batch_size,units):',sample_cell_output_dec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qlauC-cuET"
   },
   "source": [
    "<h2>2.3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDQubxhQcuEU"
   },
   "outputs": [],
   "source": [
    "class Encoder_Decoder_Model(tf.keras.models.Model):\n",
    "    def __init__(self, inp_vocab_size,out_vocab_size,embedding_dim,inp_embedding_matrix,out_embedding_matrix,units,**kwargs):\n",
    "        super(Encoder_Decoder_Model,self).__init__(**kwargs)\n",
    "        self.encoder = Encoder(vocab_size=inp_vocab_size, embedding_dim=embedding_dim,embedding_matrix=inp_embedding_matrix,\n",
    "                               enc_units=units,name='Encoder_layer')\n",
    "        self.decoder = Decoder(vocab_size=out_vocab_size, embedding_dim=embedding_dim,embedding_matrix=out_embedding_matrix,\n",
    "                               dec_units=units,name='Decoder_layer')\n",
    "        self.drop = Dropout(0.2,name='Dropout')\n",
    "        self.dense = Dense(out_vocab_size,name='Output_layer')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #Inputs will contain encoder input and decoder input\n",
    "        #Separate encoder and decoder inputs\n",
    "        encoder_inputs, decoder_inputs = inputs[0], inputs[1]\n",
    "        \n",
    "        #Genearte output and hidden states from encoder object\n",
    "        enc_hidden_output, enc_cell_output = self.encoder(encoder_inputs)\n",
    "\n",
    "        #Generate output from decoder\n",
    "        #Initialise hidden states of decoder with hidden states of encoder\n",
    "        decoder_outputs,_,_ = self.decoder(decoder_inputs,enc_hidden_output,enc_cell_output)\n",
    "\n",
    "        #Dropout\n",
    "        decoder_outputs = self.drop(decoder_outputs)\n",
    "        \n",
    "        #Shape of outputs = (batch_size,timesteps,vocab_size)\n",
    "        outputs = self.dense(decoder_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3JlgiLdcuEM"
   },
   "source": [
    "<h2>2.4. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DTKipswcuEN"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHe4U-qBcuER"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    \n",
    "    #Identify zeros in real tensor/Creating masking tensor\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    #Calculate log loss for each class\n",
    "    loss_ = loss_object(real, pred)\n",
    "    #Change data type of mask\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #Calculate loss considering masking\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcrEYcmlL7H6"
   },
   "source": [
    "<h2>2.5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBKLoKUbL7H7"
   },
   "outputs": [],
   "source": [
    "#Function returns texts from a sequence\n",
    "def get_text_from_seq(sequence,tokenizer):\n",
    "    sent =''\n",
    "    for i in sequence:\n",
    "        if i!=0:\n",
    "            sent+=tokenizer.index_word[i]+' '\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ_KwVRdL7H_"
   },
   "outputs": [],
   "source": [
    "#Function to get bleu score for a sentence\n",
    "def get_bleu_score(enc_dec_model,input_seq,expected_output_seq):\n",
    "    \n",
    "    input_max_length = X_train_padded_docs.shape[1]\n",
    "    output_max_length = y_train_padded_docs.shape[1]\n",
    "    \n",
    "    #Get output from encoder\n",
    "    enc_hidden,enc_cell = enc_dec_model.layers[0](input_seq.reshape(1,input_max_length))\n",
    "    \n",
    "    #Boundary case for decoder\n",
    "    dec_input = tf.expand_dims([out_tokenizer.word_index['<start>']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    \n",
    "    #Predicted output sequence\n",
    "    #Add <start> token to output sequence\n",
    "    output_seq = [out_tokenizer.word_index['<start>']]\n",
    "    \n",
    "    #The model will start predicting after start token, hence max_length is subtracted by 1\n",
    "    for i in range(output_max_length-1):\n",
    "        #Get prediction from decoder\n",
    "        dec_output,dec_hidden,dec_cell = enc_dec_model.layers[1](dec_input,dec_hidden,dec_cell)\n",
    "        \n",
    "        #Get prediction from dense layer\n",
    "        #Shape == (batch_size,timestep,vocab_size) == (1,1,vocab_size)\n",
    "        outputs = enc_dec_model.layers[3](dec_output)\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = np.argmax(outputs.numpy().reshape(-1))\n",
    "        \n",
    "        output_seq.append(key)\n",
    "        \n",
    "        if out_tokenizer.index_word[key] == '<end>':\n",
    "            #Get texts from input sentence\n",
    "            input_sent = get_text_from_seq(input_seq,inp_tokenizer)\n",
    "            #Get texts from sequence for actual sentence\n",
    "            actual = get_text_from_seq(expected_output_seq,out_tokenizer)\n",
    "            #Get texts from sequence for predicted sentence\n",
    "            prediction = get_text_from_seq(output_seq,out_tokenizer)\n",
    "            return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    input_sent = get_text_from_seq(input_seq,inp_tokenizer)\n",
    "    actual = get_text_from_seq(expected_output_seq,out_tokenizer)\n",
    "    prediction = get_text_from_seq(output_seq,out_tokenizer)\n",
    "    return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6naCdjvcuEa"
   },
   "source": [
    "<h1>3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TTqWUC8cuEa"
   },
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "inp_vocab_size = len(inp_tokenizer.word_index) + 1  \n",
    "out_vocab_size = len(out_tokenizer.word_index) + 1 \n",
    "#Encoding and decoding Embedding layer dimension\n",
    "embedding_dim = 300\n",
    "#Encoding and decoding LSTM layer units\n",
    "units = 256\n",
    "\n",
    "#Initialise object for Model class\n",
    "model = Encoder_Decoder_Model(inp_vocab_size,out_vocab_size,embedding_dim,inp_embedding_matrix,\n",
    "                              out_embedding_matrix,units,name='Encoder_Decoder_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "PKDJZOJDcuEc",
    "outputId": "b998c250-4c19-4936-af06-728ab284c819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder_Decoder_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_layer (Encoder)      multiple                  1011368   \n",
      "_________________________________________________________________\n",
      "Decoder_layer (Decoder)      multiple                  1012092   \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "Output_layer (Dense)         multiple                  377533    \n",
      "=================================================================\n",
      "Total params: 2,400,993\n",
      "Trainable params: 1,518,781\n",
      "Non-trainable params: 882,212\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Max sequence length for input = max_length\n",
    "#Max sequence length for output = max_length-1, 1 is subtracted because <end> token should not be give input to decoder\n",
    "model.build(input_shape=[(None,X_train_padded_docs.shape[1]),(None,y_train_padded_docs.shape[1]-1)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20CwK6Chcj1d"
   },
   "outputs": [],
   "source": [
    "def data_generator(X,y,BATCH_SIZE,shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(X)).batch(BATCH_SIZE,drop_remainder=True)\n",
    "    else:\n",
    "        dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEn_0bp2cuEf"
   },
   "outputs": [],
   "source": [
    "#Create folder to save model weights\n",
    "if not os.path.isdir('model_save'):\n",
    "    os.makedirs('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsXuVDsV0XIU"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tyKYm6yocuEm",
    "outputId": "c7f48e9a-98fc-4cf0-ccf2-3673a85bf1d1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 1.1773\n",
      "Epoch 00001: loss improved from inf to 1.17735, saving model to model_save/weights-01-1.1773.hdf5\n",
      "642/642 [==============================] - 92s 143ms/step - loss: 1.1773 - val_loss: 0.9229 - lr: 0.0100\n",
      "Epoch 2/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 1.0271\n",
      "Epoch 00002: loss improved from 1.17735 to 1.02706, saving model to model_save/weights-02-1.0271.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 1.0271 - val_loss: 0.8842 - lr: 0.0100\n",
      "Epoch 3/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9819\n",
      "Epoch 00003: loss improved from 1.02706 to 0.98189, saving model to model_save/weights-03-0.9819.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.9819 - val_loss: 0.8740 - lr: 0.0100\n",
      "Epoch 4/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9552\n",
      "Epoch 00004: loss improved from 0.98189 to 0.95522, saving model to model_save/weights-04-0.9552.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.9552 - val_loss: 0.8668 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9367\n",
      "Epoch 00005: loss improved from 0.95522 to 0.93671, saving model to model_save/weights-05-0.9367.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.9367 - val_loss: 0.8642 - lr: 0.0100\n",
      "Epoch 6/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9228\n",
      "Epoch 00006: loss improved from 0.93671 to 0.92279, saving model to model_save/weights-06-0.9228.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.9228 - val_loss: 0.8636 - lr: 0.0100\n",
      "Epoch 7/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9121\n",
      "Epoch 00007: loss improved from 0.92279 to 0.91211, saving model to model_save/weights-07-0.9121.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.9121 - val_loss: 0.8624 - lr: 0.0100\n",
      "Epoch 8/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9030\n",
      "Epoch 00008: loss improved from 0.91211 to 0.90300, saving model to model_save/weights-08-0.9030.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.9030 - val_loss: 0.8624 - lr: 0.0100\n",
      "Epoch 9/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8955\n",
      "Epoch 00009: loss improved from 0.90300 to 0.89550, saving model to model_save/weights-09-0.8955.hdf5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.8955 - val_loss: 0.8643 - lr: 0.0100\n",
      "Epoch 10/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8835\n",
      "Epoch 00010: loss improved from 0.89550 to 0.88355, saving model to model_save/weights-10-0.8835.hdf5\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.8835 - val_loss: 0.8648 - lr: 0.0090\n",
      "Epoch 11/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8778\n",
      "Epoch 00011: loss improved from 0.88355 to 0.87780, saving model to model_save/weights-11-0.8778.hdf5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.8778 - val_loss: 0.8657 - lr: 0.0090\n",
      "Epoch 12/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8681\n",
      "Epoch 00012: loss improved from 0.87780 to 0.86810, saving model to model_save/weights-12-0.8681.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8681 - val_loss: 0.8653 - lr: 0.0081\n",
      "Epoch 13/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8637\n",
      "Epoch 00013: loss improved from 0.86810 to 0.86365, saving model to model_save/weights-13-0.8637.hdf5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8637 - val_loss: 0.8655 - lr: 0.0081\n",
      "Epoch 14/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8550\n",
      "Epoch 00014: loss improved from 0.86365 to 0.85495, saving model to model_save/weights-14-0.8550.hdf5\n",
      "642/642 [==============================] - 89s 138ms/step - loss: 0.8550 - val_loss: 0.8671 - lr: 0.0073\n",
      "Epoch 15/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8509\n",
      "Epoch 00015: loss improved from 0.85495 to 0.85087, saving model to model_save/weights-15-0.8509.hdf5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8509 - val_loss: 0.8677 - lr: 0.0073\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 30\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Reduce learning rate by 10% if validation loss does not decrease from last 2 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, verbose=1, patience=2,min_lr=0.00001)\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 8 epochs\n",
    "terminate = EarlyStopping(monitor='val_loss',patience=8,verbose=1,mode='min',restore_best_weights=True)\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list = [checkpoint,reduce_lr,terminate,tensorboard_callback]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history1 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1Xe0AHTrEPTK",
    "outputId": "a6f202e0-3f10-4fe3-fdd7-188d8178e8c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history1']"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history1.history,'history1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mrd7PRmjcuEp"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7ObOhaJazQcU",
    "outputId": "da03bd2c-1659-4e37-eb9f-4709c93613b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/643 [==============================] - 32s 50ms/step - loss: 0.8201\n"
     ]
    }
   ],
   "source": [
    "train_parameters = model.evaluate([X_train_padded_docs,y_train_padded_docs[:,:-1]],y_train_padded_docs[:,1:],\n",
    "                                  verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dOq7_Vm-zjIM",
    "outputId": "78e596fb-2fce-448c-d8d9-6cc3b204537b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 51ms/step - loss: 0.8627\n"
     ]
    }
   ],
   "source": [
    "val_parameters = model.evaluate([X_val_padded_docs,y_val_padded_docs[:,:-1]],y_val_padded_docs[:,1:],\n",
    "                                 verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt-hIXlo7fBQ"
   },
   "outputs": [],
   "source": [
    "#Load weights\n",
    "model.load_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kumpzV1LEPTb",
    "outputId": "fcca0bf1-373d-4fa6-af48-1cc6c9348e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  2/642 [..............................] - ETA: 2:11 - loss: 0.8565WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.138014). Check your callbacks.\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8659\n",
      "Epoch 00001: loss improved from inf to 0.86594, saving model to model_save/weights-01-0.8659.hdf5\n",
      "642/642 [==============================] - 91s 142ms/step - loss: 0.8659 - val_loss: 0.8472 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8528\n",
      "Epoch 00002: loss improved from 0.86594 to 0.85278, saving model to model_save/weights-02-0.8528.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8528 - val_loss: 0.8452 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8466\n",
      "Epoch 00003: loss improved from 0.85278 to 0.84657, saving model to model_save/weights-03-0.8466.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8466 - val_loss: 0.8447 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8421\n",
      "Epoch 00004: loss improved from 0.84657 to 0.84213, saving model to model_save/weights-04-0.8421.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8421 - val_loss: 0.8447 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8382\n",
      "Epoch 00005: loss improved from 0.84213 to 0.83825, saving model to model_save/weights-05-0.8382.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8382 - val_loss: 0.8445 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8348\n",
      "Epoch 00006: loss improved from 0.83825 to 0.83484, saving model to model_save/weights-06-0.8348.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8348 - val_loss: 0.8448 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8319\n",
      "Epoch 00007: loss improved from 0.83484 to 0.83186, saving model to model_save/weights-07-0.8319.hdf5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "642/642 [==============================] - 89s 138ms/step - loss: 0.8319 - val_loss: 0.8451 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8282\n",
      "Epoch 00008: loss improved from 0.83186 to 0.82820, saving model to model_save/weights-08-0.8282.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8282 - val_loss: 0.8455 - lr: 9.0000e-04\n",
      "Epoch 9/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8259\n",
      "Epoch 00009: loss improved from 0.82820 to 0.82587, saving model to model_save/weights-09-0.8259.hdf5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8259 - val_loss: 0.8456 - lr: 9.0000e-04\n",
      "Epoch 10/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8229\n",
      "Epoch 00010: loss improved from 0.82587 to 0.82286, saving model to model_save/weights-10-0.8229.hdf5\n",
      "642/642 [==============================] - 89s 138ms/step - loss: 0.8229 - val_loss: 0.8458 - lr: 8.1000e-04\n",
      "Epoch 11/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8207\n",
      "Epoch 00011: loss improved from 0.82286 to 0.82073, saving model to model_save/weights-11-0.8207.hdf5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "642/642 [==============================] - 89s 138ms/step - loss: 0.8207 - val_loss: 0.8465 - lr: 8.1000e-04\n",
      "Epoch 12/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8179\n",
      "Epoch 00012: loss improved from 0.82073 to 0.81786, saving model to model_save/weights-12-0.8179.hdf5\n",
      "642/642 [==============================] - 89s 138ms/step - loss: 0.8179 - val_loss: 0.8468 - lr: 7.2900e-04\n",
      "Epoch 13/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8161\n",
      "Epoch 00013: loss improved from 0.81786 to 0.81612, saving model to model_save/weights-13-0.8161.hdf5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8161 - val_loss: 0.8471 - lr: 7.2900e-04\n",
      "Epoch 14/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8138\n",
      "Epoch 00014: loss improved from 0.81612 to 0.81380, saving model to model_save/weights-14-0.8138.hdf5\n",
      "642/642 [==============================] - 89s 138ms/step - loss: 0.8138 - val_loss: 0.8477 - lr: 6.5610e-04\n",
      "Epoch 15/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8124\n",
      "Epoch 00015: loss improved from 0.81380 to 0.81237, saving model to model_save/weights-15-0.8124.hdf5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "642/642 [==============================] - 89s 138ms/step - loss: 0.8124 - val_loss: 0.8485 - lr: 6.5610e-04\n",
      "Epoch 16/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8100\n",
      "Epoch 00016: loss improved from 0.81237 to 0.81000, saving model to model_save/weights-16-0.8100.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8100 - val_loss: 0.8487 - lr: 5.9049e-04\n",
      "Epoch 17/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8087\n",
      "Epoch 00017: loss improved from 0.81000 to 0.80871, saving model to model_save/weights-17-0.8087.hdf5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8087 - val_loss: 0.8489 - lr: 5.9049e-04\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 20\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Reduce learning rate by 10% if validation loss does not decrease from last 2 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, verbose=1, patience=2,min_lr=0.00001)\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 12 epochs\n",
    "terminate = EarlyStopping(monitor='val_loss',patience=12,verbose=1,mode='min',restore_best_weights=False)\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list = [checkpoint,reduce_lr,terminate,tensorboard_callback]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history2 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TrublRKQEPTd",
    "outputId": "1508d333-69ec-446d-b275-9f0b991f510b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history2']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history2.history,'history2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1HujhSgEPTj"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bnn6eR1SEPTl"
   },
   "outputs": [],
   "source": [
    "#Load weights\n",
    "model.load_weights('best_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IIDYqv0iEPTs",
    "outputId": "613dfef5-f249-4a6c-f080-406b4df3ef7b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8031\n",
      "Epoch 00001: loss improved from inf to 0.80306, saving model to model_save/weights-01-0.8031.hdf5\n",
      "642/642 [==============================] - 91s 143ms/step - loss: 0.8031 - val_loss: 0.8466 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8028\n",
      "Epoch 00002: loss improved from 0.80306 to 0.80282, saving model to model_save/weights-02-0.8028.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8028 - val_loss: 0.8459 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8027\n",
      "Epoch 00003: loss improved from 0.80282 to 0.80274, saving model to model_save/weights-03-0.8027.hdf5\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8027 - val_loss: 0.8457 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8029\n",
      "Epoch 00004: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8029 - val_loss: 0.8454 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8034\n",
      "Epoch 00005: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8034 - val_loss: 0.8450 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8042\n",
      "Epoch 00006: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8042 - val_loss: 0.8447 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8044\n",
      "Epoch 00007: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8044 - val_loss: 0.8445 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8048\n",
      "Epoch 00008: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.8048 - val_loss: 0.8443 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8055\n",
      "Epoch 00009: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 90s 140ms/step - loss: 0.8055 - val_loss: 0.8444 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8060\n",
      "Epoch 00010: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8060 - val_loss: 0.8442 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8068\n",
      "Epoch 00011: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8068 - val_loss: 0.8440 - lr: 9.0000e-05\n",
      "Epoch 12/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8071\n",
      "Epoch 00012: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8071 - val_loss: 0.8440 - lr: 9.0000e-05\n",
      "Epoch 13/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8076\n",
      "Epoch 00013: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8076 - val_loss: 0.8440 - lr: 9.0000e-05\n",
      "Epoch 14/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8085\n",
      "Epoch 00014: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 90s 139ms/step - loss: 0.8085 - val_loss: 0.8439 - lr: 8.1000e-05\n",
      "Epoch 15/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8087\n",
      "Epoch 00015: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8087 - val_loss: 0.8439 - lr: 8.1000e-05\n",
      "Epoch 16/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8092\n",
      "Epoch 00016: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8092 - val_loss: 0.8440 - lr: 8.1000e-05\n",
      "Epoch 17/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8101\n",
      "Epoch 00017: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8101 - val_loss: 0.8439 - lr: 7.2900e-05\n",
      "Epoch 18/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8106\n",
      "Epoch 00018: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8106 - val_loss: 0.8439 - lr: 7.2900e-05\n",
      "Epoch 19/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8108\n",
      "Epoch 00019: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8108 - val_loss: 0.8439 - lr: 6.5610e-05\n",
      "Epoch 20/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8116\n",
      "Epoch 00020: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 5.904900172026828e-05.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8116 - val_loss: 0.8439 - lr: 6.5610e-05\n",
      "Epoch 21/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8118\n",
      "Epoch 00021: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8118 - val_loss: 0.8439 - lr: 5.9049e-05\n",
      "Epoch 22/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8123\n",
      "Epoch 00022: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 5.314410154824145e-05.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8123 - val_loss: 0.8441 - lr: 5.9049e-05\n",
      "Epoch 23/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8129\n",
      "Epoch 00023: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8129 - val_loss: 0.8441 - lr: 5.3144e-05\n",
      "Epoch 24/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8134\n",
      "Epoch 00024: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.7829690083744934e-05.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8134 - val_loss: 0.8441 - lr: 5.3144e-05\n",
      "Epoch 25/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8136\n",
      "Epoch 00025: loss did not improve from 0.80274\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8136 - val_loss: 0.8441 - lr: 4.7830e-05\n",
      "Epoch 26/30\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8143\n",
      "Epoch 00026: loss did not improve from 0.80274\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.304672074795235e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "642/642 [==============================] - 89s 139ms/step - loss: 0.8143 - val_loss: 0.8441 - lr: 4.7830e-05\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 30\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.0001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Reduce learning rate by 10% if validation loss does not decrease from last 2 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, verbose=1, patience=2,min_lr=0.00001)\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 12 epochs\n",
    "terminate = EarlyStopping(monitor='val_loss',patience=12,verbose=1,mode='min',restore_best_weights=True)\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list = [checkpoint,reduce_lr,terminate,tensorboard_callback]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs[:,:-1]),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs[:,:-1]),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history3 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S49NiQJHEPTv",
    "outputId": "50e5c968-0e68-4707-9902-a6c2b23c2913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history3']"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history3.history,'history3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ben7LIgEPTz"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BemqyciZEPT2"
   },
   "outputs": [],
   "source": [
    "#Load weights\n",
    "model.load_weights('best_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sa2ll5JYguT"
   },
   "outputs": [],
   "source": [
    "h1 = joblib.load('history1')\n",
    "h2 = joblib.load('history2')\n",
    "h3 = joblib.load('history3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xl1NWqsYguW"
   },
   "outputs": [],
   "source": [
    "loss = h1['loss']+h2['loss']+h3['loss']\n",
    "val_loss = h1['val_loss']+h2['val_loss']+h3['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zES1qW6XYguZ",
    "outputId": "bd6ab8b3-b0b2-4da4-a9bf-193cd62c0d4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Vs No of epochs')"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXwU9f348dd7j9wXZzjCqUAAgQABFTwC9VuxnrVapRZEW6/aWmu1ao+ftrX92m/VtrRaRetZFbEt1ireEsCjKvchhxECBJT7SMi52ffvj5mEJWwOkiybbN7Px2Meuzuf+cy8PxuY985nZj4jqooxxhhTlyfaARhjjGmbLEEYY4wJyxKEMcaYsCxBGGOMCcsShDHGmLAsQRhjjAnLEoQxbZiIDBGRZSJSLCI3RTseABFRETkx2nGYyLMEYY4rESkUkbOO8zbvFJGFYeZ3FZFKETnpGNbV391Bvlpn/t9F5O5WCLeunwD5qpqqqjMjsH5j6mUJwnQEzwATRGRAnfmXA6tUdXUz1nmKiExseWiN6gesOQ7bMeYoliBMmyAi8SLyRxHZ7k5/FJF4t6yriLwiIvtFZK+ILBIRj1t2u4hsc7tg1ovIV+quW1WLgHeBaXWKpgNPues5UUQWiMgBEdktIi80EvL/Afc00J5rRKTAjfdlEenVwLIXiMgat335IjLUnf8uMAn4i4iUiMjgMHXTReRvIvKF+z3cIyJet2yGiLwvIn9227Uu9PsRkV5ubHvdWK8JKfOKyE9F5HP3u10iIn1CNn2WiHwmIvtE5EERkWZ+j6YtU1WbbDpuE1AInBVm/q+A/wLdgW7AB8Cv3bL/BR4G/O50OiDAEGAr0Mtdrj9wQj3bvQL4LOTzEKAS6OZ+fh74Gc6PpgTgtHrW0x9QIAXYVtMW4O/A3e77ycBuYAwQD/wZWFjP+gYDh4D/cdv2E6AAiHPL84HvNvB9vgQ8AiS7393HwHVu2QwgAPzIXfdlwAGgs1u+AHjIbW8OsAv4ilt2G7DK/Z4EGAV0ccsUeAXIAPq69aYcy/doU/uY7AjCtBVXAL9S1Z2qugv4JYd/8VcBPYF+qlqlqovU2RtV4+yAh4mIX1ULVfXzetY/F8gUkQnu5+nAa+62arbRDyfZlKvqe43EWw78hvBHEVcAj6vqUlWtAO4EThWR/mGWvQx4VVXfUtUq4D4gEZgQZtkjiEgmcA5ws6oeUtWdwB9wus5q7AT+6H5vLwDrgXPdo4HTgNvd9i4HHuPwd/5d4Oequl4dK1R1T8h671XV/aq6BZiPk2Dg2L9H04ZZgjBtRS9gc8jnze48gN/j/Kp+U0Q2isgdAKpaANwM3A3sFJHZ9XXlqGop8CIw3e0OuQK3e8n1E5xfyh+73T1XNyHmR3GSzvkNtUVVS4A9QO8w66i7bBDnqCjcsnX1wzky+MLtntqPczTRPWSZbW4yrVHzvfYC9qpqcZ2ymu32AepLtgBfhrwvxTmiguZ9j6aNsgRh2ortODu8Gn3deahqsar+WFUHAucDt9T0pavqc6p6mltXgd81sI2ngG/idOek4nST4K7nS1W9RlV7AdcBDzV2Kaf7i/+XwK9xdoph2yIiyUAXnC6pBtvtJq8+9Sxb11agAuiqqhnulKaqw0OW6V1zfsBV871uBzqLSGqdsprtbgVOaEIMR2jO92jaLksQJhr8IpIQMvlw+q5/LiLdRKQr8P9w+vURkfPck58CHMTpWqp27xGY7J7MLgfK3LL6LAL2A7OA2apaWVMgIpeKSJb7cR9OsmloXTWewenmmhIy7zngKhHJcWP7LfCRqhaGqT8Hp8vnKyLiB36Ms9P/oLENq+oXwJvA/SKSJiIeETlBRM4MWaw7cJOI+EXkUmAoME9Vt7rb+F/3bzAS+A7wrFvvMeDXIjJIHCNFpEtjMbXgezRtkCUIEw3zcHbmNdPdOH35i4GVOCdHl3K4f38Q8DZQAnwIPKSq+Tg75ntxTgh/ibMz/Gl9G3W7Wp7G+cX+dJ3iccBHIlICvAz8UFU3NdYQVa0G7gI6h8x7B/gF8E/gC5xf4pfXU3898G2cE9m7cY6Qzg9NXo2YDsQBn+LskP+Bc76mxkc4399unHMml4ScS5iKc9J9O845mrtU9S237AGc5PUmTlL+G865kcY063s0bZMc2T1pjIkVIjID5wqo06Idi2mf7AjCGGNMWJYgjDHGhGVdTMYYY8KyIwhjjDFh+aIdQGvq2rWr9u/fv1l1Dx06RHJycusGFGWx2CaIzXZZm9qPWGvXkiVLdqtqt3BlMZUg+vfvz+LFi5tVNz8/n7y8vNYNKMpisU0Qm+2yNrUfsdYuEdlcX5l1MRljjAnLEoQxxpiwLEEYY4wJK6bOQRhjjq+qqiqKioooLy8/qiw9PZ21a9dGIarIaq/tSkhIICsrC7/f3+Q6liCMMc1WVFREamoq/fv358hBY6G4uJjU1NR6arZf7bFdqsqePXsoKipiwIC6T96tn3UxGWOarby8nC5duhyVHEzbIiJ06dIl7JFeQyxBGGNaxJJD+9Ccv1OHTxCqysx3PmPVrkC0QzHGmDalwycIEeHRhRtZudueaWJMe7Nnzx5ycnLIycmhR48e9O7du/ZzZWXDj9RYvHgxN910U6PbmDCh0ceDN0l+fj7nnXdeq6zreLGT1EBaop/Sqqpoh2GMOUZdunRh+fLlANx9992kpKRw66231pYHAgF8vvC7udzcXHJzcxvdxgcfNPpwv5jV4Y8gANIT/ZRU2ai2xsSCGTNmcMsttzBp0iRuv/12Pv74YyZMmMDo0aOZMGEC69evB478RX/33Xdz9dVXk5eXx8CBA5k5c2bt+lJSUmqXz8vLY9q0aWRnZ3PFFVdQMxr2vHnzyM7O5rTTTuOmm25q9Ehh7969XHTRRYwcOZJTTjmFlStXArBgwYLaI6DRo0dTXFzMF198wRlnnEFOTg4nnXQSixYtavXvrD52BIGTIHbvtQRhTEv88j9r+HT7wdrP1dXVeL3eFq1zWK807jp/+DHX27BhA2+//TZer5eDBw+ycOFCfD4fb7/9Nj/96U/55z//eVSddevWMX/+fIqLixkyZAg33HDDUfcMLFu2jI8++ojBgwczceJE3n//fXJzc7nuuutYuHAhAwYMYOrUqY3Gd9dddzF69Gheeukl3n33XaZPn87y5cu57777ePDBB5k4cSIlJSUkJCQwa9Yszj77bH72s59RXV1NaWnpMX8fzWUJAidBbA5YgjAmVlx66aW1yenAgQNceeWVfPbZZ4gIVfV0J5977rnEx8cTHx9P9+7d2bFjB1lZWUcsM378eHr37o3H4yEnJ4fCwkJSUlIYOHBg7f0FU6dOZdasWQ3G995779UmqcmTJ7Nnzx4OHDjAxIkTueWWW7jiiiu4+OKLycrKYty4cVx99dVUVVVx0UUXkZOT09Kvp8ksQQAZSX5K7RSEMS1S95d+NG8oCx2O+xe/+AWTJk1i7ty5FBYW1jsSa3x8fO17r9dLIHD0lY3hlmnOQ9fC1RER7rjjDs4991zmzZvHKaecwttvv80ZZ5zBwoULefXVV5k2bRq33XYb06dPP+ZtNoedg8A5gjhk5yCMiUkHDhygd+/eADz55JOtvv7s7Gw2btxIYWEhAC+88EKjdc444wyeffZZwDm30bVrV9LS0vj8888ZMWIEt99+O7m5uaxbt47NmzfTvXt3rrnmGr7zne+wdOnSVm9DfewIAucqpqoglFdVk+BvWZ+pMaZt+clPfsKVV17JAw88wOTJk1t9/YmJiTz00ENMmTKFrl27Mn78+Ebr3H333Vx11VWMHDmSpKQknnrqKQD++Mc/Mn/+fLxeL8OGDeOcc85h9uzZ/P73v8fv95OSksLTTz/d6m2ol6rGzDR27Fhtjmc+LNR+t7+iXx4oa1b9tmr+/PnRDiEiYrFd7bVNn376ab1lBw8ePI6RHD/h2lVcXKyqqsFgUG+44QZ94IEHjndYTRLu7wUs1nr2qdbFhHMOAuBAmZ2IMMYcu0cffZScnByGDx/OgQMHuO6666IdUquwLiaccxBgCcIY0zw/+tGP+NGPfhTtMFqdHUFwOEHst0uZjDGmVsQShIg8LiI7RWR1PeXZIvKhiFSIyK11ygpFZJWILBeRxZGKsYYdQRhjzNEieQTxJDClgfK9wE3AffWUT1LVHFVtfLCUFrIEYYwxR4tYglDVhThJoL7ynar6CRD1vXJqgh/BEoQxxoRqqyepFXhTRBR4RFXrvW9dRK4FrgXIzMwkPz+/WRtM8CprPttEvn97s+q3RSUlJc3+PtqyWGxXe21Teno6xcXFYcuqq6vrLWstX/va17jllls466yzauc9+OCDFBQU8Ic//KHeOvfccw9jxozhG9/4Bn/729/IyMg4Ypnf/va3pKSkhB0OvKZdr7zyCieeeCLZ2dkA3HPPPUycOJFJkya1qE2LFi1i5syZvPjiiy1aTzjl5eXH9O+srSaIiaq6XUS6A2+JyDr3iOQobvKYBZCbm6v13UbfmJQF80jt3J28vNHNjbnNqRl9MtbEYrvaa5vWrl1b73Aax2OojW9/+9u8/PLLfP3rX6+d99JLL/H73/++3m17vV6Sk5NJTU3lzTffDLtMzZhM4dZR06433ngDv9/PuHHjAPjd737XCi2CpKQkfD5fRL67hIQERo9u+j6uTV7FpKrb3dedwFyg8VsTWyjJL9bFZEw7c8kll/DKK69QUVEBQGFhIdu3b+e0007jhhtuIDc3l+HDh3PXXXeFrd+/f392794NwG9+8xuGDBnCWWedVTskODj3OIwbN45Ro0bxjW98g9LSUj744ANefvllbrvtNnJycvj888+ZMWMG//jHPwB45513GD16NCNGjODqq6+uja9///7cddddjBkzhhEjRrBu3boG2xftYcHb3BGEiCQDHlUtdt9/FfhVpLeb4rdzEMa0yGt3wJeraj8mVgfA28JdTI8RcM699RZ36dKF8ePH8/rrr3PhhRcye/ZsLrvsMkSE3/zmN3Tu3Jnq6mq+8pWvsHLlSkaOHBl2PUuWLGH27NksW7aMQCDAmDFjGDt2LAAXX3wx11xzDQA///nPefrpp7ntttu44IILOO+887jkkkuOWFd5eTkzZszgnXfeYfDgwUyfPp2//vWv3HzzzQB07dqVpUuX8tBDD3Hffffx2GOP1du+aA8LHsnLXJ8HPgSGiEiRiHxHRK4Xkevd8h4iUgTcAvzcXSYNyATeE5EVwMfAq6r6eqTirJHkF/ZbgjCm3Zk6dSqzZ88GYPbs2bXPY5gzZw5jxoxh9OjRrFmzhk8//bTedSxatIivf/3rJCUlkZaWxgUXXFBbtnr1ak4//XRGjBjBs88+2+iv/vXr1zNgwAAGDx4MwJVXXsnChYd7yC+++GIAxo4dWzvAX33ee+89pk2bBoQfFnzmzJns378fn8/HuHHjeOKJJ7j77rtZtWpVq3RRRewIQlUbfGqGqn4JZIUpOgiMikhQDUj2CZtKLEEY02x1fumXHafhvi+66CJuueUWli5dSllZGWPGjGHTpk3cd999fPLJJ3Tq1IkZM2ZQXl7e4HpEJOz8GTNm8NJLLzFq1CiefPJJ3nrrrQbXo40M/10zZHh9Q4o3tq7jOSx4mzwHEQ015yAa++MaY9qWlJQU8vLyuPrqq2uPHg4ePEhycjLp6ens2LGD1157rcF1nHHGGcydO5eysjKKi4v5z3/+U1tWXFxMz549qaqqqh2iGyA1NTXsVVrZ2dkUFhZSUFAAwDPPPMOZZ57ZrLZFe1jwNncOIlqS/VBVrZRVVZMUZ1+LMe3J1KlTufjii2u7mkaNGsXo0aMZPnw4AwcOZOLEiQ3WHzNmDJdddhk5OTn069eP008/vbbs17/+NSeffDL9+vVjxIgR7N3r3N51+eWXc8011zBz5szak9PgXCn0xBNPcOmllxIIBBg3bhzXX399s9oV7WHBJZZ+Mefm5urixc0bmePuZ97iyTWVfHDHZHplJLZyZNHRXi+dbEwstqu9tmnt2rUMHTo0bFk0nygXSe25XeH+XiKypL4RK6yLyZXsd/of7UomY4xxWIJwWYIwxpgjWYJwJbmnHSxBGHNsYqmbOpY15+9kCcJlRxDGHLuEhAT27NljSaKNU1X27NlDQkLCMdWzy3VctQnCHhpkTJNlZWVRVFTErl27jiorLy8/5h1Se9Be25WQkEBWVrhbz+pnCcKV4AOP2BGEMcfC7/czYMCAsGX5+fnHNDBcexGr7QrHuphcHhHSEv2WIIwxxmUJIkSGJQhjjKllCSJEeqLfBuwzxhiXJYgQ1sVkjDGHWYIIkZ7o56AlCGOMASxBHCHdjiCMMaaWJYgQGUl+G/LbGGNcliBCpCf6qQ4qJRUNP8TDGGM6gkg+cvRxEdkpIqvrKc8WkQ9FpEJEbq1TNkVE1otIgYjcEakY60pP9AN2s5wxxkBkjyCeBKY0UL4XuAm4L3SmiHiBB4FzgGHAVBEZFqEYj2AJwhhjDotYglDVhThJoL7ynar6CVB3bzweKFDVjapaCcwGLoxUnKHSE+MAG4/JGGOgbY7F1BvYGvK5CDi5voVF5FrgWoDMzEzy8/ObtdGSkhK2rFkOwPuLl1NZ1Ba/mmNTUlLS7O+jLYvFdlmb2o9YbVc4bXEvKGHm1XtZkarOAmaB88jR5j62MT8/n9E5J/P/PniXPgMHkze+b7PW05a018dYNiYW22Vtaj9itV3htMWrmIqAPiGfs4Dtx2PDdg7CGGMOa4sJ4hNgkIgMEJE44HLg5eOx4eQ4L16P2HhMxhhDBLuYROR5IA/oKiJFwF2AH0BVHxaRHsBiIA0IisjNwDBVPSgi3wfeALzA46q6JlJx1onZRnQ1xhhXxBKEqk5tpPxLnO6jcGXzgHmRiKsxNtyGMcY42mIXU1Sl2YB9xhgDWII4Snqin/12H4QxxliCqKtmwD5jjOnoLEHUYecgjDHGYQmijvREPwfLqwgGbchvY0zHZgmijvREP6pQbEN+G2M6OEsQdaTV3E1tJ6qNMR2cJYg6Mmy4DWOMASxBHMXGYzLGGIcliDrSkyxBGGMMWII4Ss0RxP6yyihHYowx0WUJoo6MmqfK2RGEMaaDswRRR4LfQ5zXYwnCGNPhWYKoQ0RswD5jjMESRFjpiT4bsM8Y0+FZgggjIynOupiMMR2eJYgwbMA+Y4yJYIIQkcdFZKeIrK6nXERkpogUiMhKERkTUlYoIqtEZLmILI5UjPWxBGGMMZE9gngSmNJA+TnAIHe6FvhrnfJJqpqjqrmRCa9+6Yl+G4vJGNPhRSxBqOpCYG8Di1wIPK2O/wIZItIzUvEci7REP8UVAaptyG9jTAfmi+K2ewNbQz4XufO+ABR4U0QUeERVZ9W3EhG5FucIhMzMTPLz85sVTElJSW3d3duco4fX3s4nJU6atb62ILRNsSQW22Vtaj9itV3hRDNBhNvz1vxkn6iq20WkO/CWiKxzj0iOruAkj1kAubm5mpeX16xg8vPzqam7Z0kRz61bwUljxtO/a3Kz1tcWhLYplsRiu6xN7UestiucaF7FVAT0CfmcBWwHUNWa153AXGD88Qzs8HhMdh7CGNNxRTNBvAxMd69mOgU4oKpfiEiyiKQCiEgy8FUg7JVQkWIjuhpjTAS7mETkeSAP6CoiRcBdgB9AVR8G5gFfAwqAUuAqt2omMFdEauJ7TlVfj1Sc4dhDg4wxJoIJQlWnNlKuwI1h5m8ERkUqrqawhwYZY4zdSR1WzXOpbcA+Y0xHZgkijAS/l3ifh/2l9tAgY0zHZQmiHjbchjGmo7MEUY+MJEsQxpiOzRJEPewIwhjT0VmCqEd6ot8eGmSM6dAsQdSjU1Icu0sqcK7GNcaYjscSRD2G90pjd0kl2w+URzsUY4yJCksQ9RjbrzMASzfvi3IkxhgTHZYg6pHdM5UEv4elWyxBGGM6JksQ9fB7PYzMymDplv3RDsUYY6LCEkQDxvbrxJptByivqo52KMYYc9xZgmjAmL6dCASVVdsORDsUY4w57ixBNGB03wzATlQbYzomSxAN6JoST/8uSSyxBGGM6YAsQTRiTN9OLN2y326YM8Z0OJYgGjG6Xyd2l1RQtK8s2qEYY8xxZQmiEWP7dgKwbiZjTIfTpAQhIski4nHfDxaRC0TE30idx0Vkp4isrqdcRGSmiBSIyEoRGRNSNkVE1rtldxxLg1rbkB6pJMd57YY5Y0yH09QjiIVAgoj0Bt4BrgKebKTOk8CUBsrPAQa507XAXwFExAs86JYPA6aKyLAmxtnqvB5hVJ8MSxDGmA6nqQlCVLUUuBj4s6p+HWfnXS9VXQjsbWCRC4Gn1fFfIENEegLjgQJV3aiqlcBsd9moGduvE2u/KKa0MhDNMIwx5rjyNXE5EZFTgSuA7xxj3fr0BraGfC5y54Wbf3IDgV2LcwRCZmYm+fn5zQqmpKSk3rq+AwGqg8pT/1nA0C7eZq0/GhpqU3sWi+2yNrUfsdqucJq6k78ZuBOYq6prRGQgML+F25Yw87SB+WGp6ixgFkBubq7m5eU1K5j8/Hzqq5tTWskflrxFsHM/8vJObNb6o6GhNrVnsdgua1P7EavtCqdJCUJVFwALANyT1btV9aYWbrsI6BPyOQvYDsTVMz9qMpLiOKFbMsvsPIQxpgNp6lVMz4lImogkA58C60XkthZu+2Vguns10ynAAVX9AvgEGCQiA0QkDrjcXTaq7IY5Y0xH09ST1MNU9SBwETAP6AtMa6iCiDwPfAgMEZEiEfmOiFwvIte7i8wDNgIFwKPA9wBUNQB8H3gDWAvMUdU1x9as1je2Xyf2HqqkcE9ptEMxxpjjoqnnIPzufQ8XAX9R1SoRafCntKpObaRcgRvrKZuHk0DajDH9nBvmlm7ex4CuyVGOxhhjIq+pRxCPAIVAMrBQRPoBByMVVFt0YrcUUhN8LLHzEMaYDqKpJ6lnAjNDZm0WkUmRCalt8niE0X072dDfxpgOo6knqdNF5AERWexO9+McTXQoY/pmsGFHMcXlVdEOxRhjIq6pXUyPA8XAN93pIPBEpIJqq8b170xQ4f2C3dEOxRhjIq6pCeIEVb3LHf5io6r+EhgYycDaopMHdKZ7ajz/WFIU7VCMMSbimpogykTktJoPIjIR6HAPSPB5PVw8Jov563exs7g82uEYY0xENTVBXA88KCKFIlII/AW4LmJRtWGX5mZRHVReWrYt2qEYY0xENSlBqOoKVR0FjARGqupoYHJEI2ujTuiWwpi+GcxZXGR3VRtjYtoxPVFOVQ+6d1QD3BKBeNqFS3P7ULCzhOVb90c7FGOMiZiWPHI03KirHcJ5I3uS4Pfwop2sNsbEsJYkiA7bv5Ka4Oeck3rynxXbKa+qjnY4xhgTEQ0mCBEpFpGDYaZioNdxirFNujQ3i+LyAG+s+TLaoRhjTEQ0mCBUNVVV08JMqara0ifKtWunDOhCVqdE5ize2vjCxhjTDrWki6lD83iES8Zm8cHneyjaZ0OAG2NijyWIFvjGmCxU4Z9L7J4IY0zssQTRAn06JzHhhC78Y+lWgsEOe87eGBOjLEG00KW5WWzdW8ZHm/ZGOxRjjGlVEU0QIjJFRNaLSIGI3BGmvJOIzBWRlSLysYicFFJWKCKrRGS5iCyOZJwtMWV4T1ITfPztvU3RDsUYY1pVxBKEiHiBB4FzgGHAVBEZVmexnwLLVXUkMB34U53ySaqao6q5kYqzpRLjvFx/5gm8vXYHH9tRhDEmhkTyCGI8UOAOD14JzAYurLPMMOAdAFVdB/QXkcwIxhQRV08cQGZaPL+dt9bGZzLGxAyJ1A5NRC4Bpqjqd93P04CTVfX7Icv8FkhQ1VtEZDzwgbvMEhHZBOzDuWP7EVWdVc92rgWuBcjMzBw7e/bsZsVbUlJCSkpKs+oCLCyq4vHVldyYE8+4Hm3jFpGWtqmtisV2WZvaj1hr16RJk5bU10sTyT1ZuLGa6maje4E/ichyYBWwDAi4ZRNVdbuIdAfeEpF1qrrwqBU6iWMWQG5urubl5TUr2Pz8fJpbF+D0oPLenxby6tYgP7zkDOJ80T//39I2tVWx2C5rU/sRq+0KJ5J7sSKgT8jnLGB76ALu6LBXqWoOzjmIbsAmt2y7+7oTmIvTZdVmeT3CnecMpXBPKc9/vCXa4RhjTItFMkF8AgwSkQEiEgdcDrwcuoCIZLhlAN8FFqrqQRFJFpFUd5lk4KvA6gjG2iryhnTj1IFd+NM7n1FcXhXtcIwxpkUiliBUNQB8H3gDWAvMUdU1InK9iFzvLjYUWCMi63CudvqhOz8TeE9EVgAfA6+q6uuRirW1iAh3fi2bvYcqmbVwY7TDMcaYFono2VRVnQfMqzPv4ZD3HwKDwtTbCIyKZGyRMjIrgwtG9eLRRRv59in9yExLiHZIxhjTLNE/kxqDbjt7CNVB5f4310c7FGOMaTZLEBHQp3MSV00cwJzFReSv3xntcIwxplksQUTILf8zmOweqdz64gp2FpdHOxxjjDlmliAiJMHv5c9TR1NSEeDHc1bYaK/GmHbHEkQEDcpM5a7zh7Pos908usiuajLGtC+WICLs8nF9+NqIHvz+jfWs2Lo/2uEYY0yTWYKIMBHhf78+ksy0BH7w/DK7gc4Y025YglCFnWtJKPsyYptIT/Lzp8tzKNpXys9fWm0jvhpj2gVLEIEKmJVH722vRHQzuf07c/NZg/n38u08YndZG2PagbYxLnU0+ROg7yl02rEy4pu6cdKJbNhRzL2vrSM53se0U/pFfJvGGNNcliAABpxJysZ8KNkFKd0ithmvR/jDZTmUVVbzi5dWkxzn5eIxWRHbnjHGtIR1MQEMPNN53bQg4pvyez08eMUYJpzQhdv+sZLXV0fu3IcxxrSEJQiAnjlU+ZKPS4IA5ya6R6fnMjIrnR88v5QFG3Ydl+0aY8yxsAQB4PGyP+Mk2Jh/3DaZHO/jyRnjGdQ9leueWcx/N+45bts2xpimsATh2p8xCvZvgb2bjts205P8PP2d8WR1SmL64x/zxhrrbjLGtB2WIFz7Oo103hynbqYaXVPimXPdqQzrmcYNf2AxhAwAAB20SURBVF/C3/+7+bhu3xhj6mMJwlWalAUpPWDj8U0QAJ2T43jumpM5c3A3fv7Sah54a4PdTGeMibqIJggRmSIi60WkQETuCFPeSUTmishKEflYRE5qat0IBOtczbRpIQSDEd9cXUlxPmZNz+XSsVnMfOczfjp3NYHq4x+HMcbUiFiCEBEv8CDOs6aHAVNFZFidxX4KLFfVkcB04E/HULf1DTgTSnfDzk8jvqlw/F4P/3fJSG6cdALPf7yF655ZwoFSG7vJGBMdkTyCGA8UqOpGVa0EZgMX1llmGPAOgKquA/qLSGYT67a+43g/RH1EhNvOzubXFw5nwYZdfG3mIpZu2Re1eIwxHVckE0RvYGvI5yJ3XqgVwMUAIjIe6AdkNbFu60vPgs4nROU8RF3TTu3Pi9efigh88+EPmbXwc3vokDHmuIrkUBsSZl7dPdy9wJ9EZDmwClgGBJpY19mIyLXAtQCZmZnk5+c3K9iSkhLy8/MZlDCIzI35vP/u26gn+iOR3DlGeGK1h9/OW8crH3/Gd0fGkxYX7us5Wk2bYk0stsva1H7EarvCUtWITMCpwBshn+8E7mxgeQEKgbRjrVszjR07Vptr/vz5zpvVc1XvSlPd/N9mr6u1BYNBffqDTTroZ/N0/G/e0s92HGxSvdo2xZhYbJe1qf2ItXYBi7WefWoku5g+AQaJyAARiQMuB14OXUBEMtwygO8CC1X1YFPqRsyAMwCJ6nmIukSEaaf2Z+73JlAdhKufXMzeQ5XRDssYE+MiliBUNQB8H3gDWAvMUdU1InK9iFzvLjYUWCMi63CuWPphQ3UjFesRkjpDjxFt4jxEXcN7pfPo9LHsOFjOdc8spiJQHe2QjDExLKKd7Ko6D5hXZ97DIe8/BAY1te5xM/BM+OgRqCyFuKSohFCf0X07cf83R/H955Zx5z9Xcf83RyHStHMSxhhzLOxO6nAG5EF1JWz5MNqRhHXeyF78+H8G869l23hwfkG0wzHGxChLEOH0OxU8/uM6uuux+v7kE/n66N7c9+YGXlm5PdrhGGNikCWIcOKSIWscrH/N6WZqg0SEe78xgtx+nfjxnBV8ULA72iEZY2KMJYj6nPo92FMAs6dCVVm0owkr3uflkWlj6ZmewLce+4gfPL+Mon1tM6EZY9ofSxD1GXo+XPSQczXT7CugqjzaEYXVJSWeV286nZsmn8iba77kK/cv4L431nOoIhDt0Iwx7ZwliIbkfAsu+DN8/g7MmQaBimhHFFZyvI9bvjqEd2/NY8pJPfjL/ALy7svng+2WJIwxzWcJojFjpsF5f4TP3oQ50yHQdm9Q652RyJ8uH82/vjeBrE6JzFpZwV/e/SzaYRlj2ilLEE2RexWcez9seB1enNFmz0nUGNO3Ey9edyqn9vRy35sb+P0b6+wBRMaYYxb90ejai3HfdR4k9NptMCsPLn4Ueo6MdlT18nk9XDMynn5ZXXhw/ueUVQb5xXlD7aY6Y0yT2RHEsTj5Wvj2P6FsHzw6Gd6fGZWnzzWVR4T/vXgEMyb05/H3N/Gzl1bbkOHGmCazBHGsTjwLbvgQBp8Nb/0Cnr4ADhRFO6p6iQh3nT+M7+WdwHMfbeHWF1dQVtmMMZxUoaLESY7GmA7BupiaI7kLXPZ3WPZ3eO12+OsEGH8dDMxzbrDzxTW2hsgLVuMNlEF1APH6+MmUbJLinHMS767fydTxfZl+aj96pic6y5fth90bYNd62L0edm2AA1uhohgqDjqv6h4tTX0Bhkyp3VRJRYAEnwef135vGBNLLEE0l4hzhVP/ifCfm2HRfbDw/8CfBH1PcZ5v3XssJHaCxAxISIe4FKdecwSDcGAL7P4Myg84O+zKEqg85Lwv3QslO6Bkp/NaupvTNQjv4Qwb4k/k+74Erunip6SiiqoPq/B9WM0hLyR4g3irSg5vyxsHXQZBpwFO3PGpzpSQBp/8Deb/xjmCEmF/aSXn/GkRfTol8ew1J+O3JGFMzLAE0VKdB8KVLzu/wAvfg00LnWdJvH3X0cuK19nhpvVyp97OlN4b/IlONw5Q+/C80r2wY40z7VwLlcXhY/AnQVIXSOkOGX0gaywkd+fzoh2c0C/LueqqqgwCZcRXlRPv8VJSpazbWcb6nWVUVELnHn352qQziesxFDL6gbeefxpJXeHf33Ou6BpyDne/vIYdB8v54kA5v3ttHT8/b1iLv1JjTNtgCaK1JGbA0POcCaD4S9i1zvm1X7bfeS3f7+z0i7+Eg0WwbQmU7ml4vQnpkHkS5EyFzOHQbajzzIq4ZOeIJC4ZPN6wVbfm53PCmXlhy1KAXGBIeRWPv1fIr9/ZwJP5GTx2ZRZd60sOACO/CQt+Bwt+x+uVOby0fDs/Omswew9V8Nh7mxjbrxPnjOjZ6NdljGn7LEFESmoPZ2pMVRkUfxFyl7bbBSXiJIC0Xs3vlmpKmAl+fnjWIIb0SOXmF5Zx0YPv88SMcQzKTA1fweuHM26Fl3/AvLlPM7zXBL436QRUYUXRAW77x0qG9EhlYLeUiMVsjDk+rMM42vyJTjdV96HulO1M3YY4XU/H6b6FKSf14IVrT6W8KsjFf/2A9xsaHXbk5ezxZXJ1YA73XzoSv9dDnM/Dg1eMwe8Vvvfs0uZdKWWMaVMsQZhao/pkMPd7E+iRlsCVj3/MMx8WUhk4+j6PVz/dw/1l55HjKSD70OLa+b0zEvnj5aNZv6OYn720yu7eNqadi2iCEJEpIrJeRApE5I4w5eki8h8RWSEia0TkqpCyQhFZJSLLRWRx3bomMvp0TuIfN0zglIFd+MW/1zDh3nf5v9fXsXWvM4z47pIKfvHv1azrcT6a1ss5HxGSCM4c3I2bJg/iX0u38fzHW6PVDGNMK4jYOQgR8QIPAv8DFAGfiMjLqvppyGI3Ap+q6vki0g1YLyLPqmrNiHiTVNWehHOcpSf6eerq8SzYsJPnPtrCwws+568LPueMQd2oqg5SUh7g3m+egmy+Bebd6ly1NTCvtv5NXxnE0i37+NlLq1iz/QA/OTub9CR/1NpjjGmeSJ6kHg8UqOpGABGZDVwIhCYIBVLFGSAoBdgL2BjVbYDXI0zOzmRydibb95cx+5OtvPDJFnYcrOD2KdkMzkyFztNg0f2w4P+OSBBej/Dwt8dy/5sbePKDTbyx5kt+du5QLsrpbWNBAQSrobrKee55MADVlcSX74J9hU5ZsBq0GnzxkNEfPNYTbKJDItVPLCKXAFNU9bvu52nAyar6/ZBlUoGXgWwgFbhMVV91yzYB+3CSyCOqOque7VwLXAuQmZk5dvbs2c2Kt6SkhJSU2LryprXbVB1UikqC9E311O7oexf9h0EFj7F6+O3s6TIe9Rz5m2PzwWqeWlPJxgNBhnb2MG1YPL1SWrbDO+5/K1VEA3iCVbWvR0/l+AKl+AKH8AVK8VaX4guUEFd5AH/VQfd1P/6qYjza9N9AVb4UDqYN5mDaEHcaTLUvOYKNbT2x+H8KYq9dkyZNWqKqueHKIpkgLgXOrpMgxqvqD0KWuQSYCNwCnAC8BYxS1YMi0ktVt4tId3f+D1R1YUPbzM3N1cWLm3e6Ij8/n7y8vGbVbauOS5uqyuDPY+HgNvDGO/dq9BzlTF0HQ3wqQX8yc9fs4/fzi9hX5eP8nD5cPXEAw3qlHdu2gtVQVcZ7C+dz2qknO7/Aq6ucKVDmPD+86pD7WgqBcvfXePDwFKyGYJXzXI/qSqiucOrXjDNVvt95LdvvDDESqHCWb464FEjuCsndnBsMk7s6NzT6k5zLhb1+5651j491BRvJzh4GHp9zX4vH69whX7QYij5xbpSsuYEyPt257yaps3unfidnW944d6pZd7xzFOJLOPLVn+i89ye67xPd8vjD9bxx9d8s2USx+H8KYq9dIlJvgohkF1MR0Cfkcxawvc4yVwH3qpOlCtyjhmzgY1XdDqCqO0VkLk6XVYMJwkSBPxGuXeCch/hiOXyxAtb8C5Y8UbuIB/iGO+EH1kD1aiEgHjweD+LxIuJ1dkged+fm8TuX+AbKD98J7u6oTwN4vxViF+/hnWJcirOjTchwLjtOzID4NLc87sipZmfqiz+8E45LdockSXOGJIlLPaYd7JeH8skenXd0wZjpzmv5Adi2FLYvdYZTKdvn3HRZts/pmqosDUmYbvKjhT/+xOO22f2Oar4rj8+ZxHs4mYnHvVhBa1/HFpfAhnR3mZDlQxJj7Xfq8YSE20jcNevzuP9earYfsu3aCydqfhRo0Om20yAgbp2Q2EWOuNjCqauHYwlZ74nbiqB0Xj3fmTjrr+lKDQacv0mwCqoDzmtjP8rDdcPWV6dm2YR0OO8PDa+3GSKZID4BBonIAGAbcDnwrTrLbAG+AiwSkUxgCLBRRJIBj6oWu++/CvwqgrGalkjpBiMucSZw/jHv3wJ7NzpjRVUecsaNqiqFykOUV1axZtt+Vhft41BFFZ0SPZzUM4UTuySQ6A26/6ECzn9mX4Lzi9uf4PzS9Sfw2aYtDBoy1N2xuAnFlwBxSeBPdl+TnHk1OwLxODuh2p1eXL13oLdJCelwwiRnagpV5zsMVLhT+eGpqtw54jritdw5mqo9sqp06tUmHfd9wD1votWHz5fU/K2O2DkKlRV7ICnj8DmVYLWzncqSOsks4Kyjpj7Uf/+Pqruumh1v9eF4QrZd++rxOu9r/g3UJJKamFQPJ5Cw25c67yEzUA17wu061c0nIQmqJiF6/Id/AElDXawhiUC1zvdQ9zsJWTaxcwPrbL6IJQhVDYjI94E3AC/wuKquEZHr3fKHgV8DT4rIKpzW366qu0VkIDDX7ef2Ac+p6uuRitW0MhHo1M+ZwkgAxgKjqoO8vuZLHn9vE3du2I/PI5w1NJNvjsvijEHd6h0ddltVPoPG5UUs/JggcrirKT46/eWrYqwrpsb7MdqucCI61IaqzgPm1Zn3cMj77ThHB3XrbQRGRTI2E30+r4fzRvbivJG92LCjmBcXb+VfS7fx+povyUyL5+ujszh/VE+G9Uyzq5+MiQIbi8m0CYMzU/nZucO47exs5q/fyZxPtvLooo08vOBzBnRN5twRPTl3ZE+ye9QzRpQxptVZgjBtSpzPw9nDe3D28B7sPVTJG2u+5NWVX/BQfgF/mV/AwG7JZKdUktRvL2P6ZthDioyJIEsQps3qnBzH1PF9mTq+L7tLKnhjzZfMW/UFb3x+iHmPfEh6op8zBndjcnY3Jg/JtLu1jWllliBMu9A1JZ4rTu7HFSf347W350NmNu+u28n89Tv5z4rtxHk9TMruxtdHZzEpuxvxvnZ0hZIxbZQlCNPuJPqEvBE9OWdET4JBZeW2A/xnxXb+vXw7b6zZQXqin3NH9uT8kb0Y3TeDBL8lC2OawxKEadc8HiGnTwY5fTK485xs3ivYzdxl2/jX0iKe+2gLcV4PJ/VOI7d/Z8b268TYfp3omhIf7bCNaRcsQZiY4fN6yBvSnbwh3SmpCPBBwW6WbN7H4s37ePL9QmYt3AjA8F5pfCW7O5OHZjKydzoej11Ca0w4liBMTEqJ9/HV4T346nDnsa/lVdWs3naAjzbtJX/9Tv4yv4CZ7xbQNSWeydndmHhiV0ZlZdCvS5Ldc2GMyxKE6RAS/F5y+3cmt39nbpx0IvsOVbJgwy7eXruD11Z/yZzFRQBkJPkZmZVBTlY6o/t24uSBnUmKs/8mpmOyf/mmQ+qUHMdFo3tz0ejeBKqDbNhRwoqi/azYup8VRQf4y/wCggpxXg/jB3Qmb0g3zhzcjRO7p9gRhukwLEGYDs/n9TCsVxrDeqUxdXxfAEorAyzdvJ8FG3aSv34X97y6lnteXUvvjERGZqUzODOVIT1SGZyZSv8uSXbDnolJliCMCSMpzsdpg7py2qCu/Oxc2La/jAXrd/FewS7WfVHMG2u+JOgOphnn9ZDdM7X2Kqncfp3pkZ4Q3QYY0wosQRjTBL0zEvnWyX351snOEUZ5VTUFO0vYsKOY9V8Ws3zrfp7/eAtPvF9Yu3xO3wxO6JpMvy7J9O+aRL8uyXRJjrMuKoOqcqiymoNlVRSXBygur6KkIkBpZTUlFQEOue+rqoMEqpWqoPtaHaSkIsCB0ioOlB2ekuK85N/WxKHgj4ElCGOaIcHv5aTe6ZzUO712XlV1kE+3H2Tx5n0s2byXlUX7eW3VF7VHGgCp8T5G9kknt19nxvXvTE7fDFLi7b9hW1YddHbMldVBKgNBvigJsrhwL3sOVbLXnYrLA1QHg1RVK4FgkOqgUhlQDlUEOFTp7PAPVTg7/5IKJyEEG3luUA2vR/B5BL/Xg88rJMf5SE/0k5Hk58TuKaQn+umeGpl7e+xfpjGtxO/1MKpPBqP6ZPCd0wYAUBkIUrSvlM17Sincc4jPd5WwbMt+/vzuZwTV+c8/tGcqnaWC1cHP6NM5iaxOSfTplEi31Hg72miBYFApq6p2d9LOa0lFgP2llc7OvcR53XOokgNlVe5O3Nmhl1ZUc6gyQFW1Uh1uT/7eh0d8jHN33j6P4PN6anfoSXFekuN9pMT76JYaT3K8j9R4H2mJflITfKQm+ElL8JOS4CMl3lk2Oc5ZPinei9/jiep9OpYgjImgOJ+Hgd1SGNjtyIf2FJdXsWzLfhYX7uWTwn0sL6pmYdGGI5bplOTnxkknMv3U/sT5Yv8keDCoVASClFdV1746v76rD++0KwLsc3fwu4sr2H2okj0lFRSXB6gMHP6VX/O+MakJProkx5GeFEdKvJfOyUnOzjnOS1Kcl3ifF7/Xg98nxHk9+L0ethUWMDF3FF2S4+jsTrE6nIslCGOiIDXBGYn2jMHdAMjPz+fkCaezbX8pW/eWsXVfKW99uoN7Xl3LM//dzB1TsplyUo82fURRGQhysNzpEz9YVsWqXQFKVm6npNz55X7Q7Ws/UFbF/tIq9pdWOq9lVZSUB5q0Q68R7/PQNSWerilxZKYlcGJ3H/E+D3E+Zyce5/MQ7/OS7P6CT473khznIzneR0aSny7J8XRK9jdrUMf8ykLOdP9usS6iCUJEpgB/wnnk6GOqem+d8nTg70BfN5b7VPWJptQ1JtYkxnk5sXsqJ3Z3Hoo07ZR+5G/YxW9fXcsNzy5lXP9O/PzcYYzqk9HibVVVBzlUEaC43OlSOVBaxT53p73X3XEfLKuistrtV3dfq6qdX/blVdWU1UyVQUoqqiivCrODX7LsiI8p8Yf7zzOS/PTMSCQj0eliSfB5SfB7SfA7O/cEv4ekkO6W5Djnl32n5DiS47xtOlnGioglCBHxAg8C/wMUAZ+IyMuq+mnIYjcCn6rq+SLSDVgvIs8C1U2oa0xMExEmDenO6Sd25YXFW/nDWxu48MH38Xpqujuk9hez1yN4RPAIeERqn3UfVCcZVAeVQNDZ0ZdWOl04DUnwe0hL8Neuv6ZP3e8V4v3OTrqX30ui30tCnPNLPT3RT3qin7REp1+9YO0qzpwwnpR4H6kJTt+6jXvVvkTyCGI8UOA+XxoRmQ1cCITu5BVIFeenQAqwFwgAJzehrjEdgs/r4YqT+3HBqF68uLiIPYcqqKpWKgNB5+qagJMAFAiqElTnFT18BYzXI/i8zmvNSdDkeB8pCc5J09QEP52S/XRKiqNTUhyJcS3vU5cvvQzOtEfEtmeRTBC9ga0hn4twdvyh/gK8DGwHUoHLVDUoIk2pC4CIXAtcC5CZmUl+fn6zgi0pKWl23bYqFtsEsdmuprZpIDCwta5oDAAlzhQAdrlTa4nFvxPEbrvCiWSCCHcsWfd6sbOB5cBk4ATgLRFZ1MS6zkzVWcAsgNzcXM3Ly2tWsPn5+TS3blsVi22C2GyXtan9iNV2hRPJa+eKgD4hn7NwjhRCXQX8Sx0FwCYgu4l1jTHGRFAkE8QnwCARGSAiccDlON1JobYAXwEQkUxgCLCxiXWNMcZEUMS6mFQ1ICLfB97AuVT1cVVdIyLXu+UPA78GnhSRVTjdSrer6m6AcHUjFasxxpijRfQ+CFWdB8yrM+/hkPfbga82ta4xxpjjJ/bv3zfGGNMsliCMMcaEZQnCGGNMWKLaxEHJ2wER2QVsbmb1rsDuVgynLYjFNkFstsva1H7EWrv6qWrY0QdjKkG0hIgsVtXcaMfRmmKxTRCb7bI2tR+x2q5wrIvJGGNMWJYgjDHGhGUJ4rBZ0Q4gAmKxTRCb7bI2tR+x2q6j2DkIY4wxYdkRhDHGmLAsQRhjjAmrwycIEZkiIutFpEBE7oh2PM0lIo+LyE4RWR0yr7OIvCUin7mvnaIZ47ESkT4iMl9E1orIGhH5oTu/3bZLRBJE5GMRWeG26Zfu/Hbbphoi4hWRZSLyivs5FtpUKCKrRGS5iCx257X7djVVh04QIc/NPgcYBkwVkWHRjarZngSm1Jl3B/COqg4C3nE/tycB4MeqOhQ4BbjR/fu053ZVAJNVdRSQA0wRkVNo322q8UNgbcjnWGgTwCRVzQm59yFW2tWoDp0gCHlutqpWAjXPvm53VHUhzjO9Q10IPOW+fwq46LgG1UKq+oWqLnXfF+PsfHrTjtvlPhyrxP3odyelHbcJQESygHOBx0Jmt+s2NSBW23WUjp4gwj37uneUYomETFX9ApydLdA9yvE0m4j0B0YDH9HO2+V2xSwHdgJvqWq7bxPwR+AnQDBkXntvEzjJ+00RWSIi17rzYqFdTRLR50G0A01+9rWJHhFJAf4J3KyqB0XC/dnaD1WtBnJEJAOYKyInRTumlhCR84CdqrpERPKiHU8rm6iq20WkO/CWiKyLdkDHU0c/goj1Z1/vEJGeAO7rzijHc8xExI+THJ5V1X+5s9t9uwBUdT+Qj3PuqD23aSJwgYgU4nTTThaRv9O+2wTUPtQMVd0JzMXplm737Wqqjp4gYv3Z1y8DV7rvrwT+HcVYjpk4hwp/A9aq6gMhRe22XSLSzT1yQEQSgbOAdbTjNqnqnaqapar9cf4Pvauq36YdtwlARJJFJLXmPc7TL1fTztt1LDr8ndQi8jWc/tOaZ1//JsohNYuIPA/k4QxFvAO4C3gJmAP0BbYAl6pq3RPZbZaInAYsAlZxuG/7pzjnIdplu0RkJM6JTS/OD7Q5qvorEelCO21TKLeL6VZVPa+9t0lEBuIcNYDTHf+cqv6mvbfrWHT4BGGMMSa8jt7FZIwxph6WIIwxxoRlCcIYY0xYliCMMcaEZQnCGGNMWJYgTIchIioi94d8vlVE7m6F9caLyNvuiJ+XtXR9x7jtQhHpejy3aToOSxCmI6kALo7ADnU04HdH/HyhlddtTNRYgjAdSQDnecI/qlsgIv1E5B0RWem+9g2zTGcRecld5r8iMtIdo+fvOGMrLReRE+rUOUFEXncHe1skItnu/CdF5GF33gZ3PKOa50U84T6DYJmITHLne0XkPnf+ShH5QchmfiAiS92ymvWf6caz3F1Pait9h6YDsQRhOpoHgStEJL3O/L8AT6vqSOBZYGaYur8ElrnL/NRdfifwXWCRewTxeZ06s4AfqOpY4FbgoZCy/sCZOMNkPywiCcCNAKo6ApgKPOXOvxYYAIwOibHGblUdA/zV3Qbu642qmgOcDpQ1/tUYcyRLEKZDUdWDwNPATXWKTgWec98/A5wWpvppbhmq+i7QJUyiqeWOQjsBeNEd3vsRoGfIInNUNaiqnwEbgew621gHbAYG44zZ9LCqBtyy0KEdagYxXIKTdADeBx4QkZuAjJp6xhwLSxCmI/oj8B0guYFlwo1Bc6zDw3uA/e6RRc00tIG6Ws82arZd37Yq3Ndq3CH8VfVenCObROC/NV1PxhwLSxCmw3F/fc/BSRI1PsAZiRTgCuC9MFUXumU1g9Ltdo9I6tvOQWCTiFzq1hERGRWyyKUi4nHPWwwE1tfZxmCcAeHWA28C14uIzy3r3FAbReQEVV2lqr8DFuMcnRhzTCxBmI7qfpyRb2vcBFwlIiuBaTjPV67rbiDXXeZeDg/53JArgO+IyApgDUc+0nY9sAB4DbheVctxzlF4RWQV8AIwQ1UrcB7luQVY6a7rW41s92YRWe0uW+Zuw5hjYqO5GhMFIvIk8Iqq/iPasRhTHzuCMMYYE5YdQRhjjAnLjiCMMcaEZQnCGGNMWJYgjDHGhGUJwhhjTFiWIIwxxoT1/wGTDFOA6QAWGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss,label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('No of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Vs No of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvvc3q93L7In"
   },
   "outputs": [],
   "source": [
    "#Generate 1000 random samples from train and val data\n",
    "#Train data\n",
    "train_index = []\n",
    "for i in range(X_train_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_train_padded_docs[i]!=0)>14:\n",
    "        train_index.append(i)\n",
    "train_index = random.sample(train_index,1000)\n",
    "\n",
    "#Validation data\n",
    "#Train data\n",
    "val_index = []\n",
    "for i in range(X_val_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_val_padded_docs[i]!=0)>14:\n",
    "        val_index.append(i)\n",
    "val_index = random.sample(val_index,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "71f3488b8aa84ddc99185c9da46d6bf7",
      "f3069b67e0ce47e4a5a1dd90d7576239",
      "8a9ee09cf1f0497fbf160f641045ca96",
      "265b920a4cb74bcab6b5ed5412967016",
      "aee3ff0a9fd042f786f138df9b26264e",
      "42d34c6298e744d084d2ae9cf5440528",
      "e4efcc22f53b47ee8038532e176563ed",
      "d3783f14ab52470fb674de28734f2505"
     ]
    },
    "colab_type": "code",
    "id": "muqMywldL7Iq",
    "outputId": "9ad3c27b-1be7-4458-9775-64180223fda4",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f3488b8aa84ddc99185c9da46d6bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> with the things that happened a couple of weeks ago our travel has <end> \n",
      "Actual words: <start> been put off for a while <end> \n",
      "Predicted words: <start> been very helpful <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the tickets are at my house but you are free to stop by and pick them up at your <end> \n",
      "Actual words: <start> convenience <end> \n",
      "Predicted words: <start> convenience <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> of course we are trying to avoid any commercial risks associated with marketing <end> \n",
      "Actual words: <start> this power <end> \n",
      "Predicted words: <start> and services <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> make sure it is sent as soon as you read it or your wish will not <end> \n",
      "Actual words: <start> come true <end> \n",
      "Predicted words: <start> be able to attend <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> please review the agreement and give any one of us a call here in credit if you have any <end> \n",
      "Actual words: <start> questions <end> \n",
      "Predicted words: <start> questions <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the company will use the funding for international expansion and to further develop its <end> \n",
      "Actual words: <start> business and information technology operations <end> \n",
      "Predicted words: <start> technology and marketing <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> please see me or send me an email if you are interested and we will make <end> \n",
      "Actual words: <start> scheduling arrangements <end> \n",
      "Predicted words: <start> it <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> you can always check the web site to see if there are other <end> \n",
      "Actual words: <start> areas you may be interested in <end> \n",
      "Predicted words: <start> things <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> everyone should have access to this and if you do not know how <end> \n",
      "Actual words: <start> to load these files let me know <end> \n",
      "Predicted words: <start> we can do it <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> if you need me to do anything else in order for this to happen let <end> \n",
      "Actual words: <start> me know <end> \n",
      "Predicted words: <start> me know <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For train data, actual and predicted words\n",
    "train_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_train_padded_docs[train_index,:],y_train_padded_docs[train_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    train_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "fd37cc5d5d1e487e89d4e824c03756ae",
      "487a4bfe9ebc4e4497e156ed2377656f",
      "8b25a98f83664b5b9ff072334597c5cc",
      "3a16837624894c68bb214685f9a66bc4",
      "a60bc83bc60244b095e0b3f96412c342",
      "e6dbe328a0eb4ff8b633a9ef3ba6363f",
      "239cfdfc526d4060b2b80bafaa8d8116",
      "08b2a31dbbbe41e1961e6e377881ae18"
     ]
    },
    "colab_type": "code",
    "id": "o2B9_PCSL7Is",
    "outputId": "4fcb930a-f814-4485-8851-f267515d2ec4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd37cc5d5d1e487e89d4e824c03756ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> we are going to have to push back the meeting to review the model if that <end> \n",
      "Actual words: <start> ok <end> \n",
      "Predicted words: <start> is what you want to do <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> and they pay me to worry about things that can go wrong in <end> \n",
      "Actual words: <start> construction <end> \n",
      "Predicted words: <start> the system <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> please feel free to send this information to other friends and family who <end> \n",
      "Actual words: <start> may be interested <end> \n",
      "Predicted words: <start> might be interested in the group <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> you know we begin to believe that there is something we can do to <end> \n",
      "Actual words: <start> stay safe <end> \n",
      "Predicted words: <start> do <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> i am going to get more details on these separate requests but wanted your <end> \n",
      "Actual words: <start> initial interest level <end> \n",
      "Predicted words: <start> input <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> we are requested to send the letter right away so would appreciate your prompt <end> \n",
      "Actual words: <start> response <end> \n",
      "Predicted words: <start> response <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> we know you are busy we appreciate the consideration and above all we wish you well in the weeks <end> \n",
      "Actual words: <start> ahead <end> \n",
      "Predicted words: <start> of the meeting <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> please give me a call when you get this so we can pick a time to discuss <end> \n",
      "Actual words: <start> the project further <end> \n",
      "Predicted words: <start> this <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> i thank you in advance and hope that we can pull something together in the next few <end> \n",
      "Actual words: <start> weeks <end> \n",
      "Predicted words: <start> days <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> thank you again for your assistance with these issues and we look forward to receiving your <end> \n",
      "Actual words: <start> letter <end> \n",
      "Predicted words: <start> comments <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For validation data actual and predicted words\n",
    "val_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_val_padded_docs[val_index,:],y_val_padded_docs[val_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    val_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "EvU7rH7IL7Iy",
    "outputId": "98d57f68-9d78-4476-f582-2891844c671d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for train data of 1000 samples: 0.715\n",
      "BLEU Score for validation data of 1000 samples: 0.699\n"
     ]
    }
   ],
   "source": [
    "#Average BLEU Score for sentences\n",
    "print('BLEU Score for train data of 1000 samples:',np.round(sum(train_bleu_list)/len(train_bleu_list),3))\n",
    "print('BLEU Score for validation data of 1000 samples:',np.round(sum(val_bleu_list)/len(val_bleu_list),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xqdMoy5cuFl"
   },
   "source": [
    "<h1>4. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgjJobuUcuFl"
   },
   "outputs": [],
   "source": [
    "def predict_sentence(enc_dec_model,input_sentence):\n",
    "    \n",
    "    #Maximum sequence length for input and target sentence\n",
    "    input_max_length = X_train_padded_docs.shape[1]\n",
    "    output_max_length = y_train_padded_docs.shape[1]\n",
    "\n",
    "    input_sentence = '<start> ' + input_sentence + ' <end>'\n",
    "    \n",
    "    #Convert texts to sequences\n",
    "    sent = inp_tokenizer.texts_to_sequences([input_sentence])\n",
    "    #Pad data\n",
    "    sent = tf.keras.preprocessing.sequence.pad_sequences(sent,maxlen=input_max_length,padding='post')\n",
    "    \n",
    "    #print('Encoder input shape (batch_size,sequence length):',sent.shape)\n",
    "    enc_hidden,enc_cell = enc_dec_model.layers[0](sent)\n",
    "    #print('Encoder hidden state shape (batch_size,units):',enc_hidden.shape)\n",
    "    #print('Encoder cell state shape (batch_size,units):',enc_cell.shape)\n",
    "    #print(90*'-')\n",
    "    \n",
    "    #Boundary case\n",
    "    dec_input = tf.expand_dims([out_tokenizer.word_index['<start>']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    #print('Decoder input shape (batch_size,1):',dec_input.shape)\n",
    "    #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "    #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    output_sent = ''\n",
    "    \n",
    "    for i in range(output_max_length-1):\n",
    "        #Get prediction from onestep_decoder\n",
    "        dec_output,dec_hidden,dec_cell = enc_dec_model.layers[1](dec_input,dec_hidden,dec_cell)\n",
    "        #print('Decoder output shape (batch_size,vocab_size):',dec_output.shape)\n",
    "        #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "        #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    \n",
    "        #Get prediction from dense layer\n",
    "        #Shape == (batch_size,timestep,vocab_size) == (1,1,vocab_size)\n",
    "        outputs = enc_dec_model.layers[3](dec_output)\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = np.argmax(outputs.numpy().reshape(-1))\n",
    "        \n",
    "        #Get word corresponding to index\n",
    "        output_sent+=out_tokenizer.index_word[key]+' '\n",
    "        \n",
    "        if out_tokenizer.index_word[key] == '<end>':\n",
    "            return output_sent\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    return output_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tbVttk15Wx-m",
    "outputId": "fc21860b-32da-479c-c7c6-438f6f4fafa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the way <end> '"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'where is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fi7OT3XCWx-t",
    "outputId": "f1fd62e7-b597-4d50-8e63-3370b490c68b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best way to get together <end> '"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'when will the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dysFablEWx-w",
    "outputId": "8aff8c8a-ad55-40c5-c6ec-06345002c070"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good weekend <end> '"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'have a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DIgD44y6Wx-0",
    "outputId": "54839c5c-b50b-48e6-bce3-6a59f96ccb0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new date is the same <end> '"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'ensure the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jbug0uI7Wx-3",
    "outputId": "49124f98-4c50-4041-b48a-30a711227558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you for your time and consideration <end> '"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(model,'thank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>Encoder Decoder Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "9xrQi-N9MPy0",
    "outputId": "f5be2b06-4aa5-46a0-b341-2d675bb56734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-09 09:33:35--  https://doc-0o-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/pb164rsi80irjfu5iub508823718ee9q/1591695150000/02963250765125473783/02963250765125473783/1ZQRWKkDbx1agHPIzaX-3L9UgfpPBboQi?e=download&authuser=1&nonce=tc3g03pp0suqo&user=02963250765125473783&hash=a8ftsob7vg8c9oues2uo1rm6ap6i7g77\n",
      "Resolving doc-0o-ak-docs.googleusercontent.com (doc-0o-ak-docs.googleusercontent.com)... 74.125.203.132, 2404:6800:4008:c03::84\n",
      "Connecting to doc-0o-ak-docs.googleusercontent.com (doc-0o-ak-docs.googleusercontent.com)|74.125.203.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘encoded_data’\n",
      "\n",
      "\r",
      "encoded_data            [<=>                 ]       0  --.-KB/s               \r",
      "encoded_data            [ <=>                ]   7.08M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-06-09 09:33:36 (55.0 MB/s) - ‘encoded_data’ saved [7426606]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-0o-ak-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://drive.google.com/drive/u/1/folders/1Nz-Vq0RhziotMAesPgnisN_Ti9HNQ51f\" --header=\"Cookie: AUTH_hsr61oqao0sqa2rdskku1n6gcr67pomr_nonce=tc3g03pp0suqo; _ga=GA1.2.1509677474.1591248567\" --header=\"Connection: keep-alive\" \"https://doc-0o-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/pb164rsi80irjfu5iub508823718ee9q/1591695150000/02963250765125473783/02963250765125473783/1ZQRWKkDbx1agHPIzaX-3L9UgfpPBboQi?e=download&authuser=1&nonce=tc3g03pp0suqo&user=02963250765125473783&hash=a8ftsob7vg8c9oues2uo1rm6ap6i7g77\" -c -O 'encoded_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5JLhjfZ0XEz"
   },
   "source": [
    "<h1>1. Read Featurized data</h1> \n",
    "<h2>(Refer Word Featurization Section 3 of 2_Data_Preparation.ipynb)</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnTFvgjaWx8o"
   },
   "outputs": [],
   "source": [
    "[X_train_padded_docs,y_train_padded_docs,X_val_padded_docs,y_val_padded_docs,inp_embedding_matrix,\n",
    "                             out_embedding_matrix,inp_tokenizer,out_tokenizer] = joblib.load('encoded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gi9gVXkcuCy"
   },
   "source": [
    "<h1>2. Define Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icMEwKexcuC2"
   },
   "source": [
    "<h2>2.1. Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgtZmDqYcuC6"
   },
   "outputs": [],
   "source": [
    "#Encoder class\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,enc_units,**kwargs):\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim,weights=[embedding_matrix],\n",
    "                                   mask_zero=True,name='Encoder_Embedding_layer',trainable=False)\n",
    "        self.lstm = LSTM(self.enc_units,return_sequences=True,return_state=True,name='Encoder_LSTM')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        #state_h = Hidden state output of last time step (Output of last time step)\n",
    "        #state_c = Cell state output of last time step\n",
    "        lstm_out, state_h, state_c = self.lstm(x)\n",
    "        return lstm_out, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uc064MCCcuC_",
    "outputId": "4855ec73-7784-4c67-83bf-65916f291e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data Vocab size: 1470\n"
     ]
    }
   ],
   "source": [
    "input_vocab_size = len(inp_tokenizer.word_index) + 1\n",
    "print('Input data Vocab size:',input_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "P_xpJvvccuDE",
    "outputId": "aeebd4ea-372f-44cb-99b7-01b529fc837d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch input data (batch_size,sequence length): (32, 23)\n",
      "Shape of batch output data (batch_size,sequence length): (32, 23)\n",
      "Shape of encoder output (batch_size,sequence length,units): (32, 23, 256)\n",
      "Shape of hidden state output of last time step (batch_size,units): (32, 256)\n",
      "Shape of memory state output of last time step (batch_size,units): (32, 256)\n"
     ]
    }
   ],
   "source": [
    "#Create encoder object\n",
    "BATCH_SIZE = 32\n",
    "encoder = Encoder(vocab_size=input_vocab_size,embedding_dim=300,embedding_matrix=inp_embedding_matrix,\n",
    "                  enc_units=256,name='Encoder')\n",
    "\n",
    "#Get data from data generator\n",
    "example_input_batch, example_target_batch = X_train_padded_docs[:BATCH_SIZE], y_train_padded_docs[:BATCH_SIZE]\n",
    "print('Shape of batch input data (batch_size,sequence length):',example_input_batch.shape)\n",
    "print('Shape of batch output data (batch_size,sequence length):',example_target_batch.shape)\n",
    "\n",
    "#Genearte sample ouptput and hidden state from encoder object\n",
    "sample_output, sample_hidden_output, sample_cell_output = encoder(example_input_batch)\n",
    "print('Shape of encoder output (batch_size,sequence length,units):',sample_output.shape)\n",
    "print('Shape of hidden state output of last time step (batch_size,units):',sample_hidden_output.shape)\n",
    "print('Shape of memory state output of last time step (batch_size,units):',sample_cell_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGFLsbQOcuDJ"
   },
   "source": [
    "<h2>2.2. Attention layer</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rp9SoJz2cuDK"
   },
   "source": [
    "For a particular time step of Decoder, the attention layer takes the output from the encoder (output at all time steps) and decoder output (hidden state output of decoder) at previous time step and computes the context vector. The context vector concatenated with the decoder output of previous time step is given as an input to the decoder for the current time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMN95hW8w8Kv"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.units = units\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "        \n",
    "    def call(self, hs, ht):\n",
    "        #hs = Encoder output at all time steps\n",
    "        #ht = Decoder output at last time step (Hidden state output of decoder at last time step)\n",
    "        #Add time axis to ht, this is done to perform broadcast addition along time axis to calculate score\n",
    "        #hs shape == (batch size,max_length,hidden size)\n",
    "        #ht shape == (batch size,hidden size)\n",
    "        #ht_with_time_axis shape == (batch size,1,hidden size)\n",
    "        ht_with_time_axis = tf.expand_dims(ht, axis=1)\n",
    "        \n",
    "        #score shape == (batch size, max_length, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(ht_with_time_axis) + self.W2(hs)))\n",
    "        \n",
    "        #Softmaxing the scores to get attention weights (alpha's)\n",
    "        #attention_weights shape == (batch size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        #Get context vector\n",
    "        #context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * hs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "uw8EUNgXw8Kz",
    "outputId": "f821caa8-cb21-4990-f811-a9fc35d76fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of context vector (batch_size,units): (32, 256)\n",
      "Shape of attention weights (batch_size,sequence length,1): (32, 23, 1)\n"
     ]
    }
   ],
   "source": [
    "#Initalise Attention\n",
    "attention_layer = BahdanauAttention(units=128)\n",
    "sample_context_vector, sample_attention_weights = attention_layer(sample_output,sample_hidden_output)\n",
    "print('Shape of context vector (batch_size,units):',sample_context_vector.shape)\n",
    "print('Shape of attention weights (batch_size,sequence length,1):',sample_attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWTi0DbhcuDf"
   },
   "source": [
    "<h2>2.3. Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOymahJ7cuDg"
   },
   "source": [
    "<h3>2.3.1. One Step Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxVxxpnbcuDg"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,dec_units,att_units):\n",
    "        super(OneStepDecoder, self).__init__()\n",
    "        self.attention = BahdanauAttention(units=att_units)\n",
    "        self.embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim,weights=[embedding_matrix],mask_zero=True,\n",
    "                                   name='Decoder_Embedding_layer',trainable=False)\n",
    "        self.lstm = LSTM(dec_units,return_sequences=False,return_state=True,name='Decoder_LSTM',dropout=0.33)\n",
    "        self.fc = Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x, hidden, cell, enc_output):\n",
    "        #enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(enc_output,hidden)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the LSTM\n",
    "        output, state_h, state_c = self.lstm(x,initial_state=[hidden,cell])\n",
    "        \n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state_h, state_c, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0Qhm_VdocuDr",
    "outputId": "7a71aa27-6b10-425b-86b0-dfcfa640e13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data Vocab size: 1469\n"
     ]
    }
   ],
   "source": [
    "output_vocab_size = len(out_tokenizer.word_index) + 1\n",
    "print('Output data Vocab size:',output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "b9pinu5acuDv",
    "outputId": "3e214f80-d704-4ac7-e2c6-da2cfc33d04e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Step Decoder with Attention:\n",
      "Shape of decoder output (batch_size,vocab_size): (32, 1469)\n",
      "Shape of decoder hidden state output (batch_size,units): (32, 256)\n",
      "Shape of decoder memory state output (batch_size,units): (32, 256)\n",
      "Shape of attention weights (batch_size,sequence length,1): (32, 23, 1)\n"
     ]
    }
   ],
   "source": [
    "#Initialise one step decoder with attention\n",
    "BATCH_SIZE = 32\n",
    "osd = OneStepDecoder(vocab_size=output_vocab_size,embedding_dim=300,embedding_matrix=out_embedding_matrix,\n",
    "                     dec_units=256,att_units=128)\n",
    "\n",
    "#Input to decoder for first time step\n",
    "dec_input = tf.expand_dims([out_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "#Geneate sample output, hidden states and attention weights from decoder object\n",
    "sample_output_dec,sample_hidden_output_dec,sample_cell_output_dec,sample_attention_weights = osd(dec_input,\n",
    "                                                                                                 sample_hidden_output, \n",
    "                                                                                                 sample_cell_output,\n",
    "                                                                                                 sample_output)\n",
    "print('One Step Decoder with Attention:')\n",
    "print('Shape of decoder output (batch_size,vocab_size):',sample_output_dec.shape)\n",
    "print('Shape of decoder hidden state output (batch_size,units):',sample_hidden_output_dec.shape)\n",
    "print('Shape of decoder memory state output (batch_size,units):',sample_cell_output_dec.shape)\n",
    "print('Shape of attention weights (batch_size,sequence length,1):',sample_attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZxADS2EcuD8"
   },
   "source": [
    "<h3>2.3.2. Decoder for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiG649pXcuD9"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix,dec_units,att_units,**kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.att_units = att_units\n",
    "        self.onestep_decoder = OneStepDecoder(vocab_size=self.vocab_size,embedding_dim=self.embedding_dim,\n",
    "                                              embedding_matrix=embedding_matrix,\n",
    "                                              dec_units=self.dec_units,\n",
    "                                              att_units=self.att_units)\n",
    "        \n",
    "    #@tf.function\n",
    "    def call(self,decoder_input,decoder_hidden_state,decoder_cell_state,encoder_outputs):\n",
    "        \n",
    "        #Decoder must output words after <start> token hence sequence length is reduced by 1\n",
    "        all_outputs = tf.TensorArray(tf.float32,size=decoder_input.shape[1]-1,name='Output_arrays')\n",
    "        \n",
    "        #Initialise the hidden and cell states of decoder\n",
    "        hidden_output_dec = decoder_hidden_state\n",
    "        cell_output_dec = decoder_cell_state\n",
    "        \n",
    "        #for each timestep in decoder input (output after <start> token)\n",
    "        for timestep in range(decoder_input.shape[1]-1):\n",
    "            #Get the output, hidden states from one step decoder\n",
    "            output_dec,hidden_output_dec,cell_output_dec,_ = self.onestep_decoder(decoder_input[:,timestep:timestep+1],\n",
    "                                                                                  hidden_output_dec,cell_output_dec,\n",
    "                                                                                  encoder_outputs)\n",
    "            \n",
    "            #output_dec shape == (batch_size,vocab_size)\n",
    "            #Storing all outputs\n",
    "            all_outputs = all_outputs.write(timestep,output_dec)\n",
    "        #all_outputs shape after stacking == (timestep-1,batch_size,vocab_size)\n",
    "        #all_outputs shape after transpose == (batch_size,timestep-1,vocab_size)\n",
    "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        \n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "yBIUAdeTcuEB",
    "outputId": "dee8416d-0c59-40a0-fc59-86ab70cbeca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder with Attention:\n",
      "Shape of decoder input (batch_size,sequence length): (32, 23)\n",
      "Shape of decoder output (batch_size,sequence length-1,vocab_size): (32, 22, 1469)\n"
     ]
    }
   ],
   "source": [
    "#Initialise decoder\n",
    "decoder = Decoder(vocab_size=output_vocab_size,embedding_dim=300,embedding_matrix=out_embedding_matrix,\n",
    "                  dec_units=256,att_units=128)\n",
    "\n",
    "#Generate output from decoder\n",
    "all_outputs = decoder(example_target_batch,sample_hidden_output,sample_cell_output,sample_output)\n",
    "print('Decoder with Attention:')\n",
    "print('Shape of decoder input (batch_size,sequence length):',example_target_batch.shape)\n",
    "print('Shape of decoder output (batch_size,sequence length-1,vocab_size):',all_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3JlgiLdcuEM"
   },
   "source": [
    "<h2>2.4. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DTKipswcuEN"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHe4U-qBcuER"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    \n",
    "    #Identify zeros in real tensor/Creating masking tensor\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    #Calculate log loss for each class\n",
    "    loss_ = loss_object(real, pred)\n",
    "    #Change data type of mask\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #Calculate loss considering masking\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qlauC-cuET"
   },
   "source": [
    "<h2>2.5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDQubxhQcuEU"
   },
   "outputs": [],
   "source": [
    "class Encoder_Decoder_Attention_Model(tf.keras.models.Model):\n",
    "    def __init__(self, input_vocab_size,output_vocab_size,embedding_dim,enc_embedding_matrix,dec_embedding_matrix,units,\n",
    "                 att_units,**kwargs):\n",
    "        super(Encoder_Decoder_Attention_Model,self).__init__(**kwargs)\n",
    "        self.encoder = Encoder(vocab_size=input_vocab_size, embedding_dim=embedding_dim,embedding_matrix=enc_embedding_matrix,\n",
    "                               enc_units=units,name='Encoder_layer')\n",
    "        self.decoder = Decoder(vocab_size=output_vocab_size, embedding_dim=embedding_dim,embedding_matrix=dec_embedding_matrix,\n",
    "                               dec_units=units,att_units=att_units,name='Decoder_layer')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #Inputs will contain encoder input and decoder input\n",
    "        #Separate encoder and decoder inputs\n",
    "        encoder_inputs, decoder_inputs = inputs[0], inputs[1]\n",
    "        \n",
    "        #Genearte output and hidden states from encoder object\n",
    "        encoder_outputs, enc_hidden_output, enc_cell_output = self.encoder(encoder_inputs)\n",
    "\n",
    "        #Generate output from decoder\n",
    "        #Initialise hidden states of decoder with hidden states of encoder\n",
    "        all_outputs = self.decoder(decoder_inputs,enc_hidden_output,enc_cell_output,encoder_outputs)\n",
    "        \n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcrEYcmlL7H6"
   },
   "source": [
    "<h2>2.6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBKLoKUbL7H7"
   },
   "outputs": [],
   "source": [
    "#Function returns texts from a sequence\n",
    "def get_text_from_seq(sequence,tokenizer):\n",
    "    sent =''\n",
    "    for i in sequence:\n",
    "        if i!=0:\n",
    "            sent+=tokenizer.index_word[i]+' '\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ_KwVRdL7H_"
   },
   "outputs": [],
   "source": [
    "#Function to get bleu score for a sentence\n",
    "def get_bleu_score(enc_dec_model,input_seq,expected_output_seq):\n",
    "    \n",
    "    inp_max_length = X_train_padded_docs.shape[1]\n",
    "    out_max_length = y_train_padded_docs.shape[1]\n",
    "    \n",
    "    #Get output from encoder\n",
    "    enc_outputs,enc_hidden,enc_cell = enc_dec_model.layers[0](input_seq.reshape(1,inp_max_length))\n",
    "    \n",
    "    #Boundary case for decoder\n",
    "    dec_input = tf.expand_dims([out_tokenizer.word_index['<start>']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    \n",
    "    #Predicted output sequence\n",
    "    #Add <start> token to output sequence\n",
    "    output_seq = [out_tokenizer.word_index['<start>']]\n",
    "    \n",
    "    #The model will start predicting after start token, hence max_length is subtracted by 1\n",
    "    for i in range(out_max_length-1):\n",
    "        #Get prediction from onestep_decoder\n",
    "        dec_output,dec_hidden,dec_cell,_ = enc_dec_model.layers[1].onestep_decoder(dec_input,dec_hidden,dec_cell,enc_outputs)\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = tf.argmax(dec_output[0]).numpy()\n",
    "        \n",
    "        output_seq.append(key)\n",
    "        \n",
    "        if out_tokenizer.index_word[key] == '<end>':\n",
    "            #Get texts from input sentence\n",
    "            input_sent = get_text_from_seq(input_seq,out_tokenizer)\n",
    "            #Get texts from sequence for actual sentence\n",
    "            actual = get_text_from_seq(expected_output_seq,out_tokenizer)\n",
    "            #Get texts from sequence for predicted sentence\n",
    "            prediction = get_text_from_seq(output_seq,out_tokenizer)\n",
    "            return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    input_sent = get_text_from_seq(input_seq,out_tokenizer)\n",
    "    actual = get_text_from_seq(expected_output_seq,out_tokenizer)\n",
    "    prediction = get_text_from_seq(output_seq,out_tokenizer)\n",
    "    return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6naCdjvcuEa"
   },
   "source": [
    "<h1>3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TTqWUC8cuEa"
   },
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "input_vocab_size = len(inp_tokenizer.word_index) + 1  \n",
    "output_vocab_size = len(out_tokenizer.word_index) + 1  \n",
    "#Encoding and decoding Embedding layer dimension\n",
    "embedding_dim = 300\n",
    "enc_embedding_matrix = inp_embedding_matrix\n",
    "dec_embedding_matrix = out_embedding_matrix\n",
    "#Encoding and decoding LSTM layer units\n",
    "units = 128\n",
    "att_units = units\n",
    "\n",
    "#Initialise object for Model class\n",
    "model = Encoder_Decoder_Attention_Model(input_vocab_size,output_vocab_size,embedding_dim,enc_embedding_matrix,\n",
    "                                        dec_embedding_matrix,units,att_units,name='Encoder_Decoder_Attention_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "PKDJZOJDcuEc",
    "outputId": "7c669838-dafd-4384-e5f8-473c75ee2306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder_Decoder_Attention_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_layer (Encoder)      multiple                  660648    \n",
      "_________________________________________________________________\n",
      "Decoder_layer (Decoder)      multiple                  948538    \n",
      "=================================================================\n",
      "Total params: 1,609,186\n",
      "Trainable params: 727,486\n",
      "Non-trainable params: 881,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Max sequence length\n",
    "model.build(input_shape=[(None,X_train_padded_docs.shape[1]),(None,y_train_padded_docs.shape[1])])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20CwK6Chcj1d"
   },
   "outputs": [],
   "source": [
    "def data_generator(X,y,BATCH_SIZE,shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(X)).batch(BATCH_SIZE,drop_remainder=True)\n",
    "    else:\n",
    "        dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEn_0bp2cuEf"
   },
   "outputs": [],
   "source": [
    "#Create folder to save model weights\n",
    "if not os.path.isdir('model_save'):\n",
    "    os.makedirs('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsXuVDsV0XIU"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "colab_type": "code",
    "id": "tyKYm6yocuEm",
    "outputId": "cc85a573-83cb-4c48-a122-8f56df91cc30",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/642 [..............................] - ETA: 7:52 - loss: 1.9430WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.623773). Check your callbacks.\n",
      "642/642 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 00001: loss improved from inf to 1.22204, saving model to model_save/weights-01-1.2220.hdf5\n",
      "642/642 [==============================] - 190s 296ms/step - loss: 1.2220 - val_loss: 0.9487\n",
      "Epoch 2/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 1.0319\n",
      "Epoch 00002: loss improved from 1.22204 to 1.03190, saving model to model_save/weights-02-1.0319.hdf5\n",
      "642/642 [==============================] - 179s 278ms/step - loss: 1.0319 - val_loss: 0.9070\n",
      "Epoch 3/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9832\n",
      "Epoch 00003: loss improved from 1.03190 to 0.98319, saving model to model_save/weights-03-0.9832.hdf5\n",
      "642/642 [==============================] - 179s 279ms/step - loss: 0.9832 - val_loss: 0.8954\n",
      "Epoch 4/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9560\n",
      "Epoch 00004: loss improved from 0.98319 to 0.95603, saving model to model_save/weights-04-0.9560.hdf5\n",
      "642/642 [==============================] - 179s 278ms/step - loss: 0.9560 - val_loss: 0.8926\n",
      "Epoch 5/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9384\n",
      "Epoch 00005: loss improved from 0.95603 to 0.93839, saving model to model_save/weights-05-0.9384.hdf5\n",
      "642/642 [==============================] - 179s 279ms/step - loss: 0.9384 - val_loss: 0.8935\n",
      "Epoch 6/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9253\n",
      "Epoch 00006: loss improved from 0.93839 to 0.92527, saving model to model_save/weights-06-0.9253.hdf5\n",
      "642/642 [==============================] - 179s 278ms/step - loss: 0.9253 - val_loss: 0.8943\n",
      "Epoch 7/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9152\n",
      "Epoch 00007: loss improved from 0.92527 to 0.91517, saving model to model_save/weights-07-0.9152.hdf5\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.9152 - val_loss: 0.8968\n",
      "Epoch 8/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9073\n",
      "Epoch 00008: loss improved from 0.91517 to 0.90730, saving model to model_save/weights-08-0.9073.hdf5\n",
      "642/642 [==============================] - 179s 278ms/step - loss: 0.9073 - val_loss: 0.8981\n",
      "Epoch 9/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.9004\n",
      "Epoch 00009: loss improved from 0.90730 to 0.90042, saving model to model_save/weights-09-0.9004.hdf5\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.9004 - val_loss: 0.9014\n",
      "Epoch 10/10\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8949\n",
      "Epoch 00010: loss improved from 0.90042 to 0.89490, saving model to model_save/weights-10-0.8949.hdf5\n",
      "642/642 [==============================] - 179s 279ms/step - loss: 0.8949 - val_loss: 0.9030\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 10\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list=[checkpoint,tensorboard_callback]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history1 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fxEF9HIIMEUP",
    "outputId": "807cb646-3ce2-4ffe-dd3a-1414467433a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history1']"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history1.history,'history1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mrd7PRmjcuEp"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7ObOhaJazQcU",
    "outputId": "b5416c3e-dd7c-4647-ba90-60009c5ca33d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/643 [==============================] - 61s 95ms/step - loss: 0.8313\n"
     ]
    }
   ],
   "source": [
    "train_parameters = model.evaluate([X_train_padded_docs,y_train_padded_docs],y_train_padded_docs[:,1:],\n",
    "                                  verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dOq7_Vm-zjIM",
    "outputId": "d9f48d62-494f-46cc-f099-284a5688babf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 11s 95ms/step - loss: 0.9034\n"
     ]
    }
   ],
   "source": [
    "val_parameters = model.evaluate([X_val_padded_docs,y_val_padded_docs],y_val_padded_docs[:,1:],verbose=1,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt-hIXlo7fBQ"
   },
   "outputs": [],
   "source": [
    "#Load weights\n",
    "model.load_weights('best_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lhEUJAIwRj5J",
    "outputId": "abbd84e0-8aa4-4209-c9c1-0e47182625f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  2/642 [..............................] - ETA: 10:52 - loss: 0.8452WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.904714). Check your callbacks.\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8532\n",
      "Epoch 00001: loss improved from inf to 0.85317, saving model to model_save/weights-01-0.8532.hdf5\n",
      "642/642 [==============================] - 189s 295ms/step - loss: 0.8532 - val_loss: 0.8859 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8416\n",
      "Epoch 00002: loss improved from 0.85317 to 0.84157, saving model to model_save/weights-02-0.8416.hdf5\n",
      "642/642 [==============================] - 177s 276ms/step - loss: 0.8416 - val_loss: 0.8847 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8370\n",
      "Epoch 00003: loss improved from 0.84157 to 0.83702, saving model to model_save/weights-03-0.8370.hdf5\n",
      "642/642 [==============================] - 178s 277ms/step - loss: 0.8370 - val_loss: 0.8845 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8340\n",
      "Epoch 00004: loss improved from 0.83702 to 0.83399, saving model to model_save/weights-04-0.8340.hdf5\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.8340 - val_loss: 0.8842 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8315\n",
      "Epoch 00005: loss improved from 0.83399 to 0.83151, saving model to model_save/weights-05-0.8315.hdf5\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.8315 - val_loss: 0.8842 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8294\n",
      "Epoch 00006: loss improved from 0.83151 to 0.82943, saving model to model_save/weights-06-0.8294.hdf5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.8294 - val_loss: 0.8848 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8269\n",
      "Epoch 00007: loss improved from 0.82943 to 0.82691, saving model to model_save/weights-07-0.8269.hdf5\n",
      "642/642 [==============================] - 178s 277ms/step - loss: 0.8269 - val_loss: 0.8847 - lr: 9.0000e-04\n",
      "Epoch 8/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8254\n",
      "Epoch 00008: loss improved from 0.82691 to 0.82536, saving model to model_save/weights-08-0.8254.hdf5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.8254 - val_loss: 0.8851 - lr: 9.0000e-04\n",
      "Epoch 9/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8235\n",
      "Epoch 00009: loss improved from 0.82536 to 0.82346, saving model to model_save/weights-09-0.8235.hdf5\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.8235 - val_loss: 0.8852 - lr: 8.1000e-04\n",
      "Epoch 10/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8222\n",
      "Epoch 00010: loss improved from 0.82346 to 0.82216, saving model to model_save/weights-10-0.8222.hdf5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.8222 - val_loss: 0.8854 - lr: 8.1000e-04\n",
      "Epoch 11/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8206\n",
      "Epoch 00011: loss improved from 0.82216 to 0.82063, saving model to model_save/weights-11-0.8206.hdf5\n",
      "642/642 [==============================] - 178s 278ms/step - loss: 0.8206 - val_loss: 0.8856 - lr: 7.2900e-04\n",
      "Epoch 12/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8193\n",
      "Epoch 00012: loss improved from 0.82063 to 0.81931, saving model to model_save/weights-12-0.8193.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "642/642 [==============================] - 179s 278ms/step - loss: 0.8193 - val_loss: 0.8859 - lr: 7.2900e-04\n",
      "Epoch 13/20\n",
      "642/642 [==============================] - ETA: 0s - loss: 0.8178\n",
      "Epoch 00013: loss improved from 0.81931 to 0.81779, saving model to model_save/weights-13-0.8178.hdf5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "642/642 [==============================] - 179s 278ms/step - loss: 0.8178 - val_loss: 0.8859 - lr: 6.5610e-04\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Set Parameters\n",
    "BATCH_SIZE = 512\n",
    "epochs = 20\n",
    "\n",
    "#Model compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n",
    "\n",
    "#Save intermediate model callback\n",
    "filepath=\"model_save/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#Reduce learning rate by 10% if validation loss does not decrease from last 2 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, verbose=1, patience=2,min_lr=0.00001)\n",
    "\n",
    "#Stop training if val_loss does not decrease in last 8 epochs\n",
    "terminate = EarlyStopping(monitor='val_loss',patience=8,verbose=1,mode='min',restore_best_weights=True)\n",
    "\n",
    "#Tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "#Callback list\n",
    "callback_list=[checkpoint,reduce_lr,terminate,tensorboard_callback]\n",
    "\n",
    "#Generate data\n",
    "train = data_generator((X_train_padded_docs,y_train_padded_docs),y_train_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,\n",
    "                       shuffle=True)\n",
    "val = data_generator((X_val_padded_docs,y_val_padded_docs),y_val_padded_docs[:,1:],BATCH_SIZE=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "#Train model\n",
    "history2 = model.fit(train,epochs=epochs,validation_data=val,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GDFgO6WlRj27",
    "outputId": "70f730ee-f747-48e9-e79b-8faa2fbd849e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history2']"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history2.history,'history2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBtgPKhtRjyo"
   },
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('best_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PqO7ZdNzbML7"
   },
   "outputs": [],
   "source": [
    "h1 = joblib.load('history1')\n",
    "h2 = joblib.load('history2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGKGMZ1fbML_"
   },
   "outputs": [],
   "source": [
    "loss = h1['loss']+h2['loss']\n",
    "val_loss = h1['val_loss']+h2['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "21qTt3XkbMMC",
    "outputId": "bbd7e534-edf0-45b2-90e1-7bac87beb32a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Vs No of epochs')"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXwV5bnA8d+Tk30hQE4IOwTZkT2IymJQrOCGWm2lVuWiItal7ltt4bpU21Kv9SoqWopaK1qtXFpxqYUIiguLgCAiiyD7ThZC9uf+MZNwSE5WcnKSnOf7+cznzMw7y5NXPM955515R1QVY4wxprywYAdgjDGmcbIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGGGP8sgRhjDHGL0sQxjRiItJLRFaJSLaI3BbseABEREWke7DjMIFnCcI0KBHZKiJjG/ic94vIYj/rvSJSICKn1uJYXd0vyAXl1v9VRKbXQ7jl3QssUtUEVX06AMc3plKWIEwo+Ctwpoikllt/JfC1qq6twzGHi8iZJx9atboA6xrgPMZUYAnCNAoiEiUiT4nILnd6SkSi3DKviPxLRI6IyCERWSIiYW7ZfSKy070Es0FEzil/bFXdASwEri5XdA3winuc7iLysYhkisgBEXmjmpB/DzxWxd9zg4hscuOdLyLtq9j2YhFZ5/59GSLSx12/EBgDPCMiOSLS08++iSLyZxHZ7dbDoyLiccsmicinIvKM+3d961s/ItLeje2QG+sNPmUeEXlQRDa7dbtCRDr5nHqsiGx0Y35WRKSO9WgaM1W1yaYGm4CtwFg/6x8GPgfaAMnAUuARt+xx4Hkgwp1GAQL0ArYD7d3tugKnVHLeq4CNPsu9gAIg2V1+HfgVzo+maGBkJcfpCiiQAOws/VtwWinT3fmzgQPAECAK+F9gcSXH6wkcBc51/7Z7gU1ApFueAVxfRX2+A7wAxLl19yVwo1s2CSgC7nCP/VMgE2jtli8GZrp/7yBgP3C2W3YP8LVbTwIMBJLcMgX+BbQEOrv7jatNPdrUNCZrQZjG4irgYVXdp6r7gf/m+C/+QqAd0EVVC1V1iTrfRsU4X8B9RSRCVbeq6uZKjv8OkOJzWega4D33XKXn6IKTbPJU9ZNq4j2G04J4tJK/ZbaqrlTVfOAB4AwR6epn258C76rqv1W1EJgBxADVXr4SkRTgfOB2VT2qqvuA/8G5dFZqH/CUW29vABuAC9zWwAjgPvfvXQW8hFMvANcDD6nqBnWsVtWDPsd9QlWPqOoPwCKcBAO1r0fTiFmCMI1Fe2Cbz/I2dx3AH3B+VX8oIltE5H4AVd0E3A5MB/aJyNzKLuWoai7wd+Aa93LIVbiXl1z34vxS/tK93DO5BjG/hJN0Lqrqb1HVHOAg0MHPMcpvW4LTKvK3bXldcFoGu91LPUdwWhNtfLbZ6SbTUqX12h44pKrZ5cpKz9sJqCzZAuzxmc8F4t35utSjaaQsQZjGYhfOF16pzu46VDVbVe9S1W7AxcCdpdfSVfVvqjrS3VeB31VxjpeBn+BczkkA/llaoKp7VPUGVW0P3AjMrO5WTlUtwGnpPILzpej3bxGROCAJ55JUlX+3m7w6VbJteduBfMCrqi3dqYWq9vPZpkNp/4CrtF53Aa1FJKFcWel5twOn1CCGE9SlHk3jZQnCBEOEiET7TOE4164fEpFkEfECv8G5ro+IXOh2fgrONfRioMR9RuBstzM7D+eyT0kV510CHAFmAXPdL3jcc1whIh3dxcM4yaaqY5V6Feda+zifda8D/yUig9zYfgt8oapb/ez/Js4ln3NEJAK4C+dLf2l1J1bV3cCHwB9FpIWIhInIKSJyls9mbYDbRCRCRK4A+gALVHW7e47H3f8GA4DrcOscp3X0iIj0EMcAEUmqLqaTqEfTCFmCMMGwAOfLvHSajnMtfzmwBqdzdCXHr+/3AD4CcoDPgJmqugin/+EJnA7hPThfhg9UdlL3UssrOL/YXylXPAz4QkRygPnAL1V1S3V/iKoW4ySz1j7rPgJ+DbwN7Mb5JX5lJftvAH6O05F9ALgIuMg3eVXjGiAS+AbnC/ktnP6aUl/g1N8BnD6Ty336EibidLrvwumjmebGDvAkTvL6EMgC/ozTN1KdOtWjaZzkxMuTxpjmQkQm4dwBNTLYsZimyVoQxhhj/LIEYYwxxi+7xGSMMcYva0EYY4zxKzzYAdQnr9erXbt2rdO+R48eJS4urn4DauKsTiqyOqnI6qSiplQnK1asOKCqyf7KmlWC6Nq1K8uXL6/TvhkZGaSnp9dvQE2c1UlFVicVWZ1U1JTqRES2VVZml5iMMcb4ZQnCGGOMX5YgjDHG+NWs+iCMMQ2rsLCQ+Ph41q9fH+xQGpXExMRGVyfR0dF07NiRiIiIGu9jCcIYU2c7duwgJSWFjh07cuKgsaEtOzubhISE6jdsIKrKwYMH2bFjB6mp5d+8Wzm7xGSMqbO8vDwSExMtOTRyIkJSUhJ5eXm12s8ShDHmpFhyaBrq8t8p5BNEUXEJzy7axNf7i4IdijHGNCohnyA8YcKsxVtYua842KEYY2rp4MGDDBo0iEGDBtG2bVs6dOhQtlxQUPUrNZYvX85tt91W7TnOPLPa14PXSEZGBhdeeGG9HKuhhHwntYiQ6o1jz9GsYIdijKmlpKQkVq1aBcD06dOJj4/n7rvvLisvKioiPNz/11xaWhppaWnVnmPp0mpf7tdshXwLAqCbN469uTaqrTHNwaRJk5g6dSrDhw/n3nvv5csvv+SMM85g8ODBnHnmmWzYsAE48Rf99OnTmTx5Munp6XTr1o2nn3667Hjx8fFl26enp3P55ZfTu3dvrrrqKkpHw16wYAG9e/dm6NCh3HbbbVxxxRVVxnjo0CEuueQSBgwYwOmnn86aNWsA+Pjjj8taQIMHDyY7O5vdu3czevRoBg0axKmnnsqSJUvqvc4qE/ItCIBuyXH84yslt6CI2EirEmPq4r//uY5vdtVvS7xv+xZMu6hfrffbsWMHS5cuxePxkJWVxZIlSwgPD+ejjz7iwQcf5O23366wz7fffsuiRYvIzs6mV69e3HTTTRWeGfjqq69Yt24d7du3Z8SIEXz66aekpaVx4403snjxYlJTU5k4cWK18U2bNo3Bgwczb948Fi5cyDXXXMOqVauYMWMGzz77LCNGjCAnJ4fo6GhmzZrFeeedx69+9SuKi4vJzc2tdX3UlX0bAqle5xfC1gO59G3fIsjRGGNO1hVXXIHH4wEgMzOTa6+9lo0bNyIiFBYW+t3nggsuICoqiqioKNq0acPevXvp2LHjCducdtppZesGDRrE1q1biY+Pp1u3bmXPF0ycOJGZM2dWGd8nn3xSlqTOPvtsDh48SFZWFiNGjODOO+/kqquu4rLLLqNjx44MGzaMyZMnU1hYyCWXXMKgQYNOqm5qwxIEkOp1huX9/sBRSxDG1FFdfukHiu9Q27/+9a8ZM2YM77zzDlu3bq10lNWoqKiyeY/HQ1FRxTsba7LNybj//vu54IILWLBgASNGjOCDDz5g9OjRLF68mHfffZdJkyZx5513cs0119TreStjfRBAV28sAN8fyAlyJMaY+paZmUmHDh0AmDNnTr0fv1evXmzZsoWtW7cC8MYbb1S7z6hRo3jttdcAp2/D6/XSokULNm/eTP/+/bnvvvsYNmwY3377Ldu2bSMlJYUbbriB66+/npUrV9b731AZSxBAbGQ4raOFLQeOBjsUY0w9u/fee3nggQcYPHhwvf/iB4iJiWHmzJmMGzeOoUOHkpCQQIsWVV+JmD59OitWrGDAgAHcf//9vPzyywA89dRTnHrqqQwYMICIiAjGjx9PRkYGAwcOZPDgwbzxxhv88pe/rPe/oTIBeye1iMwGLgT2qeqpfsqvAu4DBMgGblLV1W7ZOOBPgAd4SVWfqMk509LStK4vDBr/+/eIjm/BO78YUaf9m6Om9NKThmJ1cqL169fTsWPHRjXuUDDk5OQQHx+PqnLzzTfTqVMnHnjggWCHVcH69evp06fPCetEZIWq+r3fN5AtiDnAuCrKvwfOUtX+wCPALAAR8QDPAuOBvsBEEekbwDgBaBsXxpb9RwlUwjTGNF8vvvgigwYNol+/fmRmZjJ58uRgh1QvAtZJraqLRaRrFeW+T598DpTeLnAasElVtwCIyFxgAvBNYCJ1tI0LI3N7AYdzC2kdFxnIUxljmpk77riDO+64o2w5Ozs7iNHUn8ZyF9N1wHvufAdgu0/ZDmB4ZTuKyBRgCkBKSgoZGRl1CiAxLB8Q3v5wCT1aeep0jOYmJyenzvXZXFmdnCgxMZHi4uJm84VYXxprneTl5dXq32/QE4SIjMFJECPrsr+qzsK9PJWWlqZ1vT68592FwDFadupJelqnOh2jubHr7RVZnZxo/fr1eDyekO+DKK+xvQ+iVHR0NIMHD67x9kFNECIyAHgJGK+qB93VOwHfb+iO7rqA8sYI4WHC93YnkzHGAEG8zVVEOgP/AK5W1e98ipYBPUQkVUQigSuB+YGOJzxM6JwUawnCGGNcAUsQIvI68BnQS0R2iMh1IjJVRKa6m/wGSAJmisgqEVkOoKpFwC3AB8B64E1VXReoOH1188ZZgjCmCRkzZgwffPDBCeueeuopbrrppkr3SU9Pp/R2+PPPP58jR45U2Gb69OnMmDGjynPPmzePb745fu/Mb37zGz766KPahO9XYxoWPJB3MVU5YpWqXg9cX0nZAmBBIOKqSqo3jiUbD1BSooSF2VuyjGnsJk6cyNy5cznvvPPK1s2dO5ff//73Ndp/wYK6f83MmzePCy+8kL59nbvwH3744Tofq7GyJ6l9pHrjyS8qYXdW7d7baowJjssvv5x333237OVAW7duZdeuXYwaNYqbbrqJtLQ0+vXrx7Rp0/zu37VrVw4cOADAY489Rs+ePRk5cmTZkODgPOMwbNgwBg4cyI9//GNyc3NZunQp8+fP55577mHQoEFs3ryZSZMm8dZbbwFOK2Dw4MH079+fyZMnk5+fX3a+adOmMWTIEPr378+3335b5d8X7GHBg34XU2NSNmjf/qN0aBkT5GiMaWLeux/2fF2/x2zbH8ZXPpBC69atOe2003jvvfeYMGECc+fO5Sc/+QkiwmOPPUbr1q0pLi7mnHPOYc2aNQwYMMDvcVasWMHcuXNZtWoVRUVFDBkyhKFDhwJw2WWXccMNNwDw0EMP8ec//5lbb72Viy++mAsvvJDLL7/8hGPl5eVx0003sXDhQnr27Mk111zDc889x+233w6A1+tl5cqVzJw5kxkzZvDSSy9V+vcFe1hwa0H46JZcOqqrDdpnTFNRepkJnMtLpe9jePPNNxkyZAiDBw9m3bp1J/QXlLdkyRIuvfRSYmNjadGiBRdffHFZ2dq1axk1ahT9+/fntddeY926qrtEN2zYQJcuXejZsycA1157LYsXLy4rv+yyywAYOnRo2QB/lfnkk0+4+uqrAf/Dgj/99NMcOXKE8PBwhg0bxl/+8hemT5/O119/XS+32VoLwkebhChiIz1s3m8d1cbUWhW/9ANpwoQJ3HHHHaxcuZLc3FyGDh3K999/z4wZM1i2bBmtWrVi0qRJ5OXV7dLxpEmTmDdvHgMHDmTOnDkn/aBk6ZDhJzNceEMNC24tCB+l76e2O5mMaTri4+MZM2YMkydPLms9ZGVlERcXR2JiInv37uW9996r8hijR49m3rx5HDt2jOzsbP75z3+WlWVnZ9OuXTsKCwvLhugGSEhI8Pu0dK9evfjhhx/YtGkTAK+++ipnnXVWnf62YA8Lbi2IclK9cazZkRnsMIwxtTBx4kQuvfTSsktNpcNj9+7dm06dOjFiRNWjNA8ZMoSf/vSnDBw4kDZt2jBs2LCyskceeYThw4eTnJzM8OHDy5LClVdeyQ033MDTTz9d1jkNztPKM2fO5IorrqCoqIhhw4YxderUCuesidJ3ZQ8YMIDY2NgThgVftGgRYWFh9OvXj/HjxzN37lz+8Ic/EBERQXx8PK+88kqdzukrYMN9B8PJDPddOoTCkx9u4JlFm1j/yDiiwkN7TCYbVqIiq5MT2XDf/jXWoTYa03DfTVJqchwlCtsPNdyLwY0xpjGyBFFON288AFuso9oYE+IsQZTTtfRZCOuoNqZGmtNl6uasLv+dLEGUkxgTgTc+0hKEMTUQHR1NZmamJYlGTlU5ePAg0dHRtdrP7mLyI9UbxxZLEMZUq2PHjqxevZqcHHu41FdeXl6tv4wDLTo6mo4dO1a/oQ9LEH6keuNYtGF/sMMwptGLiIggJyeHtDS/N8GErNKxmJo6u8TkR6o3nv3Z+WTnFQY7FGOMCRpLEH6kWke1McYE9IVBs0Vkn4israS8t4h8JiL5InJ3ubKtIvK174uEGtLxQfssQRhjQlcgWxBzgHFVlB8CbgMqe23TGFUdVNkTfoHUuXUsIvYshDEmtAUsQajqYpwkUFn5PlVdBjS6C/3RER46tIyxFoQxJqQ11ruYFPhQRBR4QVVnVbahiEwBpgCkpKTUeSjenJycE/Zt6Slgzfd7Tnpo36asfJ0YqxN/rE4qai510lgTxEhV3SkibYB/i8i3boukAjd5zAJnsL66DqRWfhC2jKx1vLViB2eddRYiofl+ahuYriKrk4qsTipqLnXSKO9iUtWd7uc+4B3gtIaOIdUbR05+Eftz8hv61MYY0yg0ugQhInEiklA6D/wI8HsnVCD5vp/aGGNCUcAuMYnI60A64BWRHcA0IAJAVZ8XkbbAcqAFUCIitwN9AS/wjntZJxz4m6q+H6g4K+P7LMTwbkkNfXpjjAm6gCUIVZ1YTfkewN/AIFnAwIAEVQvtW8YQGR5mdzIZY0JWo7vE1Fh4woSuSbE2aJ8xJmRZgqhCqjfOWhDGmJBlCaIKqd54th08SlFxSbBDMcaYBmcJogrdvHEUFis7jxwLdijGGNPgLEFUIdUdtM/6IYwxocgSRBW62bMQxpgQZgmiCq3jImkRHW4d1caYkGQJogoiQmpyvCUIY0xIsgRRjW52q6sxJkRZgqhGqjeOnUeOkVdYHOxQjDGmQVmCqEbpmExbD1orwhgTWixBVMNGdTXGhCpLENUoTRD2LIQxJtRYgqhGXFQ4KS2i2GItCGNMiLEEUQPOoH05wQ7DGGMalCWIGuhmz0IYY0JQwBKEiMwWkX0i4vd1oSLSW0Q+E5F8Ebm7XNk4EdkgIptE5P5AxVhT3bxxHM4t5PDRgmCHYowxDSaQLYg5wLgqyg8BtwEzfFeKiAd4FhiP8wrSiSLSN0Ax1kjZnUx2q6sxJoQELEGo6mKcJFBZ+T5VXQYUlis6DdikqltUtQCYC0wIVJw1Ybe6GmNCUcDeSX0SOgDbfZZ3AMMr21hEpgBTAFJSUsjIyKjTSXNycirdt6hECRPIWPENSdmb6nT8pqiqOglVVicVWZ1U1FzqpDEmiFpR1VnALIC0tDRNT0+v03EyMjKoat8uKzMoiWtBevqQOh2/KaquTkKR1UlFVicVNZc6aYx3Me0EOvksd3TXBVWqN84eljPGhJTGmCCWAT1EJFVEIoErgflBjolUbxxbDxylpESDHYoxxjSIgF1iEpHXgXTAKyI7gGlABICqPi8ibYHlQAugRERuB/qqapaI3AJ8AHiA2aq6LlBx1lSqN45jhcXszc6jXWJMsMMxxpiAC1iCUNWJ1ZTvwbl85K9sAbAgEHHVle/rRy1BGGNCQWO8xNQopSY7CWKz9UMYY0KEJYgaatsimpgIjz0LYYwJGZYgakhEbNA+Y0xIsQRRC6nJ9n5qY0zosARRC928cWw/fIyCopJgh2KMMQFnCaIWUr1xFJco2w/nBjsUY4wJOEsQtWCD9hljQokliFooSxDWD2GMCQGWIGqhZWwkreMibUwmY0xIsARRS3arqzEmVFiCqCUnQVgLwhjT/FmCqKVUbxx7s/LJyS8KdijGGBNQliBq6RR3TKat1oowxjRzliBqKdUbD2Ad1caYZs8SRC11SYpFxJ6FMMY0fwFLECIyW0T2icjaSspFRJ4WkU0iskZEhviUFYvIKncK+tvkfEVHeGifGGN3Mhljmr1AtiDmAOOqKB8P9HCnKcBzPmXHVHWQO10cuBDrppsN2meMCQEBSxCquhg4VMUmE4BX1PE50FJE2gUqnvqU6o1jy4GjqNr7qY0xzVfAXjlaAx2A7T7LO9x1u4FoEVkOFAFPqOq8yg4iIlNwWiCkpKSQkZFRp2BycnJqvG/x4UKy84r454cZtIiSOp2vKahNnYQKq5OKrE4qai51EswEUZUuqrpTRLoBC0Xka1Xd7G9DVZ0FzAJIS0vT9PT0Op0wIyODGu+7YR+vfbuMdr0GMqxr6zqdrymoVZ2ECKuTiqxOKmoudRLMu5h2Ap18lju661DV0s8tQAYwuKGDq0o391ZXu5PJGNOcBTNBzAeuce9mOh3IVNXdItJKRKIARMQLjAC+CWKcFXRoFUOkJ8yehTDGNGsBu8QkIq8D6YBXRHYA04AIAFV9HlgAnA9sAnKB/3J37QO8ICIlOAnsCVVtVAnCEyZ0SYq1W12NMc1awBKEqk6splyBm/2sXwr0D1Rc9SXVG8cWu8RkjGnG7EnqOkpNjmPbwVyKS+xWV2NM81SjBCEicSIS5s73FJGLRSQisKE1bt28cRQUl7DryLFgh2KMMQFR0xbEYpxnEzoAHwJX4zwpHbJKB+3bvN/6IYwxzVNNE4Soai5wGTBTVa8A+gUurMavV0oC0RFhvLViR7BDMcaYgKhxghCRM4CrgHfddZ7AhNQ0JMZGMPWsU/jXmt18seVgsMMxxph6V9MEcTvwAPCOqq5zn3BeFLiwmoYbR59Ch5YxTP/nN9ZZbYxpdmqUIFT1Y1W9WFV/53ZWH1DV2wIcW6MXE+nhgfN7s353Fm8s2179DsYY04TU9C6mv4lICxGJA9YC34jIPYENrWm4oH87TkttzYwPN5CZWxjscIwxpt7U9BJTX1XNAi4B3gNSce5kCnkiwrSL+nIkt4Cn/vNdsMMxxph6U9MEEeE+93AJMF9VCwG76O7q1z6RK0/rzCufbWPj3uxgh2OMMfWipgniBWArEAcsFpEuQFaggmqK7jq3J3GRHh7+1zf2IiFjTLNQ007qp1W1g6qe774BbhswJsCxNSlJ8VHcPrYnSzYe4KP1+4IdjjHGnLSadlInisiTIrLcnf6I05owPq4+ows92sTz6LvfkF9UHOxwjDHmpNT0EtNsIBv4iTtlAX8JVFBNVYQnjN9c1JdtB3OZ/cnWYIdjjDEnpaYJ4hRVnaaqW9zpv4FugQysqRrVI5mxfVJ4ZuFG9mXlBTscY4yps5omiGMiMrJ0QURGADaMaSUeuqAPhcXK797fEOxQjDGmzmqaIKYCz4rIVhHZCjwD3FjdTiIyW0T2icjaSspFRJ4WkU0iskZEhviUXSsiG93p2hrG2Sh09cYxeWQqb6/cwVc/HA52OMYYUyc1vYtptaoOBAYAA1R1MHB2DXadA4yronw80MOdpgDPAYhIa5xXlA4HTgOmiUirmsTaWNxydnfaJEQx/Z/fUGLjNBljmqBavVFOVbPcJ6oB7qzB9ouBQ1VsMgF4xb119nOgpYi0A84D/q2qh1T1MPBvqk40jU58VDj3jevN6u1HeOerncEOxxhjau1k3kkt9XD+DoDvKHc73HWVra8YhMgUnNYHKSkpZGRk1CmQnJycOu9bmVaqdEsM4+H5a4g9vJGY8PqosoYTiDpp6qxOKrI6qai51MnJJIhGcd1EVWcBswDS0tI0PT29TsfJyMigrvtWpdUph7l05lJWF7bj/rG96/34gRSoOmnKrE4qsjqpqLnUSZWXmEQkW0Sy/EzZQPt6OP9OoJPPckd3XWXrm5zBnVvx4yEdmf3J92w9cDTY4RhjTI1VmSBUNUFVW/iZElT1ZFofpeYD17h3M50OZKrqbuAD4Eci0srtnP6Ru65Jum9cLyI8wqPvrg92KMYYU2O16qSuLRF5HfgM6CUiO0TkOhGZKiJT3U0WAFuATcCLwC8AVPUQ8AiwzJ0edtc1SW1aRHPL2T34aP1eFn+3P9jhGGNMjdRHK6BSqjqxmnIFbq6kbDbOEB/NwuSRXZm77Ace/tc3vPfLUUR4ApqbjTHmpNm3VAOJCvfw0AV92bQvh1c/2xbscIwxplqWIBrQ2D5tGNXDy/989B3bD+UGOxxjjKmSJYgGJCJMv7gfAvz0hc/43u5qMsY0YpYgGtgpyfG8PuV08opK+MkLn/GdvaLUGNNIWYIIgn7tE3ljyukIcOWsz1m7MzPYIRljTAWWIIKkR0oCb954BjERHn724uc26qsxptGxBBFEXb1xvHHj6bSKi+TnL33B51sOBjskY4wpYwkiyDq2iuXNG8+gXcsYJv3lSz62B+mMMY2EJYhGIKVFNG9MOZ1Ubzw3vLycD9ftCXZIxhhjCaKxSIqPYu4Np9OnfQt+8dpK/rl6V7BDMsaEOEsQjUhibAR/ve40hnRuxS/nfsVbK3YEOyRjTAizBNHIJERHMGfyMEZ093L331fz6uc2LIcxJjgsQTRCsZHhvHhNGmP7tOHX89by4uItwQ7JGBOCLEE0UtERHmZeNZQL+rfjsQXrefo/G3EGvzXGmIYR0OG+zcmJDA/jT1cOIio8jCf//R1H84u457xehNtQ4caYBhDoFwaNE5ENIrJJRO73U95FRP4jImtEJENEOvqUFYvIKneaH8g4G7NwTxgzrhjIVcM788LiLUx49lNWbz8S7LCMMSEgYAlCRDzAs8B4oC8wUUT6lttsBvCKqg4AHgYe9yk7pqqD3OniQMXZFISFCY9ecirPXTWE/dn5XDLzU6bPX0d2XmGwQzPGNGOBbEGcBmxS1S2qWgDMBSaU26YvsNCdX+SnvGEUF4KWBOXUNSUijO/fjo/uOotrTu/Cy59tZeyTH/Pe17utb8IYExCB7IPoAGz3Wd4BDC+3zWrgMuBPwKVAgogkqepBIFpElgNFwBOqOs/fSURkCjAFICUlhYyMjFoFGV6YzcDVvyG51ZlkSNO4tj8mEboMj2bOugJuem0lA5M9XPXeF7cAABzkSURBVN03Em9M/cafk5NT6/ps7qxOKrI6qai51IkE6teniFwOjFPV693lq4HhqnqLzzbtgWeAVGAx8GPgVFU9IiIdVHWniHTDaWWco6qbqzpnWlqaLl++vHaBqsLrV1K8aSGeXywFb4/a7R9ERcUlzFm6lT9++B0Ad57bk/8a0bXeOrEzMjJIT0+vl2M1F1YnFVmdVNSU6kREVqhqmr+yQP5k3gl08lnu6K4ro6q7VPUyVR0M/Mpdd8T93Ol+bgEygMEBiVIELvoTJWGR8M5UKC4KyGkCIdwTxvWjuvHRXWcxonsSjy1Yz0XPfGpDhxtj6kUgE8QyoIeIpIpIJHAlcMLdSCLiFSm7rvMAMNtd30pEokq3AUYA3wQs0oS2bOxxI+xcDkufDthpAqVDyxhevCaN538+lMNHC7jsuaX8et5asqwT2xhzEgKWIFS1CLgF+ABYD7ypqutE5GERKb0rKR3YICLfASnAY+76PsByEVmN03n9hKoGLkEA+9qMgr4TYNFvYe+6QJ4qIESEcae25aO7zmLSmV157YttjP3jx7y7xjqxjTF1E9AH5VR1AbCg3Lrf+My/BbzlZ7+lQP9AxlaBCFzwJGxb6lxquv4/EB7ZoCHUh/iocKZd1I9LB3fgwXe+5ua/rWRkdy83j+nO6d1aIyLBDtEY00Q0jdt2GkqcFy58CvasgSUzgh3NSRnQsSXzfjGC31zYl2/3ZDHxxc+5ZOZS3l+7m+ISa1EYY6pnCaK8PhfCgCth8QzYuTLY0ZyUcE8Yk0em8sl9Z/PoJadyJLeAqX9dyblPfszrX/5AXmFxsEM0xjRiliD8Gf8ExLeBeTdBYV6wozlp0REefn56Fxbelc6zPxtCXFQ4D/zja0b9fhEzMzZZZ7Yxxi9LEP7EtIKLn4H938Kix6rfvonwhAkXDGjH/FtG8Nr1w+ndNoHfv7+BMx9fyOML1rM3q+knQ2NM/bHRXCvTYywMnQRL/xd6Xwidyz8E3nSJCCO6exnR3cvanZm8sHgLLy7ZwuxPv+fSwR2YMvoUureJD3aYxpggsxZEVX70KLTsBPOmQsHRYEcTEKd2SOR/Jw7m43vGMPG0zsxfvYuxT37MDa8sZ/3BYkqsQ9uYkGUJoipRCTBhJhzaAh/9d7CjCahOrWN5eMKpfHrf2dx2Tg+WbT3E75blMfJ3C3n8vfV8uycr2CEaYxqYJYjqpI6C4VPhyxdgy8fBjibgkuKjuPPcnnx2/zlMHRBF73Yt+POS7xn31BLGPbWY5z/ezK4jx4IdpjGmAViCqIlzpkHrU+D/boG80PglHRPp4fT24cyeNIwvHjyHhyf0IzbSwxPvfcuI3y3kylmfMffLH8g8ZndAGdNcWYKoichYuPR5yNoBH/4q2NE0uKT4KK45oyv/+MUIPr4nnTvG9mRfVj73/+Nrhj36EVNfXcH7a3eTX2TPVRjTnNhdTDXV6TQ48zb49CnofRH0/FGwIwqKLklx3HZOD249uztf78xk3le7mL96F++v20OL6HDO79+O805ty+mpScREeoIdrjHmJFiCqI0xD8J3H8D8W+EXn0Fs62BHFDQiwoCOLRnQsSUPnt+bpZsPMu+rncxfvYu5y7YTGR7G8NTWjO6RzOieyfRMibdxoIxpYixB1EZ4lHOp6aVz4L374McvBjuiRiHcE8bonk4i+G1hMV9+f4jF3+1n8cb9PLZgPY8tWE/bFtGM6uHlrF7JjOzupWVs0xsI0ZhQYwmittoPgtH3QMbj0Oci6Htx9fuEkOgIT1myANh15BhLNu5n8XcH+GDdHv6+Ygdh4gwmOLpnMmf1TGZgx8R6ewueMab+WIKoi1F3wYYF8K87IKk7pPQNdkSNVvuWMfx0WGd+OqwzRcUlrN6RWda6eGbhRp7+z0ZaRIczsoeXM7olMbxbEt2T4wkLs8tRxgSbJYi68ETAJc/Dn8+F586ALiMgbbLTogiPCnZ0jVa4J4yhXVoxtEsr7ji3J0dyC/hk0wEWf7efJRsPsODrPQC0io1gWNfWnJbamtO7JdGnXQs8ljCMaXABTRAiMg74E+ABXlLVJ8qVd8F5zWgycAj4uarucMuuBR5yN31UVV8OZKy1ltIXfrkavvorrPgLvH0dxHphyNXOGE6tugY7wkavZWwkFw5oz4UD2qOq7Dh8jM+3HOTL7w/x5dZDfPjNXgASosIZ2rUVp6W2Znhqa/p3aElkeBWXpIoLIT8b8rOc51bys32mTOczIg4G/9y5hdkY41fAEoSIeIBngXOBHcAyEZlf7tWhM4BXVPVlETkbeBy4WkRaA9OANECBFe6+hwMVb53EeWHk7c7tr1sWwrLZ8Omf4JOnoPtYp1XR8zwIs9s9qyMidGodS6fWsVyR1gmAPZl5fPG9kzDWbNnJ29+t4nM5QJfwQwxJPEqvmEzahx0igVw8BTlOQsjPhqIajkq79H+dod17ne+8UdAYc4JAtiBOAzap6hYAEZkLTAB8E0Rf4E53fhEwz50/D/i3qh5y9/03MA54PYDx1l1YmJMQuo+FzJ2w8mVY8TLMnQgtOjotiiFXQ0LbYEfa+BQXQeFR54s9azdkbnenHbTN3MGEzO1MyNwBxw6Dz9W74uww9mS1YrO2JlPj0Mj2RMb3Jb51K1q1SiLZ6yUuoRVEt3DG1IpKgKgWxz93rYR374a5P4Me5zmJonW34NWDMY2QBOqF9iJyOTBOVa93l68GhqvqLT7b/A34QlX/JCKXAW8DXuC/gGhVfdTd7tfAMVWt8B5QEZkCTAFISUkZOnfu3DrFm5OTQ3x8/Q1xLSVFJB1cRvtd79H68GpKxMMB73B2tR/PkZb9m8Qv1mrrREuIKMwhovAIkQWZRBRmElmQiaf4KJ7iPMKLjuEpzsNTfMyd8nw+3fmSAr+HLvLEkRftJT8qmbzoZPKjvO6ns1wQ2Zqc4jA2HylmW1ZJ2bT/2PF/z62jhS4twujaIowu7tQySsqex5CSIjrs/Bddt75OWEkxP3T+MT90vowST+X9SPX976Q5sDqpqCnVyZgxY1aoapq/smB3Ut8NPCMik4DFwE6gVuM1qOosYBZAWlqapqen1ymQjIwM6rpv5cYCD8DBzYQtn02bVa/RZvVSaNkFkns7LYqEdj6fKc5nXHLgL0upQlG+czmmKB+K809cLsrn6+Xr6N+uLRzdD0cPuJ8+87kHQEv8H98TCZFxEBnvTLFxEJni/IKPjDuxLCreWU5oD4kdIbED4dGJxAO1/V8sM7eQdbsyWbcri7W7Mlm7M5N5m49S+jvIGx9Jv/aJjOrh5bqzUhEZC1n3wocP0XXtXLpmfQ7j/1Dpk/KB+XfStFmdVNRc6iSQCWIn0MlnuaO7royq7gIuAxCReODHqnpERHYC6eX2zQhgrIGVdAqc9xic/Wv4Zh5883+QtRN2feV80VKuFSce55Wn5RNITCsoLvD5Eq/iszDvxOXy+xX7/+Xuqz/AWnchMsHpc4lLhtap0GmYMx+XfHx9XLLTUR+dCOHBeRAuMTaCM7t7ObO7t2zd0fwi1u/OYu3OTNbuymLNjiM8+u76slex0qI9XD4bhlwDC+6Bv10BvS6AcY9Dqy5B+TuMaQwCmSCWAT1EJBUnMVwJ/Mx3AxHxAodUtQR4AOeOJoAPgN+KSCt3+UduedMWEQ0Dr3SmUsWFkLMPsvdA9m532nN8+fA2+OFzOHao4vHCo53bait8xjifsUnucum6yOPbeKJ89nHXl1u3Yu1Gho4e5ySAiJiGq6d6FhcVTlrX1qR1dYZGUVWumf0lv12wntE9kumc5N7J1C0dpn4Knz8LH/8enh0Oo+9ybkKw25dNCApYglDVIhG5BefL3gPMVtV1IvIwsFxV5+O0Eh4XEcW5xHSzu+8hEXkEJ8kAPFzaYd3seCIgsYMzVaUwD/IyT0wEAe7HyP4B5416zYyI8LsfD+C8/1nM3X9fzdwppx9/MC88EkbeAf2vgPcfgIWPwqrX4fw/QPdzghu4MQ0soH0QqroAWFBu3W985t8C3qpk39kcb1GYiGhnMvWifcsYpl3cj7v/vprZn37P9aPK3cGU2BF++ips+ggW3At/vQz6TiAu9myndRcR6/Sb2C3MpjKqUFIMWuz01ZW4n1oMJSXH58vKiivv0ys9XmXCPAF59irYndTGBM2Ph3Tg/bW7+cMHG0jv1Ybubfx0iXcf64zc++nTsGQGw4r+D5b7lIdHO4kiIs556C4y7njyKJuPd1omElbJJFWUuRNUv43I8WNRl9al+4VWXAglhU4/VXGRO18IJUU+ZYVl8z137oCsf7gtWqn5JzjH1GLns6TI+eIsnddiJ56yMndeS9wvS63Zp5a487j7VjZp5WWUllFu2ff4x+fTtaRhe03j2sA9G+v9sJYgTMgSEX57WX9+9D+Luevvq3l76hn+Bw0Mj4Kz7oGBV7L+/T/T55ROUJgLBUedyXe+dDlr14llxQV+vnSaqLAI5y41TziERZBUVAzZkTX4subEZXB++YaFO5OUznvKrQ87Ph/mcbcrTZrVJaOwivM1SrR+5ssfAyo9/tZt2+iaesrxfcM87ryn3LKfsiovHVdSFqA+MksQJqS1SYjmkQmncuvrX/HC4i3cPKZ75Ru37MTetun0GZZePyev6hdr6WUHqOGvXJ9fsiUn8Wa/sHDni98T6SaCCHddhLMc5qnwBfZZM7mlsz5tzcigazOoE0sQJuRdNLA976/bw1MffcfZvdvQp12LhjmxiPOrEevHMI2TDcJvDPDIhFNJjIngzjdXU1DUhC//GFOPLEEYA7SOi+TxywawfncWzyys/84+Y5oiSxDGuM7tm8JlQzrwbMZmVm8/EuxwjAk6SxDG+Jh2UT+S46O46++rySs8ic5eY5oBSxDG+EiMieB3lw9g074cnvz3d8EOx5igsgRhTDln9UzmZ8M78+KSLSzf2jxHeDGmJixBGOPHg+f3oWOrGO76+2pyC4qCHY4xQWEJwhg/4qPC+cPlA9l2MJffvfdtsMMxJigsQRhTidO7JTF5RCovf7aNTzcdCHY4xjQ4SxDGVOHecb3o5o3j3rfWkJ1XGOxwjGlQliCMqUJ0hIcZPxnI7sxjPPqv9cEOx5gGFdAEISLjRGSDiGwSkfv9lHcWkUUi8pWIrBGR8931XUXkmIiscqfnAxmnMVUZ0rkVN551Cm8s386qfdZhbUJHwAbrExEP8CxwLrADWCYi81X1G5/NHgLeVNXnRKQvzsuFurplm1V1UKDiM6Y2bh/bg4Xr9/HMV9lsLfmKn5/ehaFdWiEBfqufMcEUyBbEacAmVd2iqgXAXGBCuW0UKB06MxHYFcB4jKmzqHAPcyYP46xO4fxn/T4uf/4zxv9pCa9+vo2cfGtVmOZJtKrX2J3MgUUuB8ap6vXu8tXAcFW9xWebdsCHQCsgDhirqitEpCuwDvgOyAIeUtUllZxnCjAFICUlZejcuXPrFG9OTg7x8X7eKBbCrE4qysnJITw6js93F7FoexHbskqI9sAZ7cM5u3MEnRJCr1vP/p1U1JTqZMyYMStUNc1fWbATxJ1uDH8UkTOAPwOnAhFAvKoeFJGhwDygn6pmVXXOtLQ0Xb58eVWbVCrDXnpSgdVJRb51oqqs2n6Ev37+A/9as4v8ohKGdmnFz0/vzPhT2xEdERrvebB/JxU1pToRkUoTRCB/7uwEOvksd3TX+boOeBNAVT8DogGvquar6kF3/QpgM9AzgLEaU2siwuDOrfjjTwbyxYPn8NAFfTh0tIA73ljNGY//h8cXrGfbwaPBDtOYOgvkG+WWAT1EJBUnMVwJ/KzcNj8A5wBzRKQPToLYLyLJwCFVLRaRbkAPYEsAYzXmpLSMjeT6Ud2YPCKVpZsP8tfPt/HSJ9/zwuItjO6ZzPhT29KjTTzd28TTMjYy2OEaUyMBSxCqWiQitwAf4LxTcbaqrhORh4HlqjofuAt4UUTuwOmwnqSqKiKjgYdFpBAoAaaqqo2aZhq9sDBhZA8vI3t42ZOZx9xlPzD3y+0s/m5/2Tbe+Ci6t4mje5t4uifH071NAj1S4mmTEGV3RZlGJaDvpFbVBTi3rvqu+43P/DfACD/7vQ28HcjYjAm0tonR3D62J7ed3YMdh4+xcV82m/blONP+HP5v1S6y847fAZUQFc4pbiujNHl0ah1L28RoWkSHW/IwDS6gCcIY47QqOifF0jkplnP6pJStV1X2Z+ezaV8OG0sTx74cPv5uP2+t2HHCMWIiPLRLjCalRbTzmRhdttzWXZcUH4UnzJKIqT+WIIwJEhGhTYto2rSI5szu3hPKMnML2bQ/h11HjrEnM489WXlln198f4i9WXkUlZx4B6InTEhJiCIlMZrk+CiS4qNIjo8kKT4Kb3wUSfGReOMj8cZHkRgTYS0SUy1LEMY0QomxEQzt0oqhXVr5LS8pUQ4eLfBJHsfcz3z2ZB1j28FcVv5wmENHCyjxcyd7eJiQFB9JUlwU3oQovHGRJMVH0jI2klaxkbSKjXDm4yJoFRtJYkxEyNy2a46zBGFMExQWJiQnRJGcEEV/EivdrrhEOZxbwMGcAg7k5LtTAQfd+dL1m/flcCAnn/yikkqPFRPhOSFxtHQTSeb+ArZFbnVbKE5rJTk+ihYx1m/S1FmCMKYZ84RJ2Zd2LxKq3T6vsJjDuQUcPlrIkdwCDucWcji3gCO5BRzJLeRwbun6AnYfyXLLCvnn5nUVjhXhEbeF4rZU4p15r7uuVWwkCdERJESHEx8VTnx0OHGR4daP0ohYgjDGlImO8NAuMYZ2iTE13mfhokUMGHam0zrJLuDg0Xz2Z5/YUjmQU8DGvdkcyCmgoLjyVgpAXKSHeDdpnJBA3CSSEB1BYowztYyJIDH2+LJdCqtfliCMMSclTI63Umhb9baqSlZeEQdz8jmcW0BOfjE5eUVk5xWSk19Edl4ROflF5Lif2flF5OQVsjcrz93OWVeVyPCw48nDZ4qPDic2Mpy4SA+xUeHERnqIjfQQFxlObJTzGRflITaytCycyPDQG1vLlyUIY0yDEZGyL+y6Ki5RsvMKyTxWyZR74vKerDw27M3maH4RRwuKKaiin6W8CI8QHxVOXFRpi6a0JRNBfJTHbdk4ySehdLvocDYdLqbtniwn+UR6iIsKJyo8rMn1yViCMMY0KZ4woWVsZJ2HLCksLiG3oJjcgiLnM7+YowVF5BYUcTS/uOzzWGExOflFHHVbNNnu58GjBWw7mFu2fKyw2P+JvjhxAOow4YTWSmyUh9gIn2U3kZT1x0Q5Sad0Ob7cfEMkHEsQxpiQEuEJIzEm7KRaMb6Kiks4ml9Mdn5hWUL59MuVdO/dj6P5ThI6WlB0PBG5n8fc9YeOFrD9UC65BccTkr9bk8sLD5OyZNE+MYY3p55RL3/PCeeo9yMaY0wICfeEkRgbRmLs8YST/X046f3b1el4quq0Xkr7Y3xaMEfd5ey84/M5eUUB6yuxBGGMMY2IiLgd5eG0CXIsod1Fb4wxplKWIIwxxvhlCcIYY4xfAU0QIjJORDaIyCYRud9PeWcRWSQiX4nIGhE536fsAXe/DSJyXiDjNMYYU1HAOqlFxAM8C5wL7ACWich89yVBpR4C3lTV50SkL87Lhbq681cC/YD2wEci0lNVK7nh2BhjTH0LZAviNGCTqm5R1QJgLjCh3DYKtHDnE4Fd7vwEYK6q5qvq98Am93jGGGMaSCATRAdgu8/yDnedr+nAz0VkB07r4dZa7GuMMSaAgv0cxERgjqr+UUTOAF4VkVNrcwARmQJMAUhJSSEjI6NOgeTk5NR53+bK6qQiq5OKrE4qai51EsgEsRPo5LPc0V3n6zpgHICqfiYi0YC3hvvi7jcLmAUgIvvHjBmzrY7xeoEDddy3ubI6qcjqpCKrk4qaUp10qawgkAliGdBDRFJxvtyvBH5WbpsfgHOAOSLSB4gG9gPzgb+JyJM4ndQ9gC+rO6GqJtc1WBFZrqppdd2/ObI6qcjqpCKrk4qaS50ELEGoapGI3AJ8AHiA2aq6TkQeBpar6nzgLuBFEbkDp8N6kqoqsE5E3gS+AYqAm+0OJmOMaVjifB+b5pLx65PVSUVWJxVZnVTUXOrEnqQ+blawA2iErE4qsjqpyOqkomZRJ9aCMMYY45e1IIwxxvhlCcIYY4xfIZ8gqhtQMFSJyFYR+VpEVonI8mDHEwwiMltE9onIWp91rUXk3yKy0f1sFcwYG1oldTJdRHa6/1ZW+Q66GQpEpJM76Og3IrJORH7prm/y/1ZCOkH4DCg4HugLTHQHCjSOMao6qDncjVFHc3Af5PRxP/AfVe0B/MddDiVzqFgnAP/j/lsZpKoLGjimYCsC7lLVvsDpwM3u90iT/7cS0gmCmg0oaEKUqi4GDpVbPQF42Z1/GbikQYMKskrqJKSp6m5VXenOZwPrccaOa/L/VkI9QdiggJVT4EMRWeGOd2UcKaq6253fA6QEM5hG5Bb3nS6zm+KllPoiIl2BwcAXNIN/K6GeIEzlRqrqEJzLbzeLyOhgB9TYuE/9233i8BxwCjAI2A38MbjhBIeIxANvA7erapZvWVP9txLqCaLGgwKGGlXd6X7uA97B3sdRaq+ItANwP/cFOZ6gU9W9qlqsqiXAi4TgvxURicBJDq+p6j/c1U3+30qoJ4iyAQVFJBJnQMH5QY4p6EQkTkQSSueBHwFrq94rZMwHrnXnrwX+L4ixNAqlX4KuSwmxfysiIsCfgfWq+qRPUZP/txLyT1K7t+Q9xfEBBR8LckhBJyLdcFoN4Azo+LdQrBcReR1Ixxm6eS8wDZgHvAl0BrYBP1HVkOm0raRO0nEuLymwFbjR59p7syciI4ElwNdAibv6QZx+iCb9byXkE4Qxxhj/Qv0SkzHGmEpYgjDGGOOXJQhjjDF+WYIwxhjjlyUIY4wxflmCMCFDRFRE/uizfLeITK+H40aJyEfuSKY/Pdnj1fLcW0XE25DnNKHDEoQJJfnAZQH4Qh0M4I5k+kY9H9uYoLEEYUJJEc67gu8oXyAiXUVkoTvg3H9EpLOfbVqLyDx3m89FZICItAH+CgxzWxCnlNvnFBF53x30cImI9HbXzxGR50VkuYh8JyIXuuujReQv7rs4vhKRMe56j4jMEJG17vlv9TnNrSKy0t2n9Phn+byf4avSJ+ONqQ1LECbUPAtcJSKJ5db/L/Cyqg4AXgOe9rPvfwNfuds8CLzijlV1PbDEbUFsLrfPLOBWVR0K3A3M9CnrijNu0QXA8yISDdyMM7Zbf2Ai8LK7foq7/SCfGEsdcAdWfM49B+7nzao6CBgFHKu+aow5kSUIE1LcUTZfAW4rV3QG8Dd3/lVgpJ/dR7plqOpCIElEWlR2Lnd0zzOBv4vIKuAFwHfcojdVtURVNwJbgN7uOf7qnuNbnCEaegJjgRdUtcgt8x2yoXRwuBU4SQTgU+BJEbkNaFm6nzG1YQnChKKngOuAuACfJww44vOmtUGq2senvPw4N3Ud9ybf/SzGGTsLVX0Cp2UTA3xaeunJmNqwBGFCjvvr+02cJFFqKc5ovgBX4Qy+Vt4StwwRSce5tJPlZ7vS82QB34vIFe4+IiIDfTa5QkTC3H6LbsCGcufoiTPQ2wbg38CNIhLulrWu6m8UkVNU9WtV/R3OqMWWIEytWYIwoeqPOCOSlroV+C8RWQNcDfzSzz7TgaHuNk9wfCjnqlwFXCciq4F1nPhK2x+AL4H3gKmqmofTRxEmIl8DbwCTVDUfeMndfo17rJ9Vc97bSzu0gUL3HMbUio3makwQiMgc4F+q+lawYzGmMtaCMMYY45e1IIwxxvhlLQhjjDF+WYIwxhjjlyUIY4wxflmCMMYY45clCGOMMX79P2xmjAMUhuVAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss,label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('No of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Vs No of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvvc3q93L7In"
   },
   "outputs": [],
   "source": [
    "#Generate 1000 random samples from train and val data\n",
    "#Train data\n",
    "train_index = []\n",
    "for i in range(X_train_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_train_padded_docs[i]!=0)>14:\n",
    "        train_index.append(i)\n",
    "train_index = random.sample(train_index,1000)\n",
    "\n",
    "#Validation data\n",
    "#Train data\n",
    "val_index = []\n",
    "for i in range(X_val_padded_docs.shape[0]):\n",
    "    if np.count_nonzero(X_val_padded_docs[i]!=0)>14:\n",
    "        val_index.append(i)\n",
    "val_index = random.sample(val_index,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "4765040db6644918bf8d8d17610d3833",
      "61a2d100efc94eb1ba80b2bc475654b6",
      "a5a73251d1a145708f46fad92d1518d6",
      "6eb8c28131a64099baa192b4491e9fe8",
      "09087bc7ff5c4e7c92b50b9fc1ad3ab0",
      "5a841e55fbb04f0a8441f9815557e842",
      "e1fb58c1987e4cb6b523866d9bfde3e2",
      "18892b9e056b47db90486c5c05fb1094"
     ]
    },
    "colab_type": "code",
    "id": "muqMywldL7Iq",
    "outputId": "8aee9aba-572a-4f63-f5f8-fb3cb49e033c",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4765040db6644918bf8d8d17610d3833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> in issue manage see development review in service not for you set end call that <end> \n",
      "Actual words: <start> day <end> \n",
      "Predicted words: <start> matter <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the of changes look you to you it in our out as this change <end> \n",
      "Actual words: <start> few days <end> \n",
      "Predicted words: <start> few days <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> together with back has provided me further look your have for be www was is <end> \n",
      "Actual words: <start> will work with your schedules <end> \n",
      "Predicted words: <start> what you think <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> me questions if chance you please and to it are them information appropriate on this just removed on <end> \n",
      "Actual words: <start> course <end> \n",
      "Predicted words: <start> this <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> later you they there name you week know you to comments an is this idea to <end> \n",
      "Actual words: <start> asked for yesterday <end> \n",
      "Predicted words: <start> need <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the it then this great on this world on comment that get will us help you <end> \n",
      "Actual words: <start> use <end> \n",
      "Predicted words: <start> use the system <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> more is in input that up we wholesale you all or cost expand <end> \n",
      "Actual words: <start> regarding this item <end> \n",
      "Predicted words: <start> using the list <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> like soon this bonds then not this means site network to generation you one <end> \n",
      "Actual words: <start> customers <end> \n",
      "Predicted words: <start> books <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> hesitate call any attend me please change possible to party or worked yesterday <end> \n",
      "Actual words: <start> and we will fix it that day <end> \n",
      "Predicted words: <start> comments <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> this at not fix soon document call proposal today a determined you hearing this <end> \n",
      "Actual words: <start> plant <end> \n",
      "Predicted words: <start> whole car <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For train data, actual and predicted words\n",
    "train_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_train_padded_docs[train_index,:],y_train_padded_docs[train_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    train_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "57314bd304444fddb34efc5c4785ddef",
      "ebb4942c411049a78ed94f60270cfeb4",
      "628c199ac0124cddadeb0556ccf394c7",
      "35d2359d4d8944f996a6e67d3c11daa2",
      "8061559e609d49c586e773e467916ddc",
      "9dbf5c1ee20f4b1a8a1e6ecf39473f8b",
      "ca4df88be882418b83e4998f3924706e",
      "b8b379f0bb994549a450e107bb22d0c5"
     ]
    },
    "colab_type": "code",
    "id": "o2B9_PCSL7Is",
    "outputId": "bb4d7f2f-75ab-4b72-aaf4-1808e1e27e90"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57314bd304444fddb34efc5c4785ddef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> link know loss complete move to of at you register any as this bad clearly <end> \n",
      "Actual words: <start> when you check out <end> \n",
      "Predicted words: <start> and let me know if you have any questions <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> service is each give comments to tomorrow when what number not in coming are possible can is as <end> \n",
      "Actual words: <start> town <end> \n",
      "Predicted words: <start> the office <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the process that back on to but it support then know today to hold this <end> \n",
      "Actual words: <start> group <end> \n",
      "Predicted words: <start> link below <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the needed look that and get it always them sure a will we make <end> \n",
      "Actual words: <start> than happy to answer them <end> \n",
      "Predicted words: <start> than happy to discuss <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> link know loss complete move to of at you register any as this bad clearly today to too <end> \n",
      "Actual words: <start> out <end> \n",
      "Predicted words: <start> it <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> this going now this than with by you we received not website reports your helps <end> \n",
      "Actual words: <start> its corporate growth <end> \n",
      "Predicted words: <start> its technology and for marketing <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> and to tomorrow me about for or around list there that a let changes <end> \n",
      "Actual words: <start> this to the banks <end> \n",
      "Predicted words: <start> out to me <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the volume do very find appears your can soon by you about to in <end> \n",
      "Actual words: <start> call <end> \n",
      "Predicted words: <start> call <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the discuss that so addition of we opinion doing database your our from you <end> \n",
      "Actual words: <start> hearing from you <end> \n",
      "Predicted words: <start> your feedback <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <start> the volume you her find appears your attached head if you during was might information <end> \n",
      "Actual words: <start> the other <end> \n",
      "Predicted words: <start> if you want to go <end> \n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For validation data actual and predicted words\n",
    "val_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(X_val_padded_docs[val_index,:],y_val_padded_docs[val_index,:])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(model,i,j)\n",
    "    val_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%100==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "EvU7rH7IL7Iy",
    "outputId": "f30ad2c9-7a55-49a6-dfb2-e72e58d1ee0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for train data of 1000 samples: 0.7\n",
      "BLEU Score for validation data of 1000 samples: 0.694\n"
     ]
    }
   ],
   "source": [
    "#Average BLEU Score for sentences\n",
    "print('BLEU Score for train data of 1000 samples:',np.round(sum(train_bleu_list)/len(train_bleu_list),3))\n",
    "print('BLEU Score for validation data of 1000 samples:',np.round(sum(val_bleu_list)/len(val_bleu_list),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xqdMoy5cuFl"
   },
   "source": [
    "<h1>4. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgjJobuUcuFl"
   },
   "outputs": [],
   "source": [
    "def predict_sentence(enc_dec_model,input_sentence):\n",
    "    \n",
    "    #Maximum sequence length for input and target sentence\n",
    "    inp_max_length = X_train_padded_docs.shape[1]\n",
    "    out_max_length = y_train_padded_docs.shape[1]\n",
    "    \n",
    "    #Attention plot\n",
    "    attention_plot = np.zeros((inp_max_length,out_max_length))\n",
    "    \n",
    "    input_sentence = '<start> ' + input_sentence + ' <end>'\n",
    "    \n",
    "    #Convert texts to sequences\n",
    "    sent = inp_tokenizer.texts_to_sequences([input_sentence])\n",
    "    #Pad data\n",
    "    sent = tf.keras.preprocessing.sequence.pad_sequences(sent,maxlen=inp_max_length,padding='post')\n",
    "    \n",
    "    #print('Encoder input shape (batch_size,sequence length):',sent.shape)\n",
    "    enc_outputs,enc_hidden,enc_cell = enc_dec_model.layers[0](sent)\n",
    "    #print('Encoder output shape (batch_size,sequence lengths,units):',enc_outputs.shape)\n",
    "    #print('Encoder hidden state shape (batch_size,units):',enc_hidden.shape)\n",
    "    #print('Encoder cell state shape (batch_size,units):',enc_cell.shape)\n",
    "    #print(90*'-')\n",
    "    \n",
    "    #Boundary case\n",
    "    dec_input = tf.expand_dims([out_tokenizer.word_index['<start>']], 1)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    #print('Decoder input shape (batch_size,1):',dec_input.shape)\n",
    "    #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "    #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    output_sent = ''\n",
    "    \n",
    "    for i in range(out_max_length-1):\n",
    "        #Get prediction from onestep_decoder\n",
    "        dec_output,dec_hidden,dec_cell,attention_weights = enc_dec_model.layers[1].onestep_decoder(dec_input,dec_hidden,\n",
    "                                                                                               dec_cell,enc_outputs)\n",
    "        #print('Decoder output shape (batch_size,vocab_size):',dec_output.shape)\n",
    "        #print('Decoder hidden state shape (batch_size,units):',dec_hidden.shape)\n",
    "        #print('Decoder cell state shape (batch_size,units):',dec_cell.shape)\n",
    "    \n",
    "        #Storing attention weights\n",
    "        attention_weights = tf.reshape(attention_weights,(-1,))\n",
    "        attention_plot[i] = attention_weights.numpy()\n",
    "        \n",
    "        #Extract predicted id from decoder output\n",
    "        key = tf.argmax(dec_output[0]).numpy()\n",
    "        #Get word corresponding to index\n",
    "        output_sent+=out_tokenizer.index_word[key]+' '\n",
    "        \n",
    "        if out_tokenizer.index_word[key] == '<end>':\n",
    "            return output_sent,input_sentence,attention_plot\n",
    "        \n",
    "        #Make current decoder output as decoder input for next time step\n",
    "        dec_input = tf.expand_dims([key], 0)\n",
    "    \n",
    "    return output_sent,input_sentence,attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmtMX13TcuFn"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/nmt_with_attention#write_the_encoder_and_decoder_model\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcbDDFYHcuFp"
   },
   "outputs": [],
   "source": [
    "def generate_sentence(enc_dec_model,input_sentence):\n",
    "    #Get prediction from model\n",
    "    result,sentence,attention_plot = predict_sentence(enc_dec_model,input_sentence)\n",
    "    print('Input sentence:',sentence)\n",
    "    print('Predicted words:',result)\n",
    "    #Plot Attention plots\n",
    "    attention_plot = attention_plot[:len(result.split()),:len(sentence.split())]\n",
    "    plot_attention(attention_plot, sentence.split(), result.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "GtnPdEIjcuFr",
    "outputId": "029b6cd0-df7b-4b78-c0b1-6ced7b025c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> thank you <end>\n",
      "Predicted words: for your time and consideration <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'thank you'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "U_HUiAXnL7KI",
    "outputId": "bc9d7140-9717-44f5-9863-d4a24fa363f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> hope it <end>\n",
      "Predicted words: is going well <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'hope it'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "PrX2R0r1L7KL",
    "outputId": "77b25374-ba6f-4071-8aee-5c30c979eb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> can you <end>\n",
      "Predicted words: please let me know if you have any questions or need additional information <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'can you'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "PPj-5vWUMEVJ",
    "outputId": "16754ee7-0b5b-4afd-c9d1-1ba12dc87468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> give me <end>\n",
      "Predicted words: a call if you have any questions or need any further information <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'give me'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "xiXj890_MEVO",
    "outputId": "fdfead52-26e7-48ea-a2ab-065f115a7870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <start> are you <end>\n",
      "Predicted words: doing this <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAEiCAYAAACxy7qgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVX0lEQVR4nO3de7hkVX3m8e9Lt41cFIygoBFFIxHvYouiRnEw0aDRKOZilIs4kBiv4xhHkzE6o0iMrQmjeRIwSot4DRMGlaiDF4SgBpEYJToCIhpEAjgodIPN7Zc/9u6krD6n6W7OWauO5/t5nn5O1V67dv1q96n3rFp77V2pKiRJ7WzXuwBJWm4MXklqzOCVpMYMXklqzOCVpMYMXklqzOCVpMYMXklqzOCVpMYMXklqzOCdAUnun+SzSR7SuxZJi8/gnQ2HAwcCR3auQ1ID8SI5fSUJcClwBvBrwD2q6pauRUlaVPZ4+zsQuBPwMuBm4OCu1UhadAZvf4cDp1TV9cCHxvuSfoY51NBRkp2AHwBPq6qzkzwc+CKwZ1X9qG91khaLPd6+DgGurqqzAarqq8BFwG93rUpagpLslOSwJLv0ruW2GLx9HQqcPLXsZOCI9qVIS95vAicyvK9mmkMNnSS5F/AdYN+qumhi+c8zzHJ4YFVd2Kk8aclJ8jng7sD1VbW6dz2bY/BKWvKS3Ae4ENgf+BKwX1V9o2dNm+NQQ0dJ9hrn8c7Z1roeaQk7FDh7PE7yd8z47CCDt6/vALtPL0xy17FN0pY5DHjfePv9wPPm69TMAoO3rwBzjfXsDPykcS3SkpTkscCewCnjoo8BOwJP7lbUbVjZu4DlKMn/Gm8WcGyS6yeaVzCMU321eWHS0nQ4cFpVrQOoqhuTfIRhdtAZPQubj8Hbx8arkAXYF7hxou1G4HxgTeuipKUmyfYM08ieO9V0MvCpJDtvDORZ4qyGTsbxp48AR1bVdb3rkZaiJLsxXN/k5Kq6dart+cCnq+qKLsVthsHbSZIVDOO4D5vlaS+SFp4H1zoZL/34XWBV71oktWWPt6MkhzOMTT2/qq7uXY+0VCT5DnPPCNpEVd13kcvZah5c6+tVwN7A95NcBqyfbKyqh3apSpp975y4vTPwSuBchqv7ARzAMDvobY3r2iIGb1+n3PYqkqZV1b8HapK1wFuq6s2T6yR5LfCgxqVtEYcaJC1pSa5luDbDxVPLfwE4v6ru3Key+XlwTdJSt57hK7SmHQhcP8fy7hxq6CjJKuCPGA6w7QXcYbK9qlb0qEtaYv4M+IskqxmuTAbwGIYz2t7Qq6jNMXj7eiPwW8CxDL88fwDch+EbKF7Xryxp6aiqP01yKfByhrPYAL4JHF5VH+lW2GY4xtvROCXmRVX1ySTXAQ+vqm8neRFwUFU9p3OJkhaBPd6+7g5sPGttHbDrePuTwFu6VCQtYUl2ZerYVVX9/07lzMuDa319D7jHePti4Cnj7QOAG7pUJC0xSe6d5BNJbgB+CFw1/rt6/Dlz7PH2dSpwEMMBgeOADyY5Crgn8NaehUlLyIkMnxZfCFzOFp7R1pNjvDMkyaOBxwEXVtXHe9ej2ZHklZtrr6q3t6pl1iRZBzymqi7oXcuWMng7SvIE4AtVdfPU8pXAY6vqrD6VadaMB2In3YHhWxduAK6cxesRtJLk68ARVfWV3rVsKYO3oyS3AHtW1ZVTy+/K8GZyHq/mleTuDB+z31VVp/aup5ck/wl4DfD702evzSqDt6MktwJ3r6qrppbvA5w3i6c6tpLk94EXM1xE6MFVdUmS1wCXzOrczB6SPAL4SFXdv3ctvYxTMbdn+NqsDcBPfYKcxfeRB9c6SPLR8WYBJyfZMNG8Angw8IXmhc2IJK8AXs0wpe5PJpq+D7yE4Zs7NNiOYVricvaS3gVsLYO3jx+OPwNcw09PHbsR+HvgXa2LmiG/BxxVVacnedPE8vOZ0atNLbYkz55exDDG+2Lg7PYVzY6qem/vGraWwdtBVb0AYDzNcU1Vrd/8I5adewNzHaG+CdihcS2zYvoSosUwR/WzwH9tX85sGce7DwXuB7yuqq5O8jjg8qqaPjDZncHb1xsn7yTZA3g68I2qWrZDDcAlwH4MX4006WD+40y/ZaWqPNlpHkkeCXwG+A7DJ6K3Mpw88cvAPsDv9Ktubv5n9nU68FKAJDsD5zH80nw+yWE9C+tsDfDOJM9j+Eh9QJLXA8fgiSXa1BrguKp6BMPBtY0+xTAvfuYYvH2tZvioCPBs4FrgbsBRDF8LtCxV1YkMl/N7M7Aj8D6GffKyqvpwx9K6SvK0JGcluTrJVUk+n+Tg3nXNgEcCc43z/oAZPfBo8Pa1M/Cj8favAKdW1U0MYXy/blV1lGTlOJXs9Kq6N8Mfoj2q6uer6t2dy+smyX9mOMX828B/Y5i3+h3g1CRH9qxtBtwA3GWO5Q8ArpxjeXfO4+0oybeA1wMfAy4FfqOqzkzycOCMqtq9Z329JFkPPLCqpsd4l60kFzF8nH7n1PKXAi+tqn36VNZfkhOAPYDfYBjbfSjDwcfTgM9W1X/pWN6c7PH29XaGj9GXMcxR3XiK8BOAr/cqagZ8ieHjo/7DXgyXC532CYZZIMvZq4CfY5jlsSPDdMyLgR8D/71jXfNyVkNHVXV8kvMY3lRnVNWtY9O3Wd7fQPEuYE2SvYCvsOnX3p/fpaq+vsdwlH76lNhfYdPZH8tKVV0LPH48dXg/hg7l+VX16b6Vzc+hhk6S7AI8tKo2mfw+zj/8RlVd076y/sZTqedTy/EaFkl+F3gHw0GkjVMNH8cwd/WlVXVCr9p6WqrvI4O3kyR3Yjjq+pSqOmdi+cOAc4F7VtXVverrKclmPzov17HfJM9iOFli33HRN4G3VtVp/arqa6m+jxxq6KSqrktyGnAYcM5E06HAp2bxl6WVqvrueGnM/RmGYVZNNjOMiy8rSf4P8NfAEyaGpJa9pfo+ssfbUZKnAB9kmC51Y5LtGA60vaSq/rZvdf0keQDDTI+9GU6guIWhk3ATsGEWrza12JK8H/h1hgNGa4H3LJVLIC62pfg+clZDX2cwzEF8+nj/IIbe3ce6VTQb/pzhoNouwPUMH61XA18FDulYVzdV9TyGi+K8EXgycOF4MsVhSZbr9Ss2WnLvI4O3o/Ej48kMH5Ng+Hj04fEkiuXsUcCbxosH3QqsHGcyvBp4W9fKOqqqa6vqL6tqf+AhDH+cjgd+kOT4JPtufgs/m5bi+8jg7e8k4Knj1KlnMfepj8tNGHq6MMzNvOd4+zLgF7pUNEOS3AN4JkMP72bgfwP3Ar6WZLmear6k3keO8c6AcS7vDcBuVbUsey2TkpwF/FlVnZrkA8BdGa7bcBTD1KGHdi2wgyR3YAjbIxnm8/4jw3znD1bVunGdZwAnVdWu3QrtaCm9j+zxzoaTGOZkntS7kBlxDEOvF4Yzj/YCPsdwssDLehXV2Q8YhhW+DTyyqvavqndtDN3RWQwX1l+ulsz7yB7vDEjycwyXhzy+qq7oXc8sGvfRNbVMf2GTHAr8TVX9pHcts2opvY8MXklqzKEGSWrM4JWkxgzeGZLk6N41zCL3y6bcJ3NbKvvF4J0tS+KXpgP3y6bcJ3NbEvvF4JWkxpb9rIZVK3aoHVbMxjVXbrz1BlZtNxun3W/YfdVtr9TILevXs2KnnXqXwaofrL/tlRq5qTZwh2zfu4zBDEXITWzgDszGfrmOa66e7+u7lv1lIXdYcWceu8dze5cxcy7+vb16lzBz9n7Dl3uXMJPq5pt7lzCTPl2nzHvdaIcaJKkxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGjN4Jakxg1eSGmsSvEk+nmTtFq57YJJKstsilyVJXcxij/cLwJ7AD3sXIkmLYWXvAqZV1Y3AFb3rkKTFsuA93iQ7JlmbZF2Sf03yh1Ptd0ny3iTXJLkhyaeTPGii/aeGGpIcMW7roCQXJFmf5HNJ9p7a7mvH51uX5KQkr09y6UK/Pkm6vRZjqGEN8MvAIcBBwCOAJ0y0rwUeDTwT2B+4Hvhkkh02s83tgdcCRwIHALsCf7WxMclvA68H/gjYD/gm8MoFeTWStMAWdKghyc7AC4Ejq+pT47IXAJeNt+8PPAN4YlWdNS47FPge8DzgrzdT54ur6lvjY9YA70mSqirg5cDaqtr4+GOTPAnYZ546jwaOBrjjijvdvhctSVtpoXu89wNWAV/cuKCq1gFfH+/uC9w61f7jsf2Bm9nuho2hO7p8fJ67jPcfAJw79Zh/mG9jVXVCVa2uqtWrtttcR1uSFt4szWqozbTdPM+6s1S/JG2RhQ6ubwM3AY/ZuCDJTsCDx7vfHJ/zgIn2OwMPAb5xO573/wGPmlq2/+3YniQtmgUd462qdUneDbwlyVUMQwJ/DKwY2y9Kchpw/DjO+iPgGOBa4AO346mPA05M8mXgbOBZDAfwrrkd25SkRbEY83hfBewEnMowY+Ed4/2NXgD8OfBR4I7AOcBTq+qGbX3CqvpQkvsCfwLsCPwtw6yHZ27rNiVpsSx48FbVeuCw8d9c7dcAh2/m8WcCmbi/lmEK2rzrjMveDLx54/0kpwIXb131krT4Zu7MtW2RZEfgRcAnGQ7EHcLQ2z2kZ12SNJefieBlmOXwq8AfAjsAFwHPr6pTu1YlSXP4mQjecXz4yb3rkKQt4TxYSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxlb2LqC3Dbuv4uLf3at3GTPn/o+/tHcJM+emW27pXcJs2m5F7wpm02Z+XezxSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNWbwSlJjBq8kNTaTwZvkwCSVZLfbs44kzaKZCN4kZyZ551Y+7AvAnsAPF6EkSVo0K3sXsK2q6kbgit51SNLW6t7jTbIWeCLw4nHooID7jM0PS/IPSa5Pcl6S/SYe91NDDUl2SfK+JFcm+UmSS5K8ovXrkaTb0j14gZcDXwROZBg62BP4l7HtWOA1wH4MQwrvT5J5tvMm4CHA04FfBI4Evr94ZUvStuk+1FBVP05yI3B9VV0BkOQBY/Prqupz47L/Cfw9cE/gsjk2dW/g/Ko6d7z/3fmeM8nRwNEAK3e5y4K8DknaUrPQ492cr03cvnz8ebd51v1L4LeS/FOSNUmeON9Gq+qEqlpdVatX7LTTQtUqSVtk1oP3ponbNf6cs+aq+gRDr3cNsBtwepITF7c8Sdp6sxK8NwIrbu9GqurqqnpfVR0BvBA4PMn2t3e7krSQuo/xji4F9k9yH2Ad2/AHYRwDPh/4Z4bX9WzgkqrasGBVStICmJUe7xqGXu83gKuAvbZhGxuAY4B/As4B7gT82kIVKEkLZSZ6vFV1IXDA1OK1U+tcCmTi/plT949hCF5Jmmmz0uOVpGXD4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWrM4JWkxgxeSWpsZe8CetvuZtjhyvQuY+Z8fJ9P9C5h5jztHgf3LmE2bWf/bU7fm7/JPSZJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjRm8ktSYwStJjS2Z4E3yqiSX9q5Dkm6vJRO8kvSzYkGCN8mdk+y6ENvaiufcPckdWz6nJC2EbQ7eJCuSPCXJB4ArgIeNy3dJckKSK5Ncl+TzSVZPPO6IJOuSHJTkgiTrk3wuyd5T2391kivGdU8Cdp4q4WDgivG5Hretr0OSWtvq4E3yoCR/CvwL8GFgPfBU4KwkAU4H7gk8HXgEcBbw2SR7Tmxme+C1wJHAAcCuwF9NPMdvAm8CXg/sB3wLeOVUKe8Hfge4E3BGkouT/PF0gEvSrNmi4E1y1yQvS/IV4B+BBwAvB/aoqqOq6qyqKuBJwMOB51TVuVV1cVW9DrgEOHRikyuBF4/rfA1YAxw4BjfAK4D3VtXxVXVhVR0DnDtZU1XdXFV/V1XPBfYA3jw+/0VJzkxyZJLpXvLG13N0kvOSnHfzDeu3ZBdI0oLZ0h7vS4HjgJ8A+1TVM6rqb6rqJ1PrPRLYEbhqHCJYl2Qd8GDgfhPrbaiqb03cvxxYBdxlvL8v8MWpbU/f/3dVdW1VvaeqngQ8Crg78G7gOfOsf0JVra6q1St32GkzL1uSFt7KLVzvBOAm4DDggiSnAu8DPlNVt0ystx3wr8AvzbGNaydu3zzVVhOP32pJtmcY2ng+w9jvPzP0mk/blu1J0mLaoqCrqsur6piq+kXgycA64EPAZUneluTh46rnM/Q2bx2HGSb/XbkVdX0TeMzUsp+6n8HjkxzPcHDvHcDFwCOrar+qOq6qrtmK55SkJra6h1lVX6qqFwF7MgxB7AN8OckvAZ8GzgFOS/KrSfZOckCS/zG2b6njgMOTHJXk/kleCzx6ap3nA/8XuDPwXOBeVfUHVXXB1r4mSWppS4caNlFVG4BTgFOS3A24paoqycEMMxLeBdyNYejhHOCkrdj2h5PcFziGYcz4o8DbgSMmVvsMw8G9azfdgiTNrm0O3kmTwwhVdR3DjIeXz7PuWmDt1LIzgUwtOxY4durhb5hov3zbK5akfjxlWJIaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqTGDV5IaM3glqbFUVe8aukpyFfDd3nWMdgOu7l3EDHK/bMp9MrdZ2i/3rqrd52pY9sE7S5KcV1Wre9cxa9wvm3KfzG2p7BeHGiSpMYNXkhozeGfLCb0LmFHul025T+a2JPaLY7yS1Jg9XklqzOCVpMYMXklqzOCVpMYMXklq7N8AyHDn+vH77bcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = 'are you'\n",
    "generate_sentence(model,input_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>GPT2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "LLmL58s7BBD3",
    "outputId": "4bbdcba0-190e-4e66-8ac4-4dc761faddc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "%tensorflow_version 1.x\n",
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "fSh9A6BeBB-U",
    "outputId": "70c55f0a-b171-4fca-99e8-9a1835fbdfb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 366Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 83.7Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 335Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:03, 140Mit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 208Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 169Mit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 145Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "#Load GPt2 model\n",
    "gpt2.download_gpt2(model_name=\"124M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "GGBPRLwDCPcv",
    "outputId": "1b2e1d15-f2e9-4c15-c609-5d1564355020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Mount Google Drive\n",
    "gpt2.mount_gdrive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>(Refer GPT2 Word Featurization Section 1 of 2_Data_Preparation.ipynb)</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdnwAYI9BCEu"
   },
   "outputs": [],
   "source": [
    "#Dataset\n",
    "file_name = \"train_preprocessed_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "99sQURrUBCJV",
    "outputId": "ff1f1e19-b89c-4cd1-8184-15a56e8d2f69",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 1000868 tokens\n",
      "Training...\n",
      "[10 | 18.77] loss=1.31 avg=1.31\n",
      "[20 | 31.39] loss=1.20 avg=1.26\n",
      "[30 | 44.02] loss=1.18 avg=1.23\n",
      "[40 | 56.71] loss=1.17 avg=1.21\n",
      "[50 | 69.42] loss=1.16 avg=1.20\n",
      "======== SAMPLE 1 ========\n",
      "endoftext|>\n",
      "<|startoftext|>if it is not then it does not really fit<|endoftext|>\n",
      "<|startoftext|>see your calendar<|endoftext|>\n",
      "<|startoftext|>just let me know if there are any problems<|endoftext|>\n",
      "<|startoftext|>if you have anything else do not hesitate to let us know<|endoftext|>\n",
      "<|startoftext|>please get the details in before you send them out<|endoftext|>\n",
      "<|startoftext|>this will be a nice change of pace<|endoftext|>\n",
      "<|startoftext|>thanks for your help<|endoftext|>\n",
      "<|startoftext|>please let me know if you would like him in this meeting<|endoftext|>\n",
      "<|startoftext|>see if you can get me a copy<|endoftext|>\n",
      "<|startoftext|>if you want this to work for you then please let me know<|endoftext|>\n",
      "<|startoftext|>you will have to ask for a signature on your records<|endoftext|>\n",
      "<|startoftext|>if you have any questions or need anything else add me<|endoftext|>\n",
      "<|startoftext|>i have been working here for several weeks<|endoftext|>\n",
      "<|startoftext|>no further changes were offered on this matter<|endoftext|>\n",
      "<|startoftext|>i got up next afternoon<|endoftext|>\n",
      "<|startoftext|>i am happy to talk with you all<|endoftext|>\n",
      "<|startoftext|>we are here now<|endoftext|>\n",
      "<|startoftext|>we will send that out to you<|endoftext|>\n",
      "<|startoftext|>please let me know if there is any additional info needed<|endoftext|>\n",
      "<|startoftext|>here we go<|endoftext|>\n",
      "<|startoftext|>i am still working on it<|endoftext|>\n",
      "<|startoftext|>i was able to call him this afternoon<|endoftext|>\n",
      "<|startoftext|>hope to see you all in a long time<|endoftext|>\n",
      "<|startoftext|>i still love it here<|endoftext|>\n",
      "<|startoftext|>please let me know when you plan on sending anything<|endoftext|>\n",
      "<|startoftext|>i will let a voice count as you wish<|endoftext|>\n",
      "<|startoftext|>if we do not we all get to give each other credit<|endoftext|>\n",
      "<|startoftext|>i am still planning on going through this again<|endoftext|>\n",
      "<|startoftext|>i told you we would discuss it<|endoftext|>\n",
      "<|startoftext|>will give you a few more minutes<|endoftext|>\n",
      "<|startoftext|>please do not hesitate to contact me with any questions<|endoftext|>\n",
      "<|startoftext|>i will pass on more details to you soon<|endoftext|>\n",
      "<|startoftext|>as we look forward this is the final document<|endoftext|>\n",
      "<|startoftext|>please send out this message as soon as you can<|endoftext|>\n",
      "<|startoftext|>it would be nice but it would be hard to get that done<|endoftext|>\n",
      "<|startoftext|>i am a little too busy<|endoftext|>\n",
      "<|startoftext|>if you have a minute please let me know<|endoftext|>\n",
      "<|startoftext|>you should have them in the database<|endoftext|>\n",
      "<|startoftext|>thanks for your help yesterday<|endoftext|>\n",
      "<|startoftext|>i could not attend the press conference<|endoftext|>\n",
      "<|startoftext|>please let me know as soon as you can when this is not possible at the end of the month<|endoftext|>\n",
      "<|startoftext|>i will let them know<|endoftext|>\n",
      "<|startoftext|>but no<|endoftext|>\n",
      "<|startoftext|>this should take a little while\n",
      "\n",
      "[60 | 94.79] loss=1.14 avg=1.19\n",
      "[70 | 107.45] loss=1.16 avg=1.19\n",
      "[80 | 120.12] loss=1.18 avg=1.19\n",
      "[90 | 132.74] loss=1.14 avg=1.18\n",
      "[100 | 145.35] loss=1.17 avg=1.18\n",
      "======== SAMPLE 1 ========\n",
      "startstart>but it does not matter<|endoftext|>\n",
      "<|startoftext|>it would work if you could put all the same questions in the next step<|endoftext|>\n",
      "<|startoftext|>that will change<|endoftext|>\n",
      "<|startoftext|>i will let you know<|endoftext|>\n",
      "<|startoftext|>he should be fine at that point<|endoftext|>\n",
      "<|startoftext|>i think it should be in the format below<|endoftext|>\n",
      "<|startoftext|>if so we would really appreciate your help<|endoftext|>\n",
      "<|startoftext|>we would love to see it<|endoftext|>\n",
      "<|startoftext|>hope all is well<|endoftext|>\n",
      "<|startoftext|>please call on the telephone if any further information is needed<|endoftext|>\n",
      "<|startoftext|>there was no time in the world to plan<|endoftext|>\n",
      "<|startoftext|>you will be able to tell a story about it and give him an opinion<|endoftext|>\n",
      "<|startoftext|>i am unable to find any other material that would allow me to have any access at the moment<|endoftext|>\n",
      "<|startoftext|>i will see you soon<|endoftext|>\n",
      "<|startoftext|>we appreciate your cooperation<|endoftext|>\n",
      "<|startoftext|>as soon as we have the chance and have agreed we will send them out on a quick basis<|endoftext|>\n",
      "<|startoftext|>he did not see it<|endoftext|>\n",
      "<|startoftext|>this is the third year in a row my name is on the list<|endoftext|>\n",
      "<|startoftext|>i would also like to hear more on the other two<|endoftext|>\n",
      "<|startoftext|>if those are available at your convenience do not hesitate to call if you want to have further discussions<|endoftext|>\n",
      "<|startoftext|>it is only through good and true that we are successful<|endoftext|>\n",
      "<|startoftext|>please call any of your staff at your earliest convenience<|endoftext|>\n",
      "<|startoftext|>we are hoping we can help him find his own house<|endoftext|>\n",
      "<|startoftext|>i will also need to review the schedules<|endoftext|>\n",
      "<|startoftext|>if there are any problems just let me know<|endoftext|>\n",
      "<|startoftext|>i will try to follow up on this<|endoftext|>\n",
      "<|startoftext|>i have received that for the last two years<|endoftext|>\n",
      "<|startoftext|>i had no idea<|endoftext|>\n",
      "<|startoftext|>attached is a link to his resume<|endoftext|>\n",
      "<|startoftext|>i have a couple of questions on the above<|endoftext|>\n",
      "<|startoftext|>these are not the only ones<|endoftext|>\n",
      "<|startoftext|>this means that there could be no further issues<|endoftext|>\n",
      "<|startoftext|>i do not really know what that means<|endoftext|>\n",
      "<|startoftext|>however if you would like to see me listed on the above page let me know<|endoftext|>\n",
      "<|startoftext|>she said that they were happy to participate<|endoftext|>\n",
      "<|startoftext|>i know that you want to have both documents signed and that it is best to do that<|endoftext|>\n",
      "<|startoftext|>i was never able to make any kind of purchase<|endoftext|>\n",
      "<|startoftext|>we need to talk a little bit more about that<|endoftext|>\n",
      "<|startoftext|>for the latest information regarding the program please visit www<|endoftext|>\n",
      "<|startoftext|>i am looking to see if that works<|endoftext|>\n",
      "<|startoftext|>let me know if there is any work you can do<|endoftext|>\n",
      "<|startoftext|>it was a very fun weekend<|endof\n",
      "\n",
      "[110 | 169.46] loss=1.13 avg=1.18\n",
      "[120 | 182.06] loss=1.11 avg=1.17\n",
      "[130 | 194.75] loss=1.12 avg=1.17\n",
      "[140 | 207.39] loss=1.09 avg=1.16\n",
      "[150 | 220.00] loss=1.13 avg=1.16\n",
      "======== SAMPLE 1 ========\n",
      "<|startoftext|>please update with any revisions you may have<|endoftext|>\n",
      "<|startoftext|>thanks so much for this<|endoftext|>\n",
      "<|startoftext|>they will take several weeks off the rest of the season to keep this going<|endoftext|>\n",
      "<|startoftext|>this letter will be released when there is not enough time on the calendar<|endoftext|>\n",
      "<|startoftext|>i have heard that he never made the trip<|endoftext|>\n",
      "<|startoftext|>thank you for your help and assistance<|endoftext|>\n",
      "<|startoftext|>will keep you posted on the developments<|endoftext|>\n",
      "<|startoftext|>you should have it now<|endoftext|>\n",
      "<|startoftext|>the new rules do require that a person be an individual of least legal size<|endoftext|>\n",
      "<|startoftext|>i have forwarded him a list of changes<|endoftext|>\n",
      "<|startoftext|>here is the current version<|endoftext|>\n",
      "<|startoftext|>please let me know if you want to discuss these changes<|endoftext|>\n",
      "<|startoftext|>that seems to be the reason for the problem<|endoftext|>\n",
      "<|startoftext|>if not let is discuss these issues in the meeting<|endoftext|>\n",
      "<|startoftext|>thanks so much for your time during this very difficult period of time<|endoftext|>\n",
      "<|startoftext|>it was very good to hear from you<|endoftext|>\n",
      "<|startoftext|>thanks for your feedback and help<|endoftext|>\n",
      "<|startoftext|>the best way to know is to be in my mind<|endoftext|>\n",
      "<|startoftext|>let me know if you would like the file attached<|endoftext|>\n",
      "<|startoftext|>thanks so much for your kind touch<|endoftext|>\n",
      "<|startoftext|>if you would like to discuss or anything else please let me know<|endoftext|>\n",
      "<|startoftext|>the company will use the funds for sales and marketing<|endoftext|>\n",
      "<|startoftext|>we are going to be there<|endoftext|>\n",
      "<|startoftext|>i may need to talk to her again<|endoftext|>\n",
      "<|startoftext|>please review your comments regarding the previous revisions<|endoftext|>\n",
      "<|startoftext|>therefore it is your responsibility to send asap to the appropriate party<|endoftext|>\n",
      "<|startoftext|>thank you for your continued support and support of the organization<|endoftext|>\n",
      "<|startoftext|>this is a complete document<|endoftext|>\n",
      "<|startoftext|>please forward to me at the email address included below and let me know that it is acceptable<|endoftext|>\n",
      "<|startoftext|>the company confirmed the news on its web site<|endoftext|>\n",
      "<|startoftext|>we will keep you up to date with new research as well<|endoftext|>\n",
      "<|startoftext|>the company says the following in the attached memo to be filed<|endoftext|>\n",
      "<|startoftext|>a little about us<|endoftext|>\n",
      "<|startoftext|>i hope all is well today for the kids on your team<|endoftext|>\n",
      "<|startoftext|>they have an opportunity to win if they make the right move<|endoftext|>\n",
      "<|startoftext|>you said in your letter<|endoftext|>\n",
      "<|startoftext|>the company will use the funds for sales and marketing<|endoftext|>\n",
      "<|startoftext|>a copy of the registration is attached<|endoftext|>\n",
      "<|startoftext|>so here are today is the results<|endoftext|>\n",
      "<|startoftext|>these are all deals we have not executed in some form<|endoftext|>\n",
      "<|startoftext|>please review and advise of changes if necessary<|endoftext|>\n",
      "<|startoftext|>i would like to see the changes for each product<|endoftext|>\n",
      "\n",
      "[160 | 243.97] loss=1.11 avg=1.15\n",
      "[170 | 256.64] loss=1.14 avg=1.15\n",
      "[180 | 269.29] loss=1.18 avg=1.15\n",
      "[190 | 281.91] loss=1.17 avg=1.16\n",
      "[200 | 294.51] loss=1.12 avg=1.15\n",
      "======== SAMPLE 1 ========\n",
      "text|>\n",
      "<|startoftext|>that is all<|endoftext|>\n",
      "<|startoftext|>this sounds like fun<|endoftext|>\n",
      "<|startoftext|>you are still here<|endoftext|>\n",
      "<|startoftext|>what a difference that makes<|endoftext|>\n",
      "<|startoftext|>please give me a call when you get back<|endoftext|>\n",
      "<|startoftext|>i look forward to seeing all of you and you are our true friends in the future<|endoftext|>\n",
      "<|startoftext|>that was always our idea<|endoftext|>\n",
      "<|startoftext|>we are going forward<|endoftext|>\n",
      "<|startoftext|>that would be very good<|endoftext|>\n",
      "<|startoftext|>please check out our site www<|endoftext|>\n",
      "<|startoftext|>if you have any questions or need additional information please please give me a call<|endoftext|>\n",
      "<|startoftext|>it would be a nice addition<|endoftext|>\n",
      "<|startoftext|>please send back back a draft<|endoftext|>\n",
      "<|startoftext|>i hope you both are having a good time<|endoftext|>\n",
      "<|startoftext|>please let me know if your working on your schedule<|endoftext|>\n",
      "<|startoftext|>please review and let us know if we need any additional information<|endoftext|>\n",
      "<|startoftext|>if you want me to make another change please just forward this to me<|endoftext|>\n",
      "<|startoftext|>attached is a list of the items we are discussing<|endoftext|>\n",
      "<|startoftext|>it is my understanding all of the deals are complete<|endoftext|>\n",
      "<|startoftext|>it is been a tough time for us<|endoftext|>\n",
      "<|startoftext|>if you have any questions or need further assistance please do not hesitate to call us<|endoftext|>\n",
      "<|startoftext|>this should be done soon since there are no other options in town<|endoftext|>\n",
      "<|startoftext|>this is the first draft for your attention<|endoftext|>\n",
      "<|startoftext|>please pass this on to anyone else you know<|endoftext|>\n",
      "<|startoftext|>the other two should be done by tomorrow<|endoftext|>\n",
      "<|startoftext|>if you have any further questions please let me know<|endoftext|>\n",
      "<|startoftext|>if any of you would like to schedule you should get a copy of the master agreement<|endoftext|>\n",
      "<|startoftext|>if you have any other suggestions or changes please do not hesitate to call me<|endoftext|>\n",
      "<|startoftext|>thanks for checking in with me<|endoftext|>\n",
      "<|startoftext|>please note that our work schedule is subject to change<|endoftext|>\n",
      "<|startoftext|>i am sure that you would agree<|endoftext|>\n",
      "<|startoftext|>you can always talk to him<|endoftext|>\n",
      "<|startoftext|>if she should not be allowed to stay she will make a difficult decision<|endoftext|>\n",
      "<|startoftext|>it has been a long day here<|endoftext|>\n",
      "<|startoftext|>but we did not know<|endoftext|>\n",
      "<|startoftext|>if you have any questions or need anything further please let me know<|endoftext|>\n",
      "<|startoftext|>if you want to participate please forward to me so that we can discuss the issue in our meeting<|endoftext|>\n",
      "<|startoftext|>i am not sure that we want to call in to say we are going to get a response<|endoftext|>\n",
      "<|startoftext|>please keep in mind that the terms of the document will remain in effect as of this news<|endoftext|>\n",
      "<|startoftext|>but it is just so<|endoftext|>\n",
      "<|startoftext|>it is probably good as well<|endoftext|>\n",
      "<|startoftext|>you should be there\n",
      "\n",
      "[210 | 318.56] loss=1.09 avg=1.15\n",
      "[220 | 331.25] loss=1.11 avg=1.15\n",
      "[230 | 343.90] loss=1.01 avg=1.14\n",
      "[240 | 356.61] loss=1.15 avg=1.14\n",
      "[250 | 369.23] loss=1.07 avg=1.14\n",
      "======== SAMPLE 1 ========\n",
      "|startoftext|>we have the documents we need<|endoftext|>\n",
      "<|startoftext|>we will need to make changes to them as needed<|endoftext|>\n",
      "<|startoftext|>i hope that everything is going well with you<|endoftext|>\n",
      "<|startoftext|>what you hear from the news is only what you understand<|endoftext|>\n",
      "<|startoftext|>the attached copy of the report<|endoftext|>\n",
      "<|startoftext|>please let me know asap<|endoftext|>\n",
      "<|startoftext|>i will update you with any changes as they occur<|endoftext|>\n",
      "<|startoftext|>we will need to get involved in making the changes<|endoftext|>\n",
      "<|startoftext|>i will be unable to make a reply next week or tomorrow<|endoftext|>\n",
      "<|startoftext|>i just got back from vacation today and we are talking about how we are going to spend the weekend<|endoftext|>\n",
      "<|startoftext|>there may be some kind of meeting that happens later this week in order to discuss the meeting<|endoftext|>\n",
      "<|startoftext|>we are very much looking forward to seeing you<|endoftext|>\n",
      "<|startoftext|>that could explain some of the stock information<|endoftext|>\n",
      "<|startoftext|>i am available in the next session to coordinate<|endoftext|>\n",
      "<|startoftext|>attached is the new form<|endoftext|>\n",
      "<|startoftext|>i am attaching a copy to my desk<|endoftext|>\n",
      "<|startoftext|>we apologize no one was able to join us<|endoftext|>\n",
      "<|startoftext|>let me know if there were any problems or if you would like to discuss issues<|endoftext|>\n",
      "<|startoftext|>please contact me if you have any questions about the attached<|endoftext|>\n",
      "<|startoftext|>therefore this report is not final<|endoftext|>\n",
      "<|startoftext|>if you have a question please feel free to call me<|endoftext|>\n",
      "<|startoftext|>you can always forward to a new user on the home page of the website if someone has no access<|endoftext|>\n",
      "<|startoftext|>if you would like to get in on the action please see their page<|endoftext|>\n",
      "<|startoftext|>we have a number of things that we needed to figure out<|endoftext|>\n",
      "<|startoftext|>please let me know if there are any more changes or comments<|endoftext|>\n",
      "<|startoftext|>i am sure in the future you will consider taking it out for an in person<|endoftext|>\n",
      "<|startoftext|>it would then be the same<|endoftext|>\n",
      "<|startoftext|>he can be reached at any time by telephone or email.<|endoftext|>\n",
      "<|startoftext|>i was not really in the business of doing deals<|endoftext|>\n",
      "<|startoftext|>please call if you need more information or want to discuss this information<|endoftext|>\n",
      "<|startoftext|>if there are other issues that you think would benefit from this type of work please take them in as soon as possible<|endoftext|>\n",
      "<|startoftext|>i would very much appreciate it<|endoftext|>\n",
      "<|startoftext|>they had several opportunities to talk about it at the meeting<|endoftext|>\n",
      "<|startoftext|>any further questions please leave me a message<|endoftext|>\n",
      "<|startoftext|>they are going to send the bill out tomorrow<|endoftext|>\n",
      "<|startoftext|>i am not going to be there<|endoftext|>\n",
      "<|startoftext|>please send as comments<|endoftext|>\n",
      "<|startoftext|>your input should be welcome<|endoftext|>\n",
      "<|startoftext|>sorry it was so late<|endoftext|>\n",
      "<|startoftext|>please let me know if you need more of the same<|endoftext|>\n",
      "<|startoftext|>i have\n",
      "\n",
      "[260 | 393.21] loss=1.10 avg=1.14\n",
      "[270 | 405.85] loss=1.14 avg=1.14\n",
      "[280 | 418.50] loss=1.02 avg=1.13\n",
      "[290 | 431.14] loss=1.11 avg=1.13\n",
      "[300 | 443.85] loss=1.01 avg=1.13\n",
      "======== SAMPLE 1 ========\n",
      " here<|endoftext|>\n",
      "<|startoftext|>you are the life of the party and if you could not attend that should not be you<|endoftext|>\n",
      "<|startoftext|>if you have further questions please contact me<|endoftext|>\n",
      "<|startoftext|>all you have to do is answer the first four questions<|endoftext|>\n",
      "<|startoftext|>i would love to meet you as well<|endoftext|>\n",
      "<|startoftext|>the final call has been scheduled<|endoftext|>\n",
      "<|startoftext|>let me know if you would like further information<|endoftext|>\n",
      "<|startoftext|>this seems to be a critical area<|endoftext|>\n",
      "<|startoftext|>i do not have the original draft<|endoftext|>\n",
      "<|startoftext|>he has taken a look at it<|endoftext|>\n",
      "<|startoftext|>just a little bit to clear up all the minor issues<|endoftext|>\n",
      "<|startoftext|>i have talked to him for days<|endoftext|>\n",
      "<|startoftext|>in any case my question is<|endoftext|>\n",
      "<|startoftext|>please review the attached draft and update me as they change<|endoftext|>\n",
      "<|startoftext|>we have an issue with the contract<|endoftext|>\n",
      "<|startoftext|>for you folks<|endoftext|>\n",
      "<|startoftext|>let me know if it is okay or if you need any more information<|endoftext|>\n",
      "<|startoftext|>i still need to figure this out<|endoftext|>\n",
      "<|startoftext|>it does not happen in the real world<|endoftext|>\n",
      "<|startoftext|>that is it<|endoftext|>\n",
      "<|startoftext|>please let me know what you see and when<|endoftext|>\n",
      "<|startoftext|>please let me know what date works for you<|endoftext|>\n",
      "<|startoftext|>this weekend is just a short time later<|endoftext|>\n",
      "<|startoftext|>i am looking for you to discuss a number of various business matters<|endoftext|>\n",
      "<|startoftext|>if your schedule makes it difficult you can make it easier on yourself<|endoftext|>\n",
      "<|startoftext|>if you have any questions on this please do not hesitate to give me email at the top<|endoftext|>\n",
      "<|startoftext|>i am available tomorrow for further analysis<|endoftext|>\n",
      "<|startoftext|>i will bring an attorney for you later<|endoftext|>\n",
      "<|startoftext|>we need to focus first<|endoftext|>\n",
      "<|startoftext|>please let me know how and if you would like a copy<|endoftext|>\n",
      "<|startoftext|>that is what you want<|endoftext|>\n",
      "<|startoftext|>thank you for your information in writing<|endoftext|>\n",
      "<|startoftext|>in order to use your information for marketing purposes please update the referenced document with new information<|endoftext|>\n",
      "<|startoftext|>i did not know<|endoftext|>\n",
      "<|startoftext|>let me know what works for you<|endoftext|>\n",
      "<|startoftext|>i did not know what was coming<|endoftext|>\n",
      "<|startoftext|>a lot of that was the energy industry<|endoftext|>\n",
      "<|startoftext|>give your card<|endoftext|>\n",
      "<|startoftext|>i assume for you<|endoftext|>\n",
      "<|startoftext|>for more information go to www<|endoftext|>\n",
      "<|startoftext|>see attached file<|endoftext|>\n",
      "<|startoftext|>all changes and new items are due to me<|endoftext|>\n",
      "<|startoftext|>it does not need to be signed<|endoftext|>\n",
      "<|startoftext|>i appreciate your assistance on this matter<|endoftext|>\n",
      "<|startoftext|>please review and let me know if you have\n",
      "\n",
      "[310 | 467.88] loss=1.11 avg=1.13\n",
      "[320 | 480.56] loss=1.03 avg=1.12\n",
      "[330 | 493.20] loss=0.97 avg=1.12\n",
      "[340 | 505.80] loss=1.06 avg=1.12\n",
      "[350 | 518.42] loss=1.04 avg=1.11\n",
      "======== SAMPLE 1 ========\n",
      " with more details<|endoftext|>\n",
      "<|startoftext|>the company said it has a cash management group<|endoftext|>\n",
      "<|startoftext|>i have attached the spreadsheet to the attached agreement<|endoftext|>\n",
      "<|startoftext|>if this is the company will be the reason we do not take action<|endoftext|>\n",
      "<|startoftext|>i will send it back and we will talk about this in our new room<|endoftext|>\n",
      "<|startoftext|>if you have any additional thoughts on these issues feel free to give me a call<|endoftext|>\n",
      "<|startoftext|>however she is doing well<|endoftext|>\n",
      "<|startoftext|>if you could send an email to him to let him know that we have an offer we were waiting for<|endoftext|>\n",
      "<|startoftext|>i did not expect it much<|endoftext|>\n",
      "<|startoftext|>if you are unable to attend please let us know<|endoftext|>\n",
      "<|startoftext|>this way we can get your feedback<|endoftext|>\n",
      "<|startoftext|>the weather is good<|endoftext|>\n",
      "<|startoftext|>the company said it will use the funds to pay for product development and marketing expenses<|endoftext|>\n",
      "<|startoftext|>here is the press release<|endoftext|>\n",
      "<|startoftext|>see what you make of it<|endoftext|>\n",
      "<|startoftext|>there was an agenda<|endoftext|>\n",
      "<|startoftext|>the report continues<|endoftext|>\n",
      "<|startoftext|>i hope this provides you with the opportunity to discuss<|endoftext|>\n",
      "<|startoftext|>let is talk about this when you get there<|endoftext|>\n",
      "<|startoftext|>this is the right move to help the country meet its long term energy needs<|endoftext|>\n",
      "<|startoftext|>the most positive effect on consumer spending is the increase in the rate of return on investment<|endoftext|>\n",
      "<|startoftext|>thank you so much for the note<|endoftext|>\n",
      "<|startoftext|>this is what the market wants and needs to get back<|endoftext|>\n",
      "<|startoftext|>let me know if you need help with any of this<|endoftext|>\n",
      "<|startoftext|>i will be there<|endoftext|>\n",
      "<|startoftext|>i just know it now<|endoftext|>\n",
      "<|startoftext|>please give your approval<|endoftext|>\n",
      "<|startoftext|>if you feel the need give me a call<|endoftext|>\n",
      "<|startoftext|>here is my new info<|endoftext|>\n",
      "<|startoftext|>i will follow up this week<|endoftext|>\n",
      "<|startoftext|>in case you need additional data<|endoftext|>\n",
      "<|startoftext|>please contact me for more information at the numbers indicated in red below<|endoftext|>\n",
      "<|startoftext|>a few notes on the form is<|endoftext|>\n",
      "<|startoftext|>please let me know what time we should start the presentation<|endoftext|>\n",
      "<|startoftext|>they should have them in place by next winter<|endoftext|>\n",
      "<|startoftext|>if you require additional information let me know<|endoftext|>\n",
      "<|startoftext|>i am waiting for a response from you<|endoftext|>\n",
      "<|startoftext|>i have been sending you emails from the customer to let you know more information<|endoftext|>\n",
      "<|startoftext|>please make your changes to the attachment<|endoftext|>\n",
      "<|startoftext|>i understand that you could go to any of the two levels and they would both do the same<|endoftext|>\n",
      "<|startoftext|>the other option would be to send it by mail<|endoftext|>\n",
      "<|startoftext|>i just did a little research and found the following<|endoftext|>\n",
      "<|startoftext|>attached is the\n",
      "\n",
      "[360 | 542.46] loss=1.06 avg=1.11\n",
      "[370 | 555.13] loss=1.00 avg=1.11\n",
      "[380 | 567.76] loss=1.02 avg=1.10\n",
      "[390 | 580.38] loss=1.04 avg=1.10\n",
      "[400 | 593.00] loss=0.99 avg=1.10\n",
      "======== SAMPLE 1 ========\n",
      " know about this<|endoftext|>\n",
      "<|startoftext|>we will continue to look for the next person<|endoftext|>\n",
      "<|startoftext|>that includes me<|endoftext|>\n",
      "<|startoftext|>please find attached notes for your convenience<|endoftext|>\n",
      "<|startoftext|>all the same things<|endoftext|>\n",
      "<|startoftext|>i will not be able to do this without them in the call<|endoftext|>\n",
      "<|startoftext|>i hope you can join me for lunch<|endoftext|>\n",
      "<|startoftext|>please see the attachment for details<|endoftext|>\n",
      "<|startoftext|>i am just glad to have you to visit<|endoftext|>\n",
      "<|startoftext|>that would be the difference<|endoftext|>\n",
      "<|startoftext|>i did not touch anything<|endoftext|>\n",
      "<|startoftext|>this is pretty much the only report we have received so far<|endoftext|>\n",
      "<|startoftext|>i will do what is necessary<|endoftext|>\n",
      "<|startoftext|>i do not know if he has done any research or not<|endoftext|>\n",
      "<|startoftext|>the other deal for that was very bad<|endoftext|>\n",
      "<|startoftext|>please do not call me on my cell phone<|endoftext|>\n",
      "<|startoftext|>but he is not expected to play this week<|endoftext|>\n",
      "<|startoftext|>i will contact him<|endoftext|>\n",
      "<|startoftext|>there are no deals yet so feel free to let me know<|endoftext|>\n",
      "<|startoftext|>thanks for everyone is help and understanding<|endoftext|>\n",
      "<|startoftext|>i am attaching my resume where you can find comments<|endoftext|>\n",
      "<|startoftext|>they were trying to build a database and a way to get it into a database<|endoftext|>\n",
      "<|startoftext|>please keep me informed<|endoftext|>\n",
      "<|startoftext|>please find attached memo<|endoftext|>\n",
      "<|startoftext|>here are the information we have on the house<|endoftext|>\n",
      "<|startoftext|>there have been no developments<|endoftext|>\n",
      "<|startoftext|>let me know if you see any of any problems or if you want to discuss<|endoftext|>\n",
      "<|startoftext|>this was the second time he has taken this step<|endoftext|>\n",
      "<|startoftext|>i will call once and get back to you<|endoftext|>\n",
      "<|startoftext|>call if you need anything<|endoftext|>\n",
      "<|startoftext|>please let me know how you would like to proceed<|endoftext|>\n",
      "<|startoftext|>thanks and please call me with your questions<|endoftext|>\n",
      "<|startoftext|>your response will be included on the report<|endoftext|>\n",
      "<|startoftext|>here are the information that we have already received<|endoftext|>\n",
      "<|startoftext|>please give me a call if you have any questions<|endoftext|>\n",
      "<|startoftext|>see link below<|endoftext|>\n",
      "<|startoftext|>please let me know if you would like me to include them in your review<|endoftext|>\n",
      "<|startoftext|>please feel free to give me a call with any questions or comments that you wish to discuss<|endoftext|>\n",
      "<|startoftext|>if you have additional questions feel free to call<|endoftext|>\n",
      "<|startoftext|>please verify your credit report with me if you have any question on this matter<|endoftext|>\n",
      "<|startoftext|>we may need some more<|endoftext|>\n",
      "<|startoftext|>so how is she doing there<|endoftext|>\n",
      "<|startoftext|>this deal should be fine<|endoftext|>\n",
      "<|startoftext|>let me know the best time for your review<|endoftext|>\n",
      "<|\n",
      "\n",
      "[410 | 617.04] loss=1.00 avg=1.10\n",
      "[420 | 629.74] loss=0.99 avg=1.09\n",
      "[430 | 642.35] loss=1.03 avg=1.09\n",
      "[440 | 654.96] loss=1.01 avg=1.09\n",
      "[450 | 667.62] loss=0.91 avg=1.08\n",
      "======== SAMPLE 1 ========\n",
      "|endoftext|>\n",
      "<|startoftext|>but there was one question about his plans<|endoftext|>\n",
      "<|startoftext|>i will update you next week when it is completed<|endoftext|>\n",
      "<|startoftext|>i would like to have our comments forwarded to you by phone<|endoftext|>\n",
      "<|startoftext|>but he did not make it<|endoftext|>\n",
      "<|startoftext|>please advise as to who we can help with the following<|endoftext|>\n",
      "<|startoftext|>please call when you know of an opportunity like this<|endoftext|>\n",
      "<|startoftext|>you would not be a good fit if you did not have the information on you book<|endoftext|>\n",
      "<|startoftext|>the company said it is looking at new investments and would focus on sales<|endoftext|>\n",
      "<|startoftext|>we are currently in the business of selling books<|endoftext|>\n",
      "<|startoftext|>i would like to set up an interview with him<|endoftext|>\n",
      "<|startoftext|>see you there<|endoftext|>\n",
      "<|startoftext|>also please let me know if you should need more information about me<|endoftext|>\n",
      "<|startoftext|>please let me know if there is anything you need from me<|endoftext|>\n",
      "<|startoftext|>i think this is the one we should look at<|endoftext|>\n",
      "<|startoftext|>he did not return for that session<|endoftext|>\n",
      "<|startoftext|>thanks for your clarification and assistance<|endoftext|>\n",
      "<|startoftext|>thanks in advance for your prompt response<|endoftext|>\n",
      "<|startoftext|>please give me a call if you have any questions<|endoftext|>\n",
      "<|startoftext|>i will need one today<|endoftext|>\n",
      "<|startoftext|>it will be nice<|endoftext|>\n",
      "<|startoftext|>i need to make sure that the changes sound acceptable to the customers<|endoftext|>\n",
      "<|startoftext|>the company said it will use the funding to develop a business technology line and for marketing<|endoftext|>\n",
      "<|startoftext|>in the meantime please follow the link below<|endoftext|>\n",
      "<|startoftext|>please let me know if you have any questions regarding this matter<|endoftext|>\n",
      "<|startoftext|>the schedule is attached for your review<|endoftext|>\n",
      "<|startoftext|>the next meeting should happen within a few days of my letter being sent out<|endoftext|>\n",
      "<|startoftext|>we are very concerned about its impact on our company<|endoftext|>\n",
      "<|startoftext|>thanks for all your patience<|endoftext|>\n",
      "<|startoftext|>thanks again to everyone for having such a help desk<|endoftext|>\n",
      "<|startoftext|>please review the attached draft of the document<|endoftext|>\n",
      "<|startoftext|>i will get it from you in the morning today<|endoftext|>\n",
      "<|startoftext|>i do not know how these three items will play out and would suggest that more testing be done shortly<|endoftext|>\n",
      "<|startoftext|>he made some money back then<|endoftext|>\n",
      "<|startoftext|>it has really changed my perspective<|endoftext|>\n",
      "<|startoftext|>please call with any questions<|endoftext|>\n",
      "<|startoftext|>do you ever have a problem with the list<|endoftext|>\n",
      "<|startoftext|>if anyone has any questions or needs more information let me know<|endoftext|>\n",
      "<|startoftext|>that is fine with me<|endoftext|>\n",
      "<|startoftext|>so here is your draft<|endoftext|>\n",
      "<|startoftext|>the following changes have been changed<|endoftext|>\n",
      "<|startoftext|>i assume that we can coordinate a meeting<|endoftext|>\n",
      "<|startoftext|>please see changes below and let me know if you need further information or\n",
      "\n",
      "[460 | 691.56] loss=0.94 avg=1.08\n",
      "[470 | 704.20] loss=1.01 avg=1.08\n",
      "[480 | 716.81] loss=0.90 avg=1.07\n",
      "[490 | 729.48] loss=1.04 avg=1.07\n",
      "[500 | 742.08] loss=1.06 avg=1.07\n",
      "Saving checkpoint/run1/model-500\n"
     ]
    }
   ],
   "source": [
    "#Fine-tune GPT2 model\n",
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=500,\n",
    "              restore_from='fresh',\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              sample_every=50\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1m3vlkFBCH2"
   },
   "outputs": [],
   "source": [
    "#Copy GPT2 model to Google Drive\n",
    "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0AWnBp_T3Eg"
   },
   "outputs": [],
   "source": [
    "#Load GPT2 model from Google Drive\n",
    "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "LF7JIfkWT3KR",
    "outputId": "bd86b36a-6ab4-4f8c-9b2e-cc0546b9cea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-500\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-500\n"
     ]
    }
   ],
   "source": [
    "#Load trained model\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "U4GqhnWRUlnt",
    "outputId": "c0e4a184-70cf-4616-e0b2-a4d0a3742e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-12 05:12:28--  https://doc-10-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/ft2nrpemmsfv4pa4tavlle3puo82k486/1591938675000/02963250765125473783/02963250765125473783/1HMgJBTT6CEU3fB9a40FxCp-PhtEgjZfj?e=download&authuser=1\n",
      "Resolving doc-10-ak-docs.googleusercontent.com (doc-10-ak-docs.googleusercontent.com)... 108.177.125.132, 2404:6800:4008:c01::84\n",
      "Connecting to doc-10-ak-docs.googleusercontent.com (doc-10-ak-docs.googleusercontent.com)|108.177.125.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘train_final_data.csv’\n",
      "\n",
      "\r",
      "train_final_data.cs     [<=>                 ]       0  --.-KB/s               \r",
      "train_final_data.cs     [ <=>                ]  21.79M   116MB/s    in 0.2s    \n",
      "\n",
      "2020-06-12 05:12:29 (116 MB/s) - ‘train_final_data.csv’ saved [22853484]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-10-ak-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://drive.google.com/drive/u/1/folders/1GPJE1WQq27nrFOlJwMRDMIO-6HbzxvVu\" --header=\"Cookie: AUTH_hsr61oqao0sqa2rdskku1n6gcr67pomr=02963250765125473783|1591938525000|hldd6k0bf58ot9hkud0vlq42tnfjpnm8; _ga=GA1.2.1509677474.1591248567\" --header=\"Connection: keep-alive\" \"https://doc-10-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/ft2nrpemmsfv4pa4tavlle3puo82k486/1591938675000/02963250765125473783/02963250765125473783/1HMgJBTT6CEU3fB9a40FxCp-PhtEgjZfj?e=download&authuser=1\" -c -O 'train_final_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "lOuipRSuU-_4",
    "outputId": "d20dafe9-89e3-4554-9c5a-8eead5278eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-12 05:12:32--  https://doc-0g-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/7hvjf16pnf3aj0u2rnhuoke3jnpips2o/1591938675000/02963250765125473783/02963250765125473783/1kdRszXCTviPXxWQcpTFTf9AXoqhowuE0?e=download&authuser=1\n",
      "Resolving doc-0g-ak-docs.googleusercontent.com (doc-0g-ak-docs.googleusercontent.com)... 108.177.125.132, 2404:6800:4008:c01::84\n",
      "Connecting to doc-0g-ak-docs.googleusercontent.com (doc-0g-ak-docs.googleusercontent.com)|108.177.125.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘val_final_data.csv’\n",
      "\n",
      "\r",
      "val_final_data.csv      [<=>                 ]       0  --.-KB/s               \r",
      "val_final_data.csv      [ <=>                ]   4.36M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-06-12 05:12:32 (97.0 MB/s) - ‘val_final_data.csv’ saved [4569448]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-0g-ak-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://drive.google.com/drive/u/1/folders/1GPJE1WQq27nrFOlJwMRDMIO-6HbzxvVu\" --header=\"Cookie: AUTH_hsr61oqao0sqa2rdskku1n6gcr67pomr=02963250765125473783|1591938525000|hldd6k0bf58ot9hkud0vlq42tnfjpnm8; _ga=GA1.2.1509677474.1591248567\" --header=\"Connection: keep-alive\" \"https://doc-0g-ak-docs.googleusercontent.com/docs/securesc/qbvov0hd66fbepcf5v8uge9fuarie7t4/7hvjf16pnf3aj0u2rnhuoke3jnpips2o/1591938675000/02963250765125473783/02963250765125473783/1kdRszXCTviPXxWQcpTFTf9AXoqhowuE0?e=download&authuser=1\" -c -O 'val_final_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>(Refer GPT2 Word Featurization Section 2 of 2_Data_Preparation.ipynb)</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWjKquddVIzi"
   },
   "outputs": [],
   "source": [
    "train_final_data = pd.read_csv('train_final_data.csv')\n",
    "val_final_data = pd.read_csv('val_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "h-Z4yjyTVWaI",
    "outputId": "bff95bec-3220-49a6-ad7e-854f7b0eafa6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|startoftext|&gt;it</td>\n",
       "      <td>looks like we should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks</td>\n",
       "      <td>like we should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks like</td>\n",
       "      <td>we should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks like we</td>\n",
       "      <td>should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks like we should</td>\n",
       "      <td>have them soon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        X                                    y\n",
       "0                       <|startoftext|>it  looks like we should have them soon\n",
       "1                 <|startoftext|>it looks        like we should have them soon\n",
       "2            <|startoftext|>it looks like             we should have them soon\n",
       "3         <|startoftext|>it looks like we                should have them soon\n",
       "4  <|startoftext|>it looks like we should                       have them soon"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "tSFRFOWLehaL",
    "outputId": "6a15b34d-286e-4498-ebe7-5fce8f0588c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>X_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that</td>\n",
       "      <td>might be just what the two utilities receive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might</td>\n",
       "      <td>be just what the two utilities receive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might be</td>\n",
       "      <td>just what the two utilities receive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might be just</td>\n",
       "      <td>what the two utilities receive</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might be just what</td>\n",
       "      <td>the two utilities receive</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  X  ... X_length\n",
       "0                     <|startoftext|>but again that  ...        3\n",
       "1               <|startoftext|>but again that might  ...        4\n",
       "2            <|startoftext|>but again that might be  ...        5\n",
       "3       <|startoftext|>but again that might be just  ...        6\n",
       "4  <|startoftext|>but again that might be just what  ...        7\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SENLy63T3JR"
   },
   "outputs": [],
   "source": [
    "#Compute loss for train and validation data\n",
    "#Generate 100 random samples from train and val data\n",
    "#Train data\n",
    "train_index = []\n",
    "for i in range(train_final_data.shape[0]):\n",
    "    if len(train_final_data.X.iloc[i].split())>13:\n",
    "        train_index.append(i)\n",
    "train_index = random.sample(train_index,100)\n",
    "\n",
    "#Validation data\n",
    "#Train data\n",
    "val_index = []\n",
    "for i in range(val_final_data.shape[0]):\n",
    "    if len(val_final_data.X.iloc[i].split())>13:\n",
    "        val_index.append(i)\n",
    "val_index = random.sample(val_index,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiMhA_YBUlly"
   },
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "    return gpt2.generate(sess, run_name='run1',length=25,prefix=text,truncate=\"<|endoftext|>\",include_prefix=False,\n",
    "                         return_as_list=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9bJvW3TV4yu"
   },
   "outputs": [],
   "source": [
    "def get_bleu_score(input_sent,actual):\n",
    "    prediction = predict_text(input_sent)\n",
    "    return input_sent,actual,prediction,bleu_score.sentence_bleu([actual.split()],prediction.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939,
     "referenced_widgets": [
      "1027ff3ef44f46d8b4424c3b25fd32da",
      "b3799b110e854631bf1e7009d6a8ac3d",
      "d8632ddaf30847209ec7446eff3076c8",
      "2c75ab0469234c20bd01c2d2cd2cf17a",
      "bf2d628164db45ecb6a4043d781ae6e2",
      "9321c8a27720422d8677efa52fb0eb65",
      "e204619892144f7295eb7dc161436669",
      "0d3516e9083c4a69bd75d94b1e9e96b7"
     ]
    },
    "colab_type": "code",
    "id": "nVge7kRBaWkN",
    "outputId": "687160fd-9d8b-4aeb-c6d8-141ebdb63285"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1027ff3ef44f46d8b4424c3b25fd32da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <|startoftext|>i would love the opportunity to talk with you further if you think this might\n",
      "Actual words: be of interest to you\n",
      "Predicted words:  be of interest to you\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>if either of you have any questions or know of more things to do please\n",
      "Actual words: let is get together and discuss\n",
      "Predicted words:  let me know\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>please call if you have any questions or would like to discuss in greater\n",
      "Actual words: detail\n",
      "Predicted words:  detail\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>i do not want that to be the basis on which the decision is\n",
      "Actual words: made\n",
      "Predicted words:  made\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>in that case you do not need to reply and this will be the last note\n",
      "Actual words: you will get from us\n",
      "Predicted words: \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>i would be happy for you to take this back if you would like to work on it as an\n",
      "Actual words: infrastructure project\n",
      "Predicted words:  individual project\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>therefore we do not wish to make an offer of this package at this\n",
      "Actual words: time\n",
      "Predicted words:  time\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>please forward this to anyone who might benefit from a better understanding of energy derivatives\n",
      "Actual words: and electric power trading\n",
      "Predicted words: \n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>this draft has not been reviewed by my client and thus we must reserve the\n",
      "Actual words: right to make further revisions\n",
      "Predicted words:  right to approve or comment on the document at any time\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>if for some reason it does not start showing up please give me a\n",
      "Actual words: call\n",
      "Predicted words:  call\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For train data, actual and predicted words\n",
    "train_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(train_final_data.X.iloc[train_index],train_final_data.y.iloc[train_index])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(i,j)\n",
    "    train_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%10==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6J_zRGft8eGW",
    "outputId": "ccf4f3d2-c5a8-429f-a497-1fef6a5cce3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for train data of 100 samples: 0.429\n"
     ]
    }
   ],
   "source": [
    "#Average BLEU Score for sentences\n",
    "print('BLEU Score for train data of 100 samples:',np.round(sum(train_bleu_list)/len(train_bleu_list),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939,
     "referenced_widgets": [
      "9e59d271f3f34d33b6d1b88fd6870e41",
      "49e47132bde64081bbf2ab2acd7344dc",
      "a8ab9d58e51645bea3284aeef2a0906b",
      "562f6676bf9b478da860a4a760cc7fa6",
      "f66be1c4332845d39903cdce6455418b",
      "067777d6b1534c3ba2f4ed318c097251",
      "8741c23a61cb4f03b5fec1c3201ddbfb",
      "85dae720e93444358419a00eced9788d"
     ]
    },
    "colab_type": "code",
    "id": "efm_xdAebaLR",
    "outputId": "ad7ffa66-b58b-4f46-8f5a-6277334ec18c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e59d271f3f34d33b6d1b88fd6870e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <|startoftext|>i would like to know by then what we like and do not like about\n",
      "Actual words: them and how to approach possible changes\n",
      "Predicted words:  you guys\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>however the states would be able to determine how and when this would be\n",
      "Actual words: done\n",
      "Predicted words:  done\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>if you want to discuss it further please feel free to give me a\n",
      "Actual words: call\n",
      "Predicted words:  call\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>if you are not the correct person that should look at this please let me\n",
      "Actual words: know\n",
      "Predicted words:  know\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: <|startoftext|>please feel free to contact me or have your counsel contact me with any questions regarding\n",
      "Actual words: the attached\n",
      "Predicted words:  this matter\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>if you wish to know that you are safe cause another to know that they\n",
      "Actual words: are safe\n",
      "Predicted words:  are not safe cause\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>a conversation with you would help me to better understand client needs in the competitive market\n",
      "Actual words: for information\n",
      "Predicted words:  and in the energy industry\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>please make a note of his information so you can work with him in\n",
      "Actual words: the future\n",
      "Predicted words:  the future\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>should you have any questions regarding this matter please do not hesitate to contact\n",
      "Actual words: me\n",
      "Predicted words:  me\n",
      "------------------------------------------------------------------------------------------\n",
      "Input sentence: <|startoftext|>please let me have your thoughts regarding these issues and how you would like to\n",
      "Actual words: proceed\n",
      "Predicted words:  proceed\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For validation data, actual and predicted words\n",
    "val_bleu_list = []\n",
    "counter = 0\n",
    "for i,j in tqdm(zip(val_final_data.X.iloc[val_index],val_final_data.y.iloc[val_index])):\n",
    "    counter+=1\n",
    "    inp, a, p, bleu = get_bleu_score(i,j)\n",
    "    val_bleu_list.append(bleu)\n",
    "    #Print some actual and predicted words\n",
    "    if counter%10==0:\n",
    "        print('Input sentence:',inp)\n",
    "        print('Actual words:',a)\n",
    "        print('Predicted words:',p)\n",
    "        print(90*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZQV3WYctbpsF",
    "outputId": "a0738d22-e9c8-4aa3-8ab4-5fc257a45f09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for validation data of 100 samples: 0.399\n"
     ]
    }
   ],
   "source": [
    "#Average BLEU Score for sentences\n",
    "print('BLEU Score for validation data of 100 samples:',np.round(sum(val_bleu_list)/len(val_bleu_list),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BCySXCv4BCDD",
    "outputId": "e51294f4-f949-45bd-ea69-59a777f6c469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your assistance and support of the group\n"
     ]
    }
   ],
   "source": [
    "#Predictions from model\n",
    "gpt2.generate(sess, run_name='run1',\n",
    "             length=25,\n",
    "             prefix=\"<|startoftext|>thank you for\",\n",
    "             truncate=\"<|endoftext|>\",\n",
    "             include_prefix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VVzfjIW6I6Fv",
    "outputId": "07905989-f730-47f6-c86a-aa1233354d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my car\n"
     ]
    }
   ],
   "source": [
    "#Predictions from model\n",
    "gpt2.generate(sess, run_name='run1',\n",
    "             length=25,\n",
    "             prefix=\"<|startoftext|>where is\",\n",
    "             truncate=\"<|endoftext|>\",\n",
    "             include_prefix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RLTt1EO9I6Ed",
    "outputId": "0a448e5b-670c-4f9e-a122-8a6026c29a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " good weekend\n"
     ]
    }
   ],
   "source": [
    "#Predictions from model\n",
    "gpt2.generate(sess, run_name='run1',\n",
    "             length=25,\n",
    "             prefix=\"<|startoftext|>have a\",\n",
    "             truncate=\"<|endoftext|>\",\n",
    "             include_prefix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6HcrL707BCAz",
    "outputId": "650b26db-409a-478f-d2a4-48d218e35293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " following\n"
     ]
    }
   ],
   "source": [
    "#Predictions from model\n",
    "gpt2.generate(sess, run_name='run1',\n",
    "             length=25,\n",
    "             prefix=\"<|startoftext|>ensure the\",\n",
    "             truncate=\"<|endoftext|>\",\n",
    "             include_prefix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNZYg61cWdqW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_Encoder_Decoder_Attention_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09087bc7ff5c4e7c92b50b9fc1ad3ab0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "18892b9e056b47db90486c5c05fb1094": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35d2359d4d8944f996a6e67d3c11daa2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8b379f0bb994549a450e107bb22d0c5",
      "placeholder": "​",
      "style": "IPY_MODEL_ca4df88be882418b83e4998f3924706e",
      "value": " 1000/? [00:50&lt;00:00, 19.75it/s]"
     }
    },
    "4765040db6644918bf8d8d17610d3833": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5a73251d1a145708f46fad92d1518d6",
       "IPY_MODEL_6eb8c28131a64099baa192b4491e9fe8"
      ],
      "layout": "IPY_MODEL_61a2d100efc94eb1ba80b2bc475654b6"
     }
    },
    "57314bd304444fddb34efc5c4785ddef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_628c199ac0124cddadeb0556ccf394c7",
       "IPY_MODEL_35d2359d4d8944f996a6e67d3c11daa2"
      ],
      "layout": "IPY_MODEL_ebb4942c411049a78ed94f60270cfeb4"
     }
    },
    "5a841e55fbb04f0a8441f9815557e842": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61a2d100efc94eb1ba80b2bc475654b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "628c199ac0124cddadeb0556ccf394c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dbf5c1ee20f4b1a8a1e6ecf39473f8b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8061559e609d49c586e773e467916ddc",
      "value": 1
     }
    },
    "6eb8c28131a64099baa192b4491e9fe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18892b9e056b47db90486c5c05fb1094",
      "placeholder": "​",
      "style": "IPY_MODEL_e1fb58c1987e4cb6b523866d9bfde3e2",
      "value": " 1000/? [01:47&lt;00:00,  9.28it/s]"
     }
    },
    "8061559e609d49c586e773e467916ddc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9dbf5c1ee20f4b1a8a1e6ecf39473f8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5a73251d1a145708f46fad92d1518d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a841e55fbb04f0a8441f9815557e842",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09087bc7ff5c4e7c92b50b9fc1ad3ab0",
      "value": 1
     }
    },
    "b8b379f0bb994549a450e107bb22d0c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca4df88be882418b83e4998f3924706e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1fb58c1987e4cb6b523866d9bfde3e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebb4942c411049a78ed94f60270cfeb4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
