{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import email\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "import time\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>Word Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Load sentences</h1>\n",
    "<h2>(Refer Section 5 of 1_Sentence_E.ipynb)</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_preprocessed_data.csv')\n",
    "validate = pd.read_csv('val_preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Data Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_and_target(text):\n",
    "    \"\"\"\n",
    "    Generates the input and target features from a single sentence\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    a = text.split()\n",
    "    for i in range(1,len(a)):\n",
    "        X.append(' '.join(a[:i]))\n",
    "        y.append(' '.join(a[i:]))\n",
    "\n",
    "    #Convert to dataframe\n",
    "    b = pd.DataFrame(data={'X':X,'y':y})\n",
    "    #Prepare input sequence to model, add start(#) and end tokens(*)\n",
    "    b['X'] = '<start> ' + b['X'] + ' <end>'\n",
    "    b['y'] = '<start> ' + b['y'] + ' <end>'\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data for all samples\n",
    "def generate_data_for_model(data_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates data for input to model\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(data_df.shape[0])):\n",
    "        if i==0:\n",
    "            \n",
    "            final_df = generate_input_and_target(data_df.sent.iloc[0])\n",
    "        else:\n",
    "            final_df = pd.concat([final_df,generate_input_and_target(data_df.sent.iloc[i])],ignore_index=True)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load train_data_featurization.py\n",
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_input_and_target(text):\n",
    "    \"\"\"\n",
    "    Generates the input and target features from a single sentence\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    a = text.split()\n",
    "    for i in range(1,len(a)):\n",
    "        X.append(' '.join(a[:i]))\n",
    "        y.append(' '.join(a[i:]))\n",
    "\n",
    "    #Convert to dataframe\n",
    "    b = pd.DataFrame(data={'X':X,'y':y})\n",
    "    #Prepare input sequence to model, add start(#) and end tokens(*)\n",
    "    b['X'] = '<start> ' + b['X'] + ' <end>'\n",
    "    b['y'] = '<start> ' + b['y'] + ' <end>'\n",
    "    \n",
    "    return b\n",
    "\n",
    "#Generate data for all samples\n",
    "def generate_data_for_model(data_df,filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates data for input to model\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(data_df.shape[0])):\n",
    "        if i==0:\n",
    "            final_df = generate_input_and_target(data_df.sent.iloc[0])\n",
    "        else:\n",
    "            final_df = pd.concat([final_df,generate_input_and_target(data_df.sent.iloc[i])],ignore_index=True)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "        \n",
    "    #Create folder to dataframe\n",
    "    if not os.path.isdir('final_df'):\n",
    "        os.makedirs('final_df')\n",
    "    if not os.path.isdir('final_df/train'):\n",
    "        os.makedirs('final_df/train')\n",
    "        \n",
    "    #Save dataframe\n",
    "    final_df.to_csv('final_df/train/'+filename+'.csv',index=False,index_label=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    #the below code is used for multiprogramming\n",
    "    #the number of process depends upon the number of cores present System\n",
    "    #process is used to call multiprogramming\n",
    "    \n",
    "    #Import dataset\n",
    "    data = pd.read_csv('train_preprocessed_data.csv')\n",
    "    \n",
    "    data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8 = np.array_split(data,8)\n",
    "\n",
    "    start=time.time()\n",
    "    manager=multiprocessing.Manager() \t\n",
    "    p1=multiprocessing.Process(target=generate_data_for_model,args=(data_1,'first'))\n",
    "    p2=multiprocessing.Process(target=generate_data_for_model,args=(data_2,'second'))\n",
    "    p3=multiprocessing.Process(target=generate_data_for_model,args=(data_3,'third'))\n",
    "    p4=multiprocessing.Process(target=generate_data_for_model,args=(data_4,'fourth'))\n",
    "    p5=multiprocessing.Process(target=generate_data_for_model,args=(data_5,'fifth'))\n",
    "    p6=multiprocessing.Process(target=generate_data_for_model,args=(data_6,'sixth'))\n",
    "    p7=multiprocessing.Process(target=generate_data_for_model,args=(data_7,'seventh'))\n",
    "    p8=multiprocessing.Process(target=generate_data_for_model,args=(data_8,'eighth'))\n",
    "    \n",
    "    #p1.start() is used to start the thread execution\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    p4.start()\n",
    "    p5.start()\n",
    "    p6.start()\n",
    "    p7.start()\n",
    "    p8.start()\n",
    "\n",
    "    #After completion all the threads are joined\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()\n",
    "    p5.join()\n",
    "    p6.join()\n",
    "    p7.join()\n",
    "    p8.join()\n",
    "    print('Time taken: {} seconds'.format(np.round(time.time()-start,2)))\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5228/5228 [01:39<00:00, 52.33it/s]\n",
      "100%|██████████| 5228/5228 [01:40<00:00, 52.11it/s]\n",
      "100%|██████████| 5229/5229 [01:40<00:00, 52.01it/s]\n",
      "100%|██████████| 5229/5229 [01:40<00:00, 51.99it/s]\n",
      "100%|██████████| 5229/5229 [01:40<00:00, 51.92it/s]\n",
      "100%|██████████| 5228/5228 [01:40<00:00, 51.88it/s]\n",
      "100%|██████████| 5229/5229 [01:40<00:00, 51.81it/s]\n",
      "100%|██████████| 5228/5228 [01:40<00:00, 51.82it/s]\n",
      "Time taken: 101.16 seconds\n"
     ]
    }
   ],
   "source": [
    "! python train_data_featurization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all train data which is featurized\n",
    "a = pd.read_csv('final_df/train/first.csv')\n",
    "b = pd.read_csv('final_df/train/second.csv')\n",
    "c = pd.read_csv('final_df/train/third.csv')\n",
    "d = pd.read_csv('final_df/train/fourth.csv')\n",
    "e = pd.read_csv('final_df/train/fifth.csv')\n",
    "f = pd.read_csv('final_df/train/sixth.csv')\n",
    "g = pd.read_csv('final_df/train/seventh.csv')\n",
    "h = pd.read_csv('final_df/train/eighth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = pd.concat([a,b,c,d,e,f,g,h],ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; it &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; looks like we should have them soon &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; it looks &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; like we should have them soon &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; it looks like &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; we should have them soon &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; it looks like we &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; should have them soon &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; it looks like we should &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; have them soon &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       X  \\\n",
       "0                       <start> it <end>   \n",
       "1                 <start> it looks <end>   \n",
       "2            <start> it looks like <end>   \n",
       "3         <start> it looks like we <end>   \n",
       "4  <start> it looks like we should <end>   \n",
       "\n",
       "                                                   y  \n",
       "0  <start> looks like we should have them soon <end>  \n",
       "1        <start> like we should have them soon <end>  \n",
       "2             <start> we should have them soon <end>  \n",
       "3                <start> should have them soon <end>  \n",
       "4                       <start> have them soon <end>  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328972, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data.to_csv('train_final_data.csv',index=False,index_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1307/1307 [00:14<00:00, 92.24it/s]\n",
      "100%|██████████| 1307/1307 [00:14<00:00, 91.52it/s]\n",
      "100%|██████████| 1308/1308 [00:14<00:00, 91.37it/s]\n",
      "100%|██████████| 1307/1307 [00:14<00:00, 90.57it/s]\n",
      "100%|██████████| 1307/1307 [00:14<00:00, 90.59it/s]\n",
      "100%|██████████| 1307/1307 [00:14<00:00, 90.19it/s]\n",
      "100%|██████████| 1307/1307 [00:14<00:00, 90.14it/s]\n",
      "100%|██████████| 1307/1307 [00:14<00:00, 89.95it/s]\n",
      "Time taken: 14.62 seconds\n"
     ]
    }
   ],
   "source": [
    "! python val_data_featurization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all validation data which is featurized\n",
    "a = pd.read_csv('final_df/val/first.csv')\n",
    "b = pd.read_csv('final_df/val/second.csv')\n",
    "c = pd.read_csv('final_df/val/third.csv')\n",
    "d = pd.read_csv('final_df/val/fourth.csv')\n",
    "e = pd.read_csv('final_df/val/fifth.csv')\n",
    "f = pd.read_csv('final_df/val/sixth.csv')\n",
    "g = pd.read_csv('final_df/val/seventh.csv')\n",
    "h = pd.read_csv('final_df/val/eighth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_data = pd.concat([a,b,c,d,e,f,g,h],ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; but &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; again that might be just what the two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; but again &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; that might be just what the two utilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; but again that &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; might be just what the two utilities r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; but again that might &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; be just what the two utilities receive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; but again that might be &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; just what the two utilities receive &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       X  \\\n",
       "0                      <start> but <end>   \n",
       "1                <start> but again <end>   \n",
       "2           <start> but again that <end>   \n",
       "3     <start> but again that might <end>   \n",
       "4  <start> but again that might be <end>   \n",
       "\n",
       "                                                   y  \n",
       "0  <start> again that might be just what the two ...  \n",
       "1  <start> that might be just what the two utilit...  \n",
       "2  <start> might be just what the two utilities r...  \n",
       "3  <start> be just what the two utilities receive...  \n",
       "4  <start> just what the two utilities receive <end>  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82086, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the model is to predict the next few words given sufficient number of input words. If the number of input words are too small, the predicted output is less likely to make sense. Hence for validation data, the samples whose number of words are less than 5 are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column which counts number of words in each text\n",
    "val_final_data['X_length'] = val_final_data['X'].apply(lambda text:len(text.split()))\n",
    "\n",
    "#Drop samples with words less than 4 \n",
    "val_final_data = val_final_data[val_final_data['X_length']>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>X_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; but again that &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; might be just what the two utilities r...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; but again that might &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; be just what the two utilities receive...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; but again that might be &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; just what the two utilities receive &lt;end&gt;</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;start&gt; but again that might be just &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; what the two utilities receive &lt;end&gt;</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;start&gt; but again that might be just what &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; the two utilities receive &lt;end&gt;</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 X  \\\n",
       "2                     <start> but again that <end>   \n",
       "3               <start> but again that might <end>   \n",
       "4            <start> but again that might be <end>   \n",
       "5       <start> but again that might be just <end>   \n",
       "6  <start> but again that might be just what <end>   \n",
       "\n",
       "                                                   y  X_length  \n",
       "2  <start> might be just what the two utilities r...         5  \n",
       "3  <start> be just what the two utilities receive...         6  \n",
       "4  <start> just what the two utilities receive <end>         7  \n",
       "5       <start> what the two utilities receive <end>         8  \n",
       "6            <start> the two utilities receive <end>         9  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61183, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_data.to_csv('val_final_data.csv',index=False,index_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = pd.read_csv('train_final_data.csv')\n",
    "val_final_data = pd.read_csv('val_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',oov_token='<unk>')\n",
    "inp_tokenizer.fit_on_texts(train_final_data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_vocab_size = len(inp_tokenizer.word_index) + 1  \n",
    "inp_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',oov_token='<unk>')\n",
    "out_tokenizer.fit_on_texts(train_final_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1469"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_vocab_size = len(out_tokenizer.word_index) + 1  \n",
    "out_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integer encode the documents\n",
    "X_train_encoded_docs = inp_tokenizer.texts_to_sequences(train_final_data.X)\n",
    "y_train_encoded_docs = out_tokenizer.texts_to_sequences(train_final_data.y)\n",
    "\n",
    "X_val_encoded_docs = inp_tokenizer.texts_to_sequences(val_final_data.X)\n",
    "y_val_encoded_docs = out_tokenizer.texts_to_sequences(val_final_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad documents of X to max length\n",
    "X_train_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(X_train_encoded_docs,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(X_val_encoded_docs,maxlen=X_train_padded_docs.shape[1],\n",
    "                                                                  padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328972, 23)\n",
      "(61183, 23)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_padded_docs.shape)\n",
    "print(X_val_padded_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad documents of y\n",
    "y_train_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(y_train_encoded_docs,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(y_val_encoded_docs,maxlen=y_train_padded_docs.shape[1],\n",
    "                                                                  padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328972, 23)\n",
      "(61183, 23)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_padded_docs.shape)\n",
    "print(y_val_padded_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:37, 10562.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#Load embedding vectors\n",
    "#https://nlp.stanford.edu/projects/glove/\n",
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.300d.txt\", encoding=\"utf8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "763f82e7db814294b0aab491a356249d"
     ]
    },
    "colab_type": "code",
    "id": "nwMVDoJQ0XHV",
    "outputId": "4c311ae3-3d5d-45ab-aa52-0ed8c6f2a59b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1469/1469 [00:00<00:00, 180867.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#create a weight matrix for input embedding layer\n",
    "inp_embedding_matrix = np.zeros((inp_vocab_size, 300))\n",
    "for word, i in tqdm(inp_tokenizer.word_index.items()):\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        inp_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFgQKmA50XHc",
    "outputId": "9d557be6-724d-4bf7-8d92-9c1c979fed3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "763f82e7db814294b0aab491a356249d"
     ]
    },
    "colab_type": "code",
    "id": "nwMVDoJQ0XHV",
    "outputId": "4c311ae3-3d5d-45ab-aa52-0ed8c6f2a59b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1468/1468 [00:00<00:00, 164298.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#create a weight matrix for output embedding layer\n",
    "out_embedding_matrix = np.zeros((out_vocab_size, 300))\n",
    "for word, i in tqdm(out_tokenizer.word_index.items()):\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        out_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFgQKmA50XHc",
    "outputId": "9d557be6-724d-4bf7-8d92-9c1c979fed3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1469, 300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoded_data']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump([X_train_padded_docs,y_train_padded_docs,X_val_padded_docs,y_val_padded_docs,\n",
    "             inp_embedding_matrix,out_embedding_matrix,inp_tokenizer,out_tokenizer],'encoded_data',compress=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>Character Featurization</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Load sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_preprocessed_data.csv',nrows=5000)\n",
    "validate = pd.read_csv('val_preprocessed_data.csv',nrows=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Data Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_and_target(text):\n",
    "    \"\"\"\n",
    "    Generates the input and target features from a single sentence\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    a = list(text)\n",
    "    for i in range(1,len(a)):\n",
    "        X.append(''.join(a[:i]))\n",
    "        y.append(''.join(a[i:]))\n",
    "\n",
    "    #Convert to dataframe\n",
    "    b = pd.DataFrame(data={'X':X,'y':y})\n",
    "    #Prepare input sequence to model, add start(#) and end tokens(*)\n",
    "    b['X'] = '# ' + b['X'] + ' *'\n",
    "    b['y'] = '# ' + b['y'] + ' *'\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data for all samples\n",
    "def generate_data_for_model(data_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates data for input to model\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(data_df.shape[0])):\n",
    "        if i==0:\n",
    "            \n",
    "            final_df = generate_input_and_target(data_df.sent.iloc[0])\n",
    "        else:\n",
    "            final_df = pd.concat([final_df,generate_input_and_target(data_df.sent.iloc[i])],ignore_index=True)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load train_data_featurization.py\n",
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_input_and_target(text):\n",
    "    \"\"\"\n",
    "    Generates the input and target features from a single sentence\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    a = list(text)\n",
    "    for i in range(1,len(a)):\n",
    "        X.append(''.join(a[:i]))\n",
    "        y.append(''.join(a[i:]))\n",
    "\n",
    "    #Convert to dataframe\n",
    "    b = pd.DataFrame(data={'X':X,'y':y})\n",
    "    #Prepare input sequence to model, add start(#) and end tokens(*)\n",
    "    b['X'] = '# ' + b['X'] + ' *'\n",
    "    b['y'] = '# ' + b['y'] + ' *'\n",
    "    \n",
    "    return b\n",
    "    \n",
    "#Generate data for all samples\n",
    "def generate_data_for_model(data_df,filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates data for input to model\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(data_df.shape[0])):\n",
    "        if i==0:\n",
    "            final_df = generate_input_and_target(data_df.sent.iloc[0])\n",
    "        else:\n",
    "            final_df = pd.concat([final_df,generate_input_and_target(data_df.sent.iloc[i])],ignore_index=True)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "        \n",
    "    #Create folder to dataframe\n",
    "    if not os.path.isdir('final_df'):\n",
    "        os.makedirs('final_df')\n",
    "    if not os.path.isdir('final_df/train'):\n",
    "        os.makedirs('final_df/train')\n",
    "        \n",
    "    #Save dataframe\n",
    "    final_df.to_csv('final_df/train/'+filename+'.csv',index=False,index_label=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    #the below code is used for multiprogramming\n",
    "    #the number of process depends upon the number of cores present System\n",
    "    #process is used to call multiprogramming\n",
    "    \n",
    "    #Import dataset\n",
    "    data = pd.read_csv('train_preprocessed_data.csv',nrows=8000)\n",
    "    \n",
    "    data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8 = np.array_split(data,8)\n",
    "\n",
    "    start=time.time()\n",
    "    manager=multiprocessing.Manager() \t\n",
    "    p1=multiprocessing.Process(target=generate_data_for_model,args=(data_1,'first'))\n",
    "    p2=multiprocessing.Process(target=generate_data_for_model,args=(data_2,'second'))\n",
    "    p3=multiprocessing.Process(target=generate_data_for_model,args=(data_3,'third'))\n",
    "    p4=multiprocessing.Process(target=generate_data_for_model,args=(data_4,'fourth'))\n",
    "    p5=multiprocessing.Process(target=generate_data_for_model,args=(data_5,'fifth'))\n",
    "    p6=multiprocessing.Process(target=generate_data_for_model,args=(data_6,'sixth'))\n",
    "    p7=multiprocessing.Process(target=generate_data_for_model,args=(data_7,'seventh'))\n",
    "    p8=multiprocessing.Process(target=generate_data_for_model,args=(data_8,'eighth'))\n",
    "    \n",
    "    #p1.start() is used to start the thread execution\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    p4.start()\n",
    "    p5.start()\n",
    "    p6.start()\n",
    "    p7.start()\n",
    "    p8.start()\n",
    "\n",
    "    #After completion all the threads are joined\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()\n",
    "    p5.join()\n",
    "    p6.join()\n",
    "    p7.join()\n",
    "    p8.join()\n",
    "    print('Time taken: {} seconds'.format(np.round(time.time()-start,2)))\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:11<00:00, 55.19it/s]\n",
      "100%|██████████| 625/625 [00:11<00:00, 54.94it/s]\n",
      "100%|██████████| 625/625 [00:11<00:00, 55.00it/s]\n",
      "100%|██████████| 625/625 [00:11<00:00, 54.98it/s]\n",
      "100%|██████████| 625/625 [00:11<00:00, 53.99it/s]\n",
      "100%|██████████| 625/625 [00:11<00:00, 53.40it/s]\n",
      "100%|██████████| 625/625 [00:11<00:00, 53.35it/s]\n",
      "100%|██████████| 625/625 [00:11<00:00, 53.22it/s]\n",
      "Time taken: 11.93 seconds\n"
     ]
    }
   ],
   "source": [
    "! python train_data_featurization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all train data which is featurized\n",
    "a = pd.read_csv('final_df/train/first.csv')\n",
    "b = pd.read_csv('final_df/train/second.csv')\n",
    "c = pd.read_csv('final_df/train/third.csv')\n",
    "d = pd.read_csv('final_df/train/fourth.csv')\n",
    "e = pd.read_csv('final_df/train/fifth.csv')\n",
    "f = pd.read_csv('final_df/train/sixth.csv')\n",
    "g = pd.read_csv('final_df/train/seventh.csv')\n",
    "h = pd.read_csv('final_df/train/eighth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = pd.concat([a,b,c,d,e,f,g,h],ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># i *</td>\n",
       "      <td># t looks like we should have them soon *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># it *</td>\n",
       "      <td>#  looks like we should have them soon *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># it  *</td>\n",
       "      <td># looks like we should have them soon *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># it l *</td>\n",
       "      <td># ooks like we should have them soon *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># it lo *</td>\n",
       "      <td># oks like we should have them soon *</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X                                          y\n",
       "0      # i *  # t looks like we should have them soon *\n",
       "1     # it *   #  looks like we should have them soon *\n",
       "2    # it  *    # looks like we should have them soon *\n",
       "3   # it l *     # ooks like we should have them soon *\n",
       "4  # it lo *      # oks like we should have them soon *"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217184, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data.to_csv('train_final_data.csv',index=False,index_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 97.77it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 93.19it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 88.50it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 88.81it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 86.12it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 85.71it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 84.43it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 84.36it/s]\n",
      "Time taken: 1.58 seconds\n"
     ]
    }
   ],
   "source": [
    "! python val_data_featurization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all validation data which is featurized\n",
    "a = pd.read_csv('final_df/val/first.csv')\n",
    "b = pd.read_csv('final_df/val/second.csv')\n",
    "c = pd.read_csv('final_df/val/third.csv')\n",
    "d = pd.read_csv('final_df/val/fourth.csv')\n",
    "e = pd.read_csv('final_df/val/fifth.csv')\n",
    "f = pd.read_csv('final_df/val/sixth.csv')\n",
    "g = pd.read_csv('final_df/val/seventh.csv')\n",
    "h = pd.read_csv('final_df/val/eighth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_data = pd.concat([a,b,c,d,e,f,g,h],ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># b *</td>\n",
       "      <td># ut again that might be just what the two uti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># bu *</td>\n",
       "      <td># t again that might be just what the two util...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># but *</td>\n",
       "      <td>#  again that might be just what the two utili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># but  *</td>\n",
       "      <td># again that might be just what the two utilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># but a *</td>\n",
       "      <td># gain that might be just what the two utiliti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X                                                  y\n",
       "0      # b *  # ut again that might be just what the two uti...\n",
       "1     # bu *  # t again that might be just what the two util...\n",
       "2    # but *  #  again that might be just what the two utili...\n",
       "3   # but  *  # again that might be just what the two utilit...\n",
       "4  # but a *  # gain that might be just what the two utiliti..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41833, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the model is to predict the next few characters given sufficient number of input characters. If the number of input characters are too small, the predicted output is less likely to make sense. Hence for validation data, the samples whose number of characters are less than 14 are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column which counts number of characters in each text\n",
    "val_final_data['X_length'] = val_final_data['X'].apply(lambda text:len(list(text)))\n",
    "\n",
    "#Drop samples with characters less than 15\n",
    "val_final_data = val_final_data[val_final_data['X_length']>=15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>X_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td># but again t *</td>\n",
       "      <td># hat might be just what the two utilities rec...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td># but again th *</td>\n",
       "      <td># at might be just what the two utilities rece...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td># but again tha *</td>\n",
       "      <td># t might be just what the two utilities recei...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td># but again that *</td>\n",
       "      <td>#  might be just what the two utilities receive *</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td># but again that  *</td>\n",
       "      <td># might be just what the two utilities receive *</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      X                                                  y  \\\n",
       "10      # but again t *  # hat might be just what the two utilities rec...   \n",
       "11     # but again th *  # at might be just what the two utilities rece...   \n",
       "12    # but again tha *  # t might be just what the two utilities recei...   \n",
       "13   # but again that *  #  might be just what the two utilities receive *   \n",
       "14  # but again that  *   # might be just what the two utilities receive *   \n",
       "\n",
       "    X_length  \n",
       "10        15  \n",
       "11        16  \n",
       "12        17  \n",
       "13        18  \n",
       "14        19  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31853, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_data.to_csv('val_final_data.csv',index=False,index_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',char_level=True)\n",
    "tokenizer.fit_on_texts(train_final_data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " '#': 12,\n",
       " '*': 13,\n",
       " 'a': 5,\n",
       " 'b': 25,\n",
       " 'c': 18,\n",
       " 'd': 15,\n",
       " 'e': 2,\n",
       " 'f': 21,\n",
       " 'g': 22,\n",
       " 'h': 10,\n",
       " 'i': 6,\n",
       " 'j': 27,\n",
       " 'k': 23,\n",
       " 'l': 9,\n",
       " 'm': 19,\n",
       " 'n': 7,\n",
       " 'o': 4,\n",
       " 'p': 20,\n",
       " 'q': 26,\n",
       " 'r': 11,\n",
       " 's': 8,\n",
       " 't': 3,\n",
       " 'u': 14,\n",
       " 'v': 24,\n",
       " 'w': 16,\n",
       " 'x': 28,\n",
       " 'y': 17,\n",
       " 'z': 29}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integer encode the documents\n",
    "X_train_encoded_docs = tokenizer.texts_to_sequences(train_final_data.X)\n",
    "y_train_encoded_docs = tokenizer.texts_to_sequences(train_final_data.y)\n",
    "\n",
    "X_val_encoded_docs = tokenizer.texts_to_sequences(val_final_data.X)\n",
    "y_val_encoded_docs = tokenizer.texts_to_sequences(val_final_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad documents of X to max length\n",
    "X_train_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(X_train_encoded_docs,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(X_val_encoded_docs,maxlen=X_train_padded_docs.shape[1],\n",
    "                                                                  padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217184, 132)\n",
      "(31853, 132)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_padded_docs.shape)\n",
    "print(X_val_padded_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad documents of y to max length\n",
    "y_train_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(y_train_encoded_docs,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_padded_docs = tf.keras.preprocessing.sequence.pad_sequences(y_val_encoded_docs,maxlen=y_train_padded_docs.shape[1],\n",
    "                                                                  padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217184, 132)\n",
      "(31853, 132)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_padded_docs.shape)\n",
    "print(y_val_padded_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:00, 1291.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#Load embedding vectors\n",
    "embeddings_dict = {}\n",
    "with open(\"glove_char_vectors.txt\", encoding=\"utf8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split()\n",
    "        char = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[char] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "763f82e7db814294b0aab491a356249d"
     ]
    },
    "colab_type": "code",
    "id": "nwMVDoJQ0XHV",
    "outputId": "4c311ae3-3d5d-45ab-aa52-0ed8c6f2a59b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 26586.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#create a weight matrix\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for char, i in tqdm(tokenizer.word_index.items()):\n",
    "    embedding_vector = embeddings_dict.get(char)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFgQKmA50XHc",
    "outputId": "9d557be6-724d-4bf7-8d92-9c1c979fed3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['char_encoded_data']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump([X_train_padded_docs,y_train_padded_docs,X_val_padded_docs,y_val_padded_docs,embedding_matrix,\n",
    "             tokenizer],'char_encoded_data',compress=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:35px\"><center>GPT2 Word Featurization</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Load sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_preprocessed_data.csv')\n",
    "validate = pd.read_csv('val_preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Data Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_and_target(text):\n",
    "    \"\"\"\n",
    "    Generates the input and target features from a single sentence\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    a = text.split()\n",
    "    for i in range(1,len(a)):\n",
    "        X.append(' '.join(a[:i]))\n",
    "        y.append(' '.join(a[i:]))\n",
    "\n",
    "    #Convert to dataframe\n",
    "    b = pd.DataFrame(data={'X':X,'y':y})\n",
    "    #Prepare input sequence to model, add start(#) and end tokens(*)\n",
    "    b['X'] = '<|startoftext|>' + b['X']\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data for all samples\n",
    "def generate_data_for_model(data_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates data for input to model\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(data_df.shape[0])):\n",
    "        if i==0:\n",
    "            \n",
    "            final_df = generate_input_and_target(data_df.sent.iloc[0])\n",
    "        else:\n",
    "            final_df = pd.concat([final_df,generate_input_and_target(data_df.sent.iloc[i])],ignore_index=True)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load train_data_featurization.py\n",
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_input_and_target(text):\n",
    "    \"\"\"\n",
    "    Generates the input and target features from a single sentence\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    a = text.split()\n",
    "    for i in range(1,len(a)):\n",
    "        X.append(' '.join(a[:i]))\n",
    "        y.append(' '.join(a[i:]))\n",
    "\n",
    "    #Convert to dataframe\n",
    "    b = pd.DataFrame(data={'X':X,'y':y})\n",
    "    #Prepare input sequence to model, add start(#) and end tokens(*)\n",
    "    b['X'] = '<|startoftext|>' + b['X']\n",
    "    \n",
    "    return b\n",
    "    \n",
    "#Generate data for all samples\n",
    "def generate_data_for_model(data_df,filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates data for input to model\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(data_df.shape[0])):\n",
    "        if i==0:\n",
    "            final_df = generate_input_and_target(data_df.sent.iloc[0])\n",
    "        else:\n",
    "            final_df = pd.concat([final_df,generate_input_and_target(data_df.sent.iloc[i])],ignore_index=True)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "        \n",
    "    #Create folder to dataframe\n",
    "    if not os.path.isdir('final_df'):\n",
    "        os.makedirs('final_df')\n",
    "    if not os.path.isdir('final_df/train'):\n",
    "        os.makedirs('final_df/train')\n",
    "        \n",
    "    #Save dataframe\n",
    "    final_df.to_csv('final_df/train/'+filename+'.csv',index=False,index_label=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    #the below code is used for multiprogramming\n",
    "    #the number of process depends upon the number of cores present System\n",
    "    #process is used to call multiprogramming\n",
    "    \n",
    "    #Import dataset\n",
    "    data = pd.read_csv('train_preprocessed_data.csv')\n",
    "    \n",
    "    data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8 = np.array_split(data,8)\n",
    "\n",
    "    start=time.time()\n",
    "    manager=multiprocessing.Manager() \t\n",
    "    p1=multiprocessing.Process(target=generate_data_for_model,args=(data_1,'first'))\n",
    "    p2=multiprocessing.Process(target=generate_data_for_model,args=(data_2,'second'))\n",
    "    p3=multiprocessing.Process(target=generate_data_for_model,args=(data_3,'third'))\n",
    "    p4=multiprocessing.Process(target=generate_data_for_model,args=(data_4,'fourth'))\n",
    "    p5=multiprocessing.Process(target=generate_data_for_model,args=(data_5,'fifth'))\n",
    "    p6=multiprocessing.Process(target=generate_data_for_model,args=(data_6,'sixth'))\n",
    "    p7=multiprocessing.Process(target=generate_data_for_model,args=(data_7,'seventh'))\n",
    "    p8=multiprocessing.Process(target=generate_data_for_model,args=(data_8,'eighth'))\n",
    "    \n",
    "    #p1.start() is used to start the thread execution\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    p4.start()\n",
    "    p5.start()\n",
    "    p6.start()\n",
    "    p7.start()\n",
    "    p8.start()\n",
    "\n",
    "    #After completion all the threads are joined\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()\n",
    "    p5.join()\n",
    "    p6.join()\n",
    "    p7.join()\n",
    "    p8.join()\n",
    "    print('Time taken: {} seconds'.format(np.round(time.time()-start,2)))\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5228/5228 [01:20<00:00, 65.02it/s] \n",
      "100%|██████████| 5228/5228 [01:20<00:00, 65.01it/s]\n",
      "100%|██████████| 5229/5229 [01:20<00:00, 64.60it/s]\n",
      "100%|██████████| 5229/5229 [01:21<00:00, 64.46it/s]\n",
      "100%|██████████| 5229/5229 [01:21<00:00, 64.46it/s]\n",
      "100%|██████████| 5228/5228 [01:21<00:00, 64.42it/s]\n",
      "100%|██████████| 5229/5229 [01:21<00:00, 64.09it/s]\n",
      "100%|██████████| 5228/5228 [01:21<00:00, 64.11it/s]\n",
      "Time taken: 81.75 seconds\n"
     ]
    }
   ],
   "source": [
    "! python train_data_featurization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all train data which is featurized\n",
    "a = pd.read_csv('final_df/train/first.csv')\n",
    "b = pd.read_csv('final_df/train/second.csv')\n",
    "c = pd.read_csv('final_df/train/third.csv')\n",
    "d = pd.read_csv('final_df/train/fourth.csv')\n",
    "e = pd.read_csv('final_df/train/fifth.csv')\n",
    "f = pd.read_csv('final_df/train/sixth.csv')\n",
    "g = pd.read_csv('final_df/train/seventh.csv')\n",
    "h = pd.read_csv('final_df/train/eighth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = pd.concat([a,b,c,d,e,f,g,h],ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|startoftext|&gt;it</td>\n",
       "      <td>looks like we should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks</td>\n",
       "      <td>like we should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks like</td>\n",
       "      <td>we should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks like we</td>\n",
       "      <td>should have them soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|startoftext|&gt;it looks like we should</td>\n",
       "      <td>have them soon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        X                                    y\n",
       "0                       <|startoftext|>it  looks like we should have them soon\n",
       "1                 <|startoftext|>it looks        like we should have them soon\n",
       "2            <|startoftext|>it looks like             we should have them soon\n",
       "3         <|startoftext|>it looks like we                should have them soon\n",
       "4  <|startoftext|>it looks like we should                       have them soon"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328972, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data.to_csv('train_final_data.csv',index=False,index_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1307/1307 [00:09<00:00, 138.57it/s]\n",
      "100%|██████████| 1308/1308 [00:09<00:00, 138.22it/s]\n",
      "100%|██████████| 1307/1307 [00:09<00:00, 138.00it/s]\n",
      "100%|██████████| 1307/1307 [00:09<00:00, 136.81it/s]\n",
      "100%|██████████| 1307/1307 [00:09<00:00, 136.85it/s]\n",
      "100%|██████████| 1307/1307 [00:09<00:00, 135.44it/s]\n",
      "100%|██████████| 1307/1307 [00:09<00:00, 135.60it/s]\n",
      "100%|██████████| 1307/1307 [00:09<00:00, 135.03it/s]\n",
      "Time taken: 9.77 seconds\n"
     ]
    }
   ],
   "source": [
    "! python val_data_featurization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all validation data which is featurized\n",
    "a = pd.read_csv('final_df/val/first.csv')\n",
    "b = pd.read_csv('final_df/val/second.csv')\n",
    "c = pd.read_csv('final_df/val/third.csv')\n",
    "d = pd.read_csv('final_df/val/fourth.csv')\n",
    "e = pd.read_csv('final_df/val/fifth.csv')\n",
    "f = pd.read_csv('final_df/val/sixth.csv')\n",
    "g = pd.read_csv('final_df/val/seventh.csv')\n",
    "h = pd.read_csv('final_df/val/eighth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_data = pd.concat([a,b,c,d,e,f,g,h],ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|startoftext|&gt;but</td>\n",
       "      <td>again that might be just what the two utilitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|startoftext|&gt;but again</td>\n",
       "      <td>that might be just what the two utilities receive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that</td>\n",
       "      <td>might be just what the two utilities receive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might</td>\n",
       "      <td>be just what the two utilities receive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might be</td>\n",
       "      <td>just what the two utilities receive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        X  \\\n",
       "0                      <|startoftext|>but   \n",
       "1                <|startoftext|>but again   \n",
       "2           <|startoftext|>but again that   \n",
       "3     <|startoftext|>but again that might   \n",
       "4  <|startoftext|>but again that might be   \n",
       "\n",
       "                                                   y  \n",
       "0  again that might be just what the two utilitie...  \n",
       "1  that might be just what the two utilities receive  \n",
       "2       might be just what the two utilities receive  \n",
       "3             be just what the two utilities receive  \n",
       "4                just what the two utilities receive  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82086, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the model is to predict the next few words given sufficient number of input words. If the number of input words are too small, the predicted output is less likely to make sense. Hence for validation data, the samples whose number of words are less than 3 are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column which counts number of words in each text\n",
    "val_final_data['X_length'] = val_final_data['X'].apply(lambda text:len(text.split()))\n",
    "\n",
    "#Drop samples with words less than 2 \n",
    "val_final_data = val_final_data[val_final_data['X_length']>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>X_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that</td>\n",
       "      <td>might be just what the two utilities receive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might</td>\n",
       "      <td>be just what the two utilities receive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might be</td>\n",
       "      <td>just what the two utilities receive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might be just</td>\n",
       "      <td>what the two utilities receive</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;|startoftext|&gt;but again that might be just what</td>\n",
       "      <td>the two utilities receive</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  X  \\\n",
       "2                     <|startoftext|>but again that   \n",
       "3               <|startoftext|>but again that might   \n",
       "4            <|startoftext|>but again that might be   \n",
       "5       <|startoftext|>but again that might be just   \n",
       "6  <|startoftext|>but again that might be just what   \n",
       "\n",
       "                                              y  X_length  \n",
       "2  might be just what the two utilities receive         3  \n",
       "3        be just what the two utilities receive         4  \n",
       "4           just what the two utilities receive         5  \n",
       "5                what the two utilities receive         6  \n",
       "6                     the two utilities receive         7  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61183, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_data.to_csv('val_final_data.csv',index=False,index_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
